{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2: Tagging and Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Student Name: Alex Cheadle\n",
    "\n",
    "Student ID: 847388\n",
    "\n",
    "Python version used: 2.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Due date</b>: 5pm, Thursday March 30\n",
    "\n",
    "<b>Submission method</b>: see LMS\n",
    "\n",
    "<b>Submission materials</b>: completed copy of this iPython notebook\n",
    "\n",
    "<b>Late submissions</b>: -20% per day\n",
    "\n",
    "<b>Marks</b>: 5% of mark for class\n",
    "\n",
    "<b>Overview</b>: In this homework, you'll be building a hidden Markov (HMM) part-of-speech tagger and applying it to text. This includes training over labelled text, then prediction (decoding) to tag an unlabelled sentence and evaluating the result. The catch is that you're to do so using algorithms from probabilistic parsing. The HMM is a kind of weighted state-machine, which formally defines a (probablistic) regular language. Context free languages subsume the regular languages, and therefore a HMM is a specific type of PCFG. Your task will be to use this equivalence in order to implement HMM decoding using PCFG parsing routings, and use this for part-of-speech tagging. \n",
    "\n",
    "<b>Materials</b>: See the main class LMS page for information on the basic setup required for this class, including an iPython notebook viewer and the python packages NLTK, Numpy, Scipy, Matplotlib, Scikit-Learn, and Gemsim. In particular, if you are not using a lab computer which already has it installed, we recommend installing all the data for NLTK, since you will need various parts of it to complete this assignment. You can also use any Python built-in packages, but do not use any other 3rd party packages; if your iPython notebook doesn't run on the marker's machine, you will lose marks.  \n",
    "\n",
    "<b>Evaluation</b>: Your iPython notebook should run end-to-end without any errors in a reasonable amount of time, and you must follow all instructions provided below, including specific implementation requirements and instructions for what needs to be printed (please avoid printing output we don't ask for). The amount each section is worth is given in parenthesis after the instructions. You will be marked not only on the correctness of your methods, but also the quality and efficency of your code: in particular, you should be careful to use Python built-in functions and operators when appropriate and pick descriptive variable names that adhere to <a href=\"https://www.python.org/dev/peps/pep-0008/\">Python style requirements</a>. If you think it might be unclear what you are doing, you should comment your code to help the marker make sense of it.\n",
    "\n",
    "<b>Extra credit</b>: Each homework has a task which is optional with respect to getting full marks on the assignment, but that can be used to offset any points lost on this or any other homework assignment (but not the final project or the exam). We recommend you skip over this step on your first pass, and come back if you have time: the amount of effort required to receive full marks (1 point) on an extra credit question will be substantially more than earning the same amount of credit on other parts of the homework.\n",
    "\n",
    "<b>Updates</b>: Any major changes to the assignment will be announced via LMS. Minor changes and clarifications will be announced in the forum on LMS, we recommend you check the forum regularly.\n",
    "\n",
    "<b>Academic Misconduct</b>: For most people, collaboration will form a natural part of the undertaking of this homework, and we encourge you to discuss it in general terms with other students. However, this ultimately is still an individual task, and so reuse of code or other instances of clear influence will be considered cheating. We will be checking submissions for originality and will invoke the University’s <a href=\"http://academichonesty.unimelb.edu.au/policy.html\">Academic Misconduct policy</a> where inappropriate levels of collusion or plagiarism are deemed to have taken place.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>Instructions</b>: For this homework we will be using the tagged sentences in the `nltk.corpus.treebank` corpus. You should start by accessing this dataset, using the `tagged_sents` method to access the sentences in the corpus, which are composed of pairs of tokens and their part of speech tags. For this homework, use all the `fileids` for training (we won't both with heldout validation or testing sets for the homework.) For each sentence, add special tokens, `<s>` and `</s>`, to the start and end. You should lower-case the tokens in the text, to limit the number of parameters in the model and allow for better generalisation.\n",
    "\n",
    "Estimate the parameters of a _first order_ HMM tagger over the training partition. First order means that the transition probabilities depend on one previous tag, i.e., the A matrix stores $p(t | t')$ entries, where _t_ and _t'_ are the current and previous tag, respectively. Estimating the parameters (a.k.a. training) means learning the transition (A), observation (O) and starting state (pi) parameter. You will need to compute normalised frequency counts, as described in the lecture (and also the workshop and reading). You may want to store these using special dictionary variants from `collections`, such as `Counter` or `defaultdict`, or use `numpy.array` objects. Don't worry about smoothing the parameters for this homework. \n",
    "\n",
    "You should include in your transition parameters the transition to the `</s>` token, which ends the sequence. You may want to do the same for the `<s>` token, in which case the pi vector can be treated as a special row in A.\n",
    "\n",
    "Your code should print out the following summary numbers: 1) the number of tag types, 2) the number of word tokens and word types (unique words), and 4) the number of parameters in each of A, O, and pi.\n",
    "\n",
    "(1.5 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3914"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import treebank\n",
    "taggedSents = treebank.tagged_sents()\n",
    "cleanedSents = []\n",
    "\n",
    "\n",
    "for sent in taggedSents :\n",
    "    newSent = []\n",
    "    newSent.append(('<s>', 'START'))\n",
    "    for (word, tag) in sent:\n",
    "        newSent.append((word.lower(), tag))\n",
    "    newSent.append(('</s>', 'END'))\n",
    "    cleanedSents.append(newSent)\n",
    "cleanedSents[0]\n",
    "len(cleanedSents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<s>', 'START'), (u'pierre', u'NNP'), (u'vinken', u'NNP'), (u',', u','), (u'61', u'CD'), (u'years', u'NNS'), (u'old', u'JJ'), (u',', u','), (u'will', u'MD'), (u'join', u'VB'), (u'the', u'DT'), (u'board', u'NN'), (u'as', u'IN'), (u'a', u'DT'), (u'nonexecutive', u'JJ'), (u'director', u'NN'), (u'nov.', u'NNP'), (u'29', u'CD'), (u'.', u'.'), ('</s>', 'END')]\n"
     ]
    }
   ],
   "source": [
    "print cleanedSents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of tag types: 47\n",
      "The number of word tokens 108504\n",
      "The number of unique words 11389\n",
      "A has 1047 params\n",
      "O has 13155 params\n",
      "pi has 36 params\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "# Need to make pi (prob that each tag! starts the chain)\n",
    "# A matrix num Tags * num Tags.\n",
    "# which A(t1, t2) is P(t1 | t2)\n",
    "# O matrix num tags * num words\n",
    "# O(t1, w1) = P(t1 == w1)\n",
    "\n",
    "# Calc pi\n",
    "firstTags = [sent[1][1] for sent in cleanedSents]\n",
    "counter = Counter()\n",
    "for firstTag in firstTags :\n",
    "    counter[firstTag] += 1\n",
    "    \n",
    "#posTags = list(counter)\n",
    "numberOfTags = sum(counter.values()) \n",
    "\n",
    "pi = defaultdict()\n",
    "for tag in counter: \n",
    "    pi[tag] = float(counter[tag]) / float(numberOfTags)\n",
    "\n",
    "# Now lets calc A\n",
    "tagPairCounter = Counter()\n",
    "for sent in cleanedSents:\n",
    "    for i in range (0, len(sent) - 1):\n",
    "        firstTag = sent[i][1]\n",
    "        secondTag = sent[i+1][1]\n",
    "        tagPairCounter[(firstTag, secondTag)] += 1\n",
    "\n",
    "\n",
    "# P(t2 | t1) = N(t1, t2) / N(t1, *)\n",
    "# where t2 is the new tag (RHS)\n",
    "\n",
    "# totalDict is a dict such that totalDict[t2] = N(t2, *)\n",
    "tagFreq = Counter()\n",
    "for (t1, t2) in tagPairCounter :\n",
    "    freq = tagPairCounter[(t1, t2)]\n",
    "    tagFreq[t1] += freq\n",
    "    \n",
    "A = defaultdict()\n",
    "for (t1, t2) in tagPairCounter :\n",
    "    freq = tagPairCounter[(t1, t2)]\n",
    "    A[(t1, t2)] = float(freq) / float(tagFreq[t1])\n",
    "    \n",
    "# Now, lets calc O\n",
    "# O matrix num tags * num words\n",
    "# O(t1, w1) = P(w1 is of tag t1) = num(w1 tagged as t1) / num(t1)\n",
    "\n",
    "allWordWithTag = Counter()\n",
    "wordFreqs = Counter()\n",
    "for sent in cleanedSents:\n",
    "    for (word, tag) in sent:\n",
    "        allWordWithTag[(word, tag)] += 1\n",
    "        wordFreqs[word] += 1\n",
    "\n",
    "# So allWordWithTag has all word Tag pairs, without duplicates\n",
    "O = defaultdict()\n",
    "for (word, tag) in allWordWithTag :\n",
    "    O[word, tag] = float(allWordWithTag[(word, tag)]) / float (wordFreqs[(word)])\n",
    "\n",
    "    \n",
    "# NUmber of word tokens\n",
    "numWordTokens = 0\n",
    "for sent in cleanedSents:\n",
    "    for (word, tag) in sent:\n",
    "        numWordTokens += 1\n",
    "\n",
    "print (\"The number of tag types: \" + str(len(tagFreq)) + \" including START, but not END\")\n",
    "print (\"The number of word tokens \" + str(numWordTokens))\n",
    "print (\"The number of unique words \" + str(len(wordFreqs)))\n",
    "print (\"A has \" + str(len(A)) + \" params\")\n",
    "print (\"O has \" + str(len(O)) + \" params\")\n",
    "print (\"pi has \" + str(len(pi)) + \" params\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({u'NN': 13166, u'IN': 9857, u'NNP': 9410, u'DT': 8165, u'-NONE-': 6592, u'NNS': 6047, u'JJ': 5834, u',': 4886, 'START': 3914, u'.': 3874, u'CD': 3546, u'VBD': 3043, u'RB': 2822, u'VB': 2554, u'CC': 2265, u'TO': 2179, u'VBN': 2134, u'VBZ': 2125, u'PRP': 1716, u'VBG': 1460, u'VBP': 1321, u'MD': 927, u'POS': 824, u'PRP$': 766, u'$': 724, u'``': 712, u\"''\": 694, u':': 563, u'WDT': 445, u'JJR': 381, u'NNPS': 244, u'WP': 241, u'RP': 216, u'JJS': 182, u'WRB': 178, u'RBR': 136, u'-RRB-': 126, u'-LRB-': 120, u'EX': 88, u'RBS': 35, u'PDT': 27, u'#': 16, u'WP$': 14, u'LS': 13, u'FW': 4, u'UH': 3, u'SYM': 1})\n"
     ]
    }
   ],
   "source": [
    "print(tagFreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {u'PRP$': 0.00740929994890138, u'VBG': 0.004343382728666326, u'VBD': 0.0002554931016862545, u'VBN': 0.0017884517118037812, u\"''\": 0.0002554931016862545, u'WDT': 0.000510986203372509, u'JJ': 0.036535513541134386, u'WP': 0.0035769034236075624, u'VBZ': 0.0022994379151762903, u'DT': 0.2312212570260603, u'$': 0.0012774655084312723, u'NN': 0.04445579969340828, u'TO': 0.0012774655084312723, u'PRP': 0.06259580991313235, u'RB': 0.04471129279509453, u'-LRB-': 0.0017884517118037812, u':': 0.002810424118548799, u'NNS': 0.04675523760858457, u'NNP': 0.19775166070516095, u'``': 0.07562595809913132, u'WRB': 0.006387327542156361, u'CC': 0.05135411343893715, u'LS': 0.0017884517118037812, u'PDT': 0.0007664793050587634, u'RBS': 0.000510986203372509, u'RBR': 0.0007664793050587634, u'CD': 0.008431272355646398, u'-NONE-': 0.020950434338272865, u'EX': 0.004343382728666326, u'IN': 0.1290240163515585, u'MD': 0.0002554931016862545, u'NNPS': 0.0025549310168625446, u'JJS': 0.0015329586101175269, u'JJR': 0.0030659172202350538, u'VB': 0.0007664793050587634, u'UH': 0.0002554931016862545})\n",
      "3914\n",
      "3914\n"
     ]
    }
   ],
   "source": [
    "print(pi)\n",
    "print(numberOfTags)\n",
    "print(len(cleanedSents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Instructions</b>: The next part requires thinking about the relationships between formal languages. Recall that the regular languages (including the HMM) are a subset of the context-free languages (PCFGs). Note that although we have _weighted (probabilistic)_ grammars, the same relation still holds. Your challenge is to figure out a _context-free grammar_ that corresponds to the HMM tagger, and the weighting of each production. \n",
    "\n",
    "To help get started, consider a part-of-speech tagged sentence, e.g., _`<s>` Donald/NNP has/VBZ small/JJ hands/NNS_ `</s>`.  The sequence of tags forms a chain, which is already a type of tree. Think about how this tagged sequence is scored by the HMM to compute the joint probability, which might help to figure out what non-terminal symbols you might need and where to attach a special _S_ start symbol.   \n",
    "\n",
    "Use the HMM parameters computed above to construct a PCFG, using the `nltk.grammar.ProbabilisticProduction` and `nltk.grammar.PCFG` classes. This will require you to come up with a 'grammar' representation of the HMM, which you should create directly from your HMM parameters including the HMM probabilities in the PCFG productions. Your grammar should be in Chomsky Normal Form.\n",
    "\n",
    "Finally, implement a probabilistic CYK parser using your tagging _PCFG_. Feel free to cut-and-paste code from the supplied notebooks, although ensure when you do this you clearly specify in comments the source of the code (and if you make changes to the copied code, then use comments to flag these changes.) Apply this \"tagger\" to the test sentence \n",
    "\n",
    "    <s> a dozen dinosaurs debate deals for daily dessert delivery . </s>\n",
    "\n",
    "and print the predicted tree and the sequence of POS tags. During code development you may want to also view the chart.\n",
    "\n",
    "*Note: Depending on how you go about this, you may need to relax the test for grammar validity in the `PCFG` constructor by changing the constant `nltk.grammar.PCFG.EPSILON`.* \n",
    "\n",
    "(2.5 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.grammar import ProbabilisticProduction, PCFG, Nonterminal\n",
    "# First we need the non terminal to terminal productions \n",
    "# ie what is stored in O\n",
    "productions = []\n",
    "    \n",
    "for (word, tag) in O:\n",
    "    if word != '<s>' :\n",
    "        theProb = O[(word, tag)]\n",
    "        adjustedProb = theProb / 10000000000\n",
    "        productions.append(ProbabilisticProduction(Nonterminal(tag), [word], prob = adjustedProb))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now, we can deal with transitions between states (tags)\n",
    "    \n",
    "for (tag1, tag2) in A:\n",
    "    theProb = A[(tag1, tag2)]\n",
    "    if (tag2 == 'END') :\n",
    "        productions.append(ProbabilisticProduction(Nonterminal(tag1), [Nonterminal(tag2)], prob = theProb))\n",
    "    else :\n",
    "        productions.append(ProbabilisticProduction(Nonterminal(tag1), [Nonterminal(tag2),Nonterminal(tag2)], prob = theProb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We don't actually need to use pi, as it's included as a row of A\n",
    "# But we do need the start production! \n",
    "productions.append(ProbabilisticProduction(Nonterminal('START'),[Nonterminal('START'),Nonterminal('START')], prob = 0.000000001))\n",
    "productions.append(ProbabilisticProduction(Nonterminal('START'),['<s>'], prob = 1))\n",
    "productions.append(ProbabilisticProduction(Nonterminal('END'),['</s>'], prob = 0.00000000001))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "PCFG.EPSILON = 1000000\n",
    "pcfg = PCFG(Nonterminal(\"START\"),productions)\n",
    "\n",
    "print pcfg.is_flexible_chomsky_normal_form()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<tr><td><i><s><i></td><td><i>a<i></td><td><i>dozen<i></td><td><i>dinosaurs<i></td><td><i></s><i></td></tr><tr><td bgcolor='lightcyan'>[0,1]<br><b>START</b> [1.00000]</td><td bgcolor='lightcyan'>[0,2]</td><td bgcolor='lightcyan'>[0,3]<br><b>START</b> [0.00000]<br>&nbsp; (k=1, START -> START START [1e-05])</td><td bgcolor='lightcyan'>[0,4]<br><b>START</b> [0.00000]<br>&nbsp; (k=1, START -> START START [1e-05])</td><td bgcolor='lightcyan'>[0,5]<br><b>START</b> [0.00000]<br>&nbsp; (k=1, START -> START START [1e-05])</td></tr><tr><td></td><td bgcolor='lightcyan'>[1,2]<br><b>NN</b> [0.00000]<br><b>LS</b> [0.00000]<br><b>JJ</b> [0.00000]<br><b>IN</b> [0.00000]<br><b>DT</b> [0.00000]<br><b>NNP</b> [0.00000]</td><td bgcolor='lightcyan'>[1,3]<br><b>PRP$</b> [0.00000]<br>&nbsp; (k=2, PRP$ -> NN NN [0.439948])<br><b>VBG</b> [0.00000]<br>&nbsp; (k=2, VBG -> NN NN [0.146575])<br><b>VBD</b> [0.00000]<br>&nbsp; (k=2, VBD -> NN NN [0.0295761])<br><b>``</b> [0.00000]<br>&nbsp; (k=2, `` -> NN NN [0.0983146])<br><b>VBN</b> [0.00000]<br>&nbsp; (k=2, VBN -> NN NN [0.0674789])<br><b>,</b> [0.00000]<br>&nbsp; (k=2, , -> NN NN [0.0485059])<br><b>''</b> [0.00000]<br>&nbsp; (k=2, '' -> NN NN [0.0403458])<br><b>VBP</b> [0.00000]<br>&nbsp; (k=2, VBP -> NN NN [0.0264951])<br><b>WDT</b> [0.00000]<br>&nbsp; (k=2, WDT -> NN NN [0.00674157])<br><b>JJ</b> [0.00000]<br>&nbsp; (k=2, JJ -> NN NN [0.447549])<br><b>WP</b> [0.00000]<br>&nbsp; (k=2, WP -> NN NN [0.0124481])<br><b>VBZ</b> [0.00000]<br>&nbsp; (k=2, VBZ -> NN NN [0.0390588])<br><b>DT</b> [0.00000]<br>&nbsp; (k=2, DT -> NN NN [0.47079])<br><b>RP</b> [0.00000]<br>&nbsp; (k=2, RP -> NN NN [0.0509259])<br><b>NN</b> [0.00000]<br>&nbsp; (k=2, NN -> NN NN [0.125854])<br><b>FW</b> [0.00000]<br>&nbsp; (k=2, FW -> NN NN [0.25])<br><b>POS</b> [0.00000]<br>&nbsp; (k=2, POS -> NN NN [0.412621])<br><b>.</b> [0.00000]<br>&nbsp; (k=2, . -> NN NN [0.000258131])<br><b>TO</b> [0.00000]<br>&nbsp; (k=2, TO -> NN NN [0.0279945])<br><b>PRP</b> [0.00000]<br>&nbsp; (k=2, PRP -> NN NN [0.0034965])<br><b>RB</b> [0.00000]<br>&nbsp; (k=2, RB -> NN NN [0.0145287])<br><b>-LRB-</b> [0.00000]<br>&nbsp; (k=2, -LRB- -> NN NN [0.05])<br><b>:</b> [0.00000]<br>&nbsp; (k=2, : -> NN NN [0.035524])<br><b>NNS</b> [0.00000]<br>&nbsp; (k=2, NNS -> NN NN [0.0224905])<br><b>NNP</b> [0.00000]<br>&nbsp; (k=2, NNP -> NN NN [0.0553666])<br><b>VB</b> [0.00000]<br>&nbsp; (k=2, VB -> NN NN [0.0665623])<br><b>WRB</b> [0.00000]<br>&nbsp; (k=2, WRB -> NN NN [0.0617978])<br><b>CC</b> [0.00000]<br>&nbsp; (k=2, CC -> NN NN [0.12053])<br><b>CD</b> [0.00000]<br>&nbsp; (k=2, CD -> NN NN [0.193739])<br><b>START</b> [0.00000]<br>&nbsp; (k=2, START -> NN NN [0.0444558])<br><b>-NONE-</b> [0.00000]<br>&nbsp; (k=2, -NONE- -> NN NN [0.0189624])<br><b>IN</b> [0.00000]<br>&nbsp; (k=2, IN -> NN NN [0.109567])<br><b>WP$</b> [0.00000]<br>&nbsp; (k=2, WP$ -> NN NN [0.571429])<br><b>NNPS</b> [0.00000]<br>&nbsp; (k=2, NNPS -> NN NN [0.0204918])<br><b>-RRB-</b> [0.00000]<br>&nbsp; (k=2, -RRB- -> NN NN [0.0396825])<br><b>JJS</b> [0.00000]<br>&nbsp; (k=2, JJS -> NN NN [0.28022])<br><b>JJR</b> [0.00000]<br>&nbsp; (k=2, JJR -> NN NN [0.2021])</td><td bgcolor='lightcyan'>[1,4]<br><b>PRP$</b> [0.00000]<br>&nbsp; (k=3, PRP$ -> NNS NNS [0.206266])<br><b>VBG</b> [0.00000]<br>&nbsp; (k=3, VBG -> NNS NNS [0.0945205])<br><b>VBD</b> [0.00000]<br>&nbsp; (k=3, VBD -> NNS NNS [0.0193888])<br><b>``</b> [0.00000]<br>&nbsp; (k=3, `` -> NNS NNS [0.0308989])<br><b>VBN</b> [0.00000]<br>&nbsp; (k=3, VBN -> NNS NNS [0.0360825])<br><b>,</b> [0.00000]<br>&nbsp; (k=3, , -> NNS NNS [0.026402])<br><b>''</b> [0.00000]<br>&nbsp; (k=3, '' -> NNS NNS [0.0201729])<br><b>VBP</b> [0.00000]<br>&nbsp; (k=3, VBP -> NNS NNS [0.0219531])<br><b>WDT</b> [0.00000]<br>&nbsp; (k=3, WDT -> NNS NNS [0.0157303])<br><b>JJ</b> [0.00000]<br>&nbsp; (k=3, JJ -> NNS NNS [0.243744])<br><b>WP</b> [0.00000]<br>&nbsp; (k=3, WP -> NNS NNS [0.00829876])<br><b>VBZ</b> [0.00000]<br>&nbsp; (k=3, VBZ -> NNS NNS [0.0122353])<br><b>DT</b> [0.00000]<br>&nbsp; (k=3, DT -> NNS NNS [0.0774036])<br><b>RP</b> [0.00000]<br>&nbsp; (k=3, RP -> NNS NNS [0.0555556])<br><b>NN</b> [0.00000]<br>&nbsp; (k=3, NN -> NNS NNS [0.0817257])<br><b>POS</b> [0.00000]<br>&nbsp; (k=3, POS -> NNS NNS [0.127427])<br><b>TO</b> [0.00000]<br>&nbsp; (k=3, TO -> NNS NNS [0.0289123])<br><b>PRP</b> [0.00000]<br>&nbsp; (k=3, PRP -> NNS NNS [0.0011655])<br><b>RB</b> [0.00000]<br>&nbsp; (k=3, RB -> NNS NNS [0.00460666])<br><b>-LRB-</b> [0.00000]<br>&nbsp; (k=3, -LRB- -> NNS NNS [0.025])<br><b>:</b> [0.00000]<br>&nbsp; (k=3, : -> NNS NNS [0.0301954])<br><b>NNS</b> [0.00000]<br>&nbsp; (k=3, NNS -> NNS NNS [0.0125682])<br><b>NNP</b> [0.00000]<br>&nbsp; (k=3, NNP -> NNS NNS [0.0226355])<br><b>VB</b> [0.00000]<br>&nbsp; (k=3, VB -> NNS NNS [0.0446359])<br><b>WRB</b> [0.00000]<br>&nbsp; (k=3, WRB -> NNS NNS [0.0674157])<br><b>CC</b> [0.00000]<br>&nbsp; (k=3, CC -> NNS NNS [0.0701987])<br><b>CD</b> [0.00000]<br>&nbsp; (k=3, CD -> NNS NNS [0.14749])<br><b>START</b> [0.00000]<br>&nbsp; (k=3, START -> NNS NNS [0.0467552])<br><b>-NONE-</b> [0.00000]<br>&nbsp; (k=3, -NONE- -> NNS NNS [0.00530947])<br><b>IN</b> [0.00000]<br>&nbsp; (k=3, IN -> NNS NNS [0.0620879])<br><b>WP$</b> [0.00000]<br>&nbsp; (k=3, WP$ -> NNS NNS [0.357143])<br><b>MD</b> [0.00000]<br>&nbsp; (k=3, MD -> NNS NNS [0.00107875])<br><b>NNPS</b> [0.00000]<br>&nbsp; (k=3, NNPS -> NNS NNS [0.00819672])<br><b>JJS</b> [0.00000]<br>&nbsp; (k=3, JJS -> NNS NNS [0.175824])<br><b>JJR</b> [0.00000]<br>&nbsp; (k=3, JJR -> NNS NNS [0.194226])</td><td bgcolor='lightcyan'>[1,5]<br><b>PRP$</b> [0.00000]<br>&nbsp; (k=3, PRP$ -> JJ JJ [0.223238])<br><b>VBG</b> [0.00000]<br>&nbsp; (k=2, VBG -> DT DT [0.182877])<br><b>VBD</b> [0.00000]<br>&nbsp; (k=2, VBD -> DT DT [0.127834])<br><b>``</b> [0.00000]<br>&nbsp; (k=2, `` -> DT DT [0.176966])<br><b>VBN</b> [0.00000]<br>&nbsp; (k=2, VBN -> DT DT [0.0529522])<br><b>,</b> [0.00000]<br>&nbsp; (k=2, , -> DT DT [0.13508])<br><b>''</b> [0.00000]<br>&nbsp; (k=2, '' -> DT DT [0.0461095])<br><b>VBP</b> [0.00000]<br>&nbsp; (k=2, VBP -> DT DT [0.107494])<br><b>WDT</b> [0.00000]<br>&nbsp; (k=2, WDT -> DT DT [0.0224719])<br><b>JJ</b> [0.00000]<br>&nbsp; (k=2, JJ -> DT DT [0.00394241])<br><b>WP</b> [0.00000]<br>&nbsp; (k=2, WP -> DT DT [0.0414938])<br><b>VBZ</b> [0.00000]<br>&nbsp; (k=2, VBZ -> DT DT [0.139765])<br><b>DT</b> [0.00000]<br>&nbsp; (k=2, DT -> DT DT [0.00122474])<br><b>#</b> [0.00000]<br>&nbsp; (k=3, # -> CD CD [1.0])<br><b>RP</b> [0.00000]<br>&nbsp; (k=2, RP -> DT DT [0.199074])<br><b>$</b> [0.00000]<br>&nbsp; (k=3, $ -> CD CD [0.98895])<br><b>NN</b> [0.00000]<br>&nbsp; (k=2, NN -> DT DT [0.00539268])<br><b>FW</b> [0.00000]<br>&nbsp; (k=2, FW -> NN NN [0.25])<br><b>POS</b> [0.00000]<br>&nbsp; (k=3, POS -> JJ JJ [0.20267])<br><b>.</b> [0.00000]<br>&nbsp; (k=4, . -> '' '' [0.0606608])<br><b>TO</b> [0.00000]<br>&nbsp; (k=2, TO -> DT DT [0.129876])<br><b>PRP</b> [0.00000]<br>&nbsp; (k=2, PRP -> DT DT [0.00874126])<br><b>RB</b> [0.00000]<br>&nbsp; (k=2, RB -> DT DT [0.0517364])<br><b>-LRB-</b> [0.00000]<br>&nbsp; (k=2, -LRB- -> DT DT [0.0833333])<br><b>:</b> [0.00000]<br>&nbsp; (k=2, : -> DT DT [0.104796])<br><b>NNS</b> [0.00000]<br>&nbsp; (k=2, NNS -> DT DT [0.0132297])<br><b>NNP</b> [0.00000]<br>&nbsp; (k=2, NNP -> DT DT [0.00223167])<br><b>VB</b> [0.00000]<br>&nbsp; (k=2, VB -> DT DT [0.233359])<br><b>WRB</b> [0.00000]<br>&nbsp; (k=2, WRB -> DT DT [0.314607])<br><b>CC</b> [0.00000]<br>&nbsp; (k=2, CC -> DT DT [0.113024])<br><b>LS</b> [0.00000]<br>&nbsp; (k=4, LS -> : : [0.153846])<br><b>PDT</b> [0.00000]<br>&nbsp; (k=2, PDT -> DT DT [0.888889])<br><b>RBS</b> [0.00000]<br>&nbsp; (k=3, RBS -> JJ JJ [0.714286])<br><b>RBR</b> [0.00000]<br>&nbsp; (k=2, RBR -> DT DT [0.0514706])<br><b>CD</b> [0.00000]<br>&nbsp; (k=2, CD -> DT DT [0.00141004])<br><b>START</b> [0.00000]<br>&nbsp; (k=2, START -> DT DT [0.231221])<br><b>-NONE-</b> [0.00000]<br>&nbsp; (k=2, -NONE- -> DT DT [0.0533981])<br><b>EX</b> [0.00000]<br>&nbsp; (k=3, EX -> VBZ VBZ [0.590909])<br><b>IN</b> [0.00000]<br>&nbsp; (k=2, IN -> DT DT [0.318555])<br><b>WP$</b> [0.00000]<br>&nbsp; (k=3, WP$ -> JJ JJ [0.0714286])<br><b>MD</b> [0.00000]<br>&nbsp; (k=2, MD -> DT DT [0.00323625])<br><b>NNPS</b> [0.00000]<br>&nbsp; (k=4, NNPS -> : : [0.045082])<br><b>-RRB-</b> [0.00000]<br>&nbsp; (k=2, -RRB- -> DT DT [0.047619])<br><b>JJS</b> [0.00000]<br>&nbsp; (k=2, JJS -> DT DT [0.010989])<br><b>JJR</b> [0.00000]<br>&nbsp; (k=2, JJR -> DT DT [0.015748])<br><b>SYM</b> [0.00000]<br>&nbsp; (k=2, SYM -> NNP NNP [1.0])<br><b>UH</b> [0.00000]<br>&nbsp; (k=3, UH -> IN IN [0.333333])</td></tr><tr><td></td><td></td><td bgcolor='lightcyan'>[2,3]<br><b>NN</b> [0.00000]</td><td bgcolor='lightcyan'>[2,4]</td><td bgcolor='lightcyan'>[2,5]<br><b>PRP$</b> [0.00000]<br>&nbsp; (k=3, PRP$ -> NN NN [0.439948])<br><b>VBG</b> [0.00000]<br>&nbsp; (k=3, VBG -> NN NN [0.146575])<br><b>VBD</b> [0.00000]<br>&nbsp; (k=3, VBD -> NN NN [0.0295761])<br><b>``</b> [0.00000]<br>&nbsp; (k=3, `` -> NN NN [0.0983146])<br><b>VBN</b> [0.00000]<br>&nbsp; (k=3, VBN -> NN NN [0.0674789])<br><b>,</b> [0.00000]<br>&nbsp; (k=3, , -> NN NN [0.0485059])<br><b>''</b> [0.00000]<br>&nbsp; (k=3, '' -> NN NN [0.0403458])<br><b>VBP</b> [0.00000]<br>&nbsp; (k=3, VBP -> NN NN [0.0264951])<br><b>WDT</b> [0.00000]<br>&nbsp; (k=3, WDT -> NN NN [0.00674157])<br><b>JJ</b> [0.00000]<br>&nbsp; (k=3, JJ -> NN NN [0.447549])<br><b>WP</b> [0.00000]<br>&nbsp; (k=3, WP -> NN NN [0.0124481])<br><b>VBZ</b> [0.00000]<br>&nbsp; (k=3, VBZ -> NN NN [0.0390588])<br><b>DT</b> [0.00000]<br>&nbsp; (k=3, DT -> NN NN [0.47079])<br><b>RP</b> [0.00000]<br>&nbsp; (k=3, RP -> NN NN [0.0509259])<br><b>NN</b> [0.00000]<br>&nbsp; (k=3, NN -> NN NN [0.125854])<br><b>FW</b> [0.00000]<br>&nbsp; (k=3, FW -> NN NN [0.25])<br><b>POS</b> [0.00000]<br>&nbsp; (k=3, POS -> NN NN [0.412621])<br><b>.</b> [0.00000]<br>&nbsp; (k=3, . -> NN NN [0.000258131])<br><b>TO</b> [0.00000]<br>&nbsp; (k=3, TO -> NN NN [0.0279945])<br><b>PRP</b> [0.00000]<br>&nbsp; (k=3, PRP -> NN NN [0.0034965])<br><b>RB</b> [0.00000]<br>&nbsp; (k=3, RB -> NN NN [0.0145287])<br><b>-LRB-</b> [0.00000]<br>&nbsp; (k=3, -LRB- -> NN NN [0.05])<br><b>:</b> [0.00000]<br>&nbsp; (k=3, : -> NN NN [0.035524])<br><b>NNS</b> [0.00000]<br>&nbsp; (k=3, NNS -> NN NN [0.0224905])<br><b>NNP</b> [0.00000]<br>&nbsp; (k=3, NNP -> NN NN [0.0553666])<br><b>VB</b> [0.00000]<br>&nbsp; (k=3, VB -> NN NN [0.0665623])<br><b>WRB</b> [0.00000]<br>&nbsp; (k=3, WRB -> NN NN [0.0617978])<br><b>CC</b> [0.00000]<br>&nbsp; (k=3, CC -> NN NN [0.12053])<br><b>CD</b> [0.00000]<br>&nbsp; (k=3, CD -> NN NN [0.193739])<br><b>START</b> [0.00000]<br>&nbsp; (k=3, START -> NN NN [0.0444558])<br><b>-NONE-</b> [0.00000]<br>&nbsp; (k=3, -NONE- -> NN NN [0.0189624])<br><b>IN</b> [0.00000]<br>&nbsp; (k=3, IN -> NN NN [0.109567])<br><b>WP$</b> [0.00000]<br>&nbsp; (k=3, WP$ -> NN NN [0.571429])<br><b>NNPS</b> [0.00000]<br>&nbsp; (k=3, NNPS -> NN NN [0.0204918])<br><b>-RRB-</b> [0.00000]<br>&nbsp; (k=3, -RRB- -> NN NN [0.0396825])<br><b>JJS</b> [0.00000]<br>&nbsp; (k=3, JJS -> NN NN [0.28022])<br><b>JJR</b> [0.00000]<br>&nbsp; (k=3, JJR -> NN NN [0.2021])</td></tr><tr><td></td><td></td><td></td><td bgcolor='lightcyan'>[3,4]<br><b>NNS</b> [0.00000]</td><td bgcolor='lightcyan'>[3,5]<br><b>PRP$</b> [0.00000]<br>&nbsp; (k=4, PRP$ -> NNS NNS [0.206266])<br><b>VBG</b> [0.00000]<br>&nbsp; (k=4, VBG -> NNS NNS [0.0945205])<br><b>VBD</b> [0.00000]<br>&nbsp; (k=4, VBD -> NNS NNS [0.0193888])<br><b>``</b> [0.00000]<br>&nbsp; (k=4, `` -> NNS NNS [0.0308989])<br><b>VBN</b> [0.00000]<br>&nbsp; (k=4, VBN -> NNS NNS [0.0360825])<br><b>,</b> [0.00000]<br>&nbsp; (k=4, , -> NNS NNS [0.026402])<br><b>''</b> [0.00000]<br>&nbsp; (k=4, '' -> NNS NNS [0.0201729])<br><b>VBP</b> [0.00000]<br>&nbsp; (k=4, VBP -> NNS NNS [0.0219531])<br><b>WDT</b> [0.00000]<br>&nbsp; (k=4, WDT -> NNS NNS [0.0157303])<br><b>JJ</b> [0.00000]<br>&nbsp; (k=4, JJ -> NNS NNS [0.243744])<br><b>WP</b> [0.00000]<br>&nbsp; (k=4, WP -> NNS NNS [0.00829876])<br><b>VBZ</b> [0.00000]<br>&nbsp; (k=4, VBZ -> NNS NNS [0.0122353])<br><b>DT</b> [0.00000]<br>&nbsp; (k=4, DT -> NNS NNS [0.0774036])<br><b>RP</b> [0.00000]<br>&nbsp; (k=4, RP -> NNS NNS [0.0555556])<br><b>NN</b> [0.00000]<br>&nbsp; (k=4, NN -> NNS NNS [0.0817257])<br><b>POS</b> [0.00000]<br>&nbsp; (k=4, POS -> NNS NNS [0.127427])<br><b>TO</b> [0.00000]<br>&nbsp; (k=4, TO -> NNS NNS [0.0289123])<br><b>PRP</b> [0.00000]<br>&nbsp; (k=4, PRP -> NNS NNS [0.0011655])<br><b>RB</b> [0.00000]<br>&nbsp; (k=4, RB -> NNS NNS [0.00460666])<br><b>-LRB-</b> [0.00000]<br>&nbsp; (k=4, -LRB- -> NNS NNS [0.025])<br><b>:</b> [0.00000]<br>&nbsp; (k=4, : -> NNS NNS [0.0301954])<br><b>NNS</b> [0.00000]<br>&nbsp; (k=4, NNS -> NNS NNS [0.0125682])<br><b>NNP</b> [0.00000]<br>&nbsp; (k=4, NNP -> NNS NNS [0.0226355])<br><b>VB</b> [0.00000]<br>&nbsp; (k=4, VB -> NNS NNS [0.0446359])<br><b>WRB</b> [0.00000]<br>&nbsp; (k=4, WRB -> NNS NNS [0.0674157])<br><b>CC</b> [0.00000]<br>&nbsp; (k=4, CC -> NNS NNS [0.0701987])<br><b>CD</b> [0.00000]<br>&nbsp; (k=4, CD -> NNS NNS [0.14749])<br><b>START</b> [0.00000]<br>&nbsp; (k=4, START -> NNS NNS [0.0467552])<br><b>-NONE-</b> [0.00000]<br>&nbsp; (k=4, -NONE- -> NNS NNS [0.00530947])<br><b>IN</b> [0.00000]<br>&nbsp; (k=4, IN -> NNS NNS [0.0620879])<br><b>WP$</b> [0.00000]<br>&nbsp; (k=4, WP$ -> NNS NNS [0.357143])<br><b>MD</b> [0.00000]<br>&nbsp; (k=4, MD -> NNS NNS [0.00107875])<br><b>NNPS</b> [0.00000]<br>&nbsp; (k=4, NNPS -> NNS NNS [0.00819672])<br><b>JJS</b> [0.00000]<br>&nbsp; (k=4, JJS -> NNS NNS [0.175824])<br><b>JJR</b> [0.00000]<br>&nbsp; (k=4, JJR -> NNS NNS [0.194226])</td></tr><tr><td></td><td></td><td></td><td></td><td bgcolor='lightcyan'>[4,5]<br><b>``</b> [0.00000]<br>&nbsp; (k=None, `` -> END [0.00280899])<br><b>NNPS</b> [0.00000]<br>&nbsp; (k=None, NNPS -> END [0.0204918])<br><b>END</b> [0.00000]<br><b>NN</b> [0.00000]<br>&nbsp; (k=None, NN -> END [0.000455719])<br><b>-RRB-</b> [0.00000]<br>&nbsp; (k=None, -RRB- -> END [0.0634921])<br><b>CD</b> [0.00000]<br>&nbsp; (k=None, CD -> END [0.000564016])<br><b>,</b> [0.00000]<br>&nbsp; (k=None, , -> END [0.000409333])<br><b>.</b> [0.00000]<br>&nbsp; (k=None, . -> END [0.929272])<br><b>''</b> [0.00000]<br>&nbsp; (k=None, '' -> END [0.329971])<br><b>-NONE-</b> [0.00000]<br>&nbsp; (k=None, -NONE- -> END [0.000151699])<br><b>RB</b> [0.00000]<br>&nbsp; (k=None, RB -> END [0.000354359])<br><b>IN</b> [0.00000]<br>&nbsp; (k=None, IN -> END [0.000507254])<br><b>DT</b> [0.00000]<br>&nbsp; (k=None, DT -> END [0.000122474])<br><b>:</b> [0.00000]<br>&nbsp; (k=None, : -> END [0.0763766])<br><b>NNS</b> [0.00000]<br>&nbsp; (k=None, NNS -> END [0.000330743])<br><b>NNP</b> [0.00000]<br>&nbsp; (k=None, NNP -> END [0.000743889])</td></tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do it\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Tree(START, [Tree(START, ['<s>']), Tree(START, [Tree(DT, ['a']), Tree(DT, [Tree(NN, ['dozen']), Tree(NN, [Tree(NNS, ['dinosaurs']), Tree(NNS, [Tree(END, ['</s>'])])])])])])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_CYK('<s> a dozen dinosaurs </s>'.split(), pcfg)\n",
    "#parse_CYK('<s> a </s>'.split(), pcfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Taken from WSTA_N6_probabilistic_parsing\n",
    "import nltk\n",
    "import nltk.grammar\n",
    "from collections import defaultdict\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "def parse_CYK(words, grammar):\n",
    "    table = defaultdict(dict)    \n",
    "    back = defaultdict(dict)\n",
    "    \n",
    "    # righter-most index j\n",
    "    for j in range(1, len(words)+1):\n",
    "        # insert token preterminal rewrites, POS -> 'word'\n",
    "        token = words[j-1]\n",
    "        for prod in grammar.productions(rhs=token):\n",
    "            if len(prod.rhs()) == 1:\n",
    "                table[j-1,j][prod.lhs()] = prod.prob()\n",
    "\n",
    "        # deal with pesky unary productions \n",
    "        changes = True\n",
    "        cell = table[j-1,j]\n",
    "        while changes:\n",
    "            # repeat this loop until no rule changes; will infinitely\n",
    "            # loop for grammars with a unary cycle\n",
    "            changes = False\n",
    "            for non_term in list(cell.keys()):\n",
    "                prob = cell[non_term]\n",
    "                for prod in grammar.productions(rhs=non_term):\n",
    "                    if len(prod.rhs()) == 1:\n",
    "                        unary_prob = prod.prob() * prob\n",
    "                        if unary_prob > cell.get(prod.lhs(), 0):\n",
    "                            cell[prod.lhs()] = unary_prob\n",
    "                            back[j-1,j][prod.lhs()] = (None, prod)\n",
    "                            changes = True\n",
    "        \n",
    "        # now look for larger productions that span [i, j]\n",
    "        # allowing i to move leftward over the input\n",
    "        for i in range(j-2, -1, -1):\n",
    "            cell = table[i,j]\n",
    "            # k is the split point, i < k < j\n",
    "            for k in range(i+1, j):\n",
    "                # find chart cells based on the split point\n",
    "                left_cell = table[i,k]\n",
    "                right_cell = table[k,j]\n",
    "                # find binary productions which handle a valid symbol A from left cell, X -> A B\n",
    "                for left_nt, left_prob in left_cell.items():\n",
    "                    for prod in grammar.productions(rhs=left_nt):\n",
    "                        if len(prod.rhs()) == 2:\n",
    "                            # check if the left and right cells have a valid parse\n",
    "                            right_prob = right_cell.get(prod.rhs()[1])\n",
    "                            if left_prob != None and right_prob != None:\n",
    "                                # score the partial parse\n",
    "                                prob = prod.prob() * left_prob * right_prob\n",
    "                                if prob > cell.get(prod.lhs(), 0.0):\n",
    "                                    # if it exceeds the current best analysis, update the cell\n",
    "                                    cell[prod.lhs()] = prob\n",
    "                                    # and store a record of how we got here\n",
    "                                    back[i,j][prod.lhs()] = (k, prod)\n",
    "    \n",
    "    # display the table and back pointers\n",
    "    display_CYK_chart(words, table, back)\n",
    "    #I added the line below, and commented out the one above\n",
    "    print_sequence(words, table, back)\n",
    "    # have to build the tree from the back pointers\n",
    "    return build_tree(words, back, grammar.start(), i=0, j=len(words))\n",
    "\n",
    "def build_tree(words, back, symbol, i, j):\n",
    "    backpointer = back[i, j].get(symbol)\n",
    "    if backpointer == None:\n",
    "        # X -> 'word' production\n",
    "        assert j == i+1\n",
    "        return nltk.tree.Tree(symbol, [words[i]])\n",
    "    else:\n",
    "        k, prod = back[i, j][symbol]\n",
    "        if k != None:\n",
    "            # X -> A B binary production\n",
    "            left_subtree = build_tree(words, back, prod.rhs()[0], i=i, j=k)\n",
    "            right_subtree = build_tree(words, back, prod.rhs()[1], i=k, j=j)\n",
    "            return nltk.tree.Tree(symbol, [left_subtree, right_subtree])\n",
    "        else:\n",
    "            # X -> A unary production\n",
    "            subtree = build_tree(words, back, prod.rhs()[0], i=i, j=j)\n",
    "            return nltk.tree.Tree(symbol, [subtree])\n",
    "        \n",
    "# From here onwards is my own code, to interact with the above to give the \n",
    "\n",
    "def print_sequence(words, table, back):\n",
    "    print(\"Do it\")\n",
    "    #print back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions:** This approach is pretty slow, which you may notice if you apply your method to much longer senentences. Clearly the CYK algorithm is too general, and thus is not optimised for tagging grammars. Your job is to tailor the CYK algorithm to speed up its tagging performance. Start by pasting in a copy of the PCYK function from the notebook, and then make your edits. Please ensure that you clearly mark the parts you have changed with comments. You are free to sacrifice generality of the algorithm, so that it only works for your style of grammar. Are there aspects of your grammar that can be exploited by small changes to the parsing code? Looking carefully at the parse chart might help you to identify these opporunities. \n",
    "\n",
    "Print out the time of running the original CYK parsing for an example sentence, and the time for your improved method (you may want to use the `timeit` library.) Also print the tag predictions for both parsing methods, to verify that they produce the same results.\n",
    "\n",
    "(1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<tr><td><i><s><i></td><td><i>a<i></td><td><i>dozen<i></td><td><i>dinosaurs<i></td><td><i></s><i></td></tr><tr><td bgcolor='lightcyan'>[0,1]<br><b>START</b> [1.00000]</td><td bgcolor='lightcyan'>[0,2]</td><td bgcolor='lightcyan'>[0,3]</td><td bgcolor='lightcyan'>[0,4]</td><td bgcolor='lightcyan'>[0,5]<br><b>START</b> [0.00000]</td></tr><tr><td></td><td bgcolor='lightcyan'>[1,2]<br><b>NN</b> [0.00000]<br><b>LS</b> [0.00000]<br><b>JJ</b> [0.00000]<br><b>IN</b> [0.00000]<br><b>DT</b> [0.00000]<br><b>NNP</b> [0.00000]</td><td bgcolor='lightcyan'>[1,3]</td><td bgcolor='lightcyan'>[1,4]</td><td bgcolor='lightcyan'>[1,5]<br><b>PRP$</b> [0.00000]<br><b>VBG</b> [0.00000]<br><b>VBD</b> [0.00000]<br><b>``</b> [0.00000]<br><b>VBN</b> [0.00000]<br><b>,</b> [0.00000]<br><b>''</b> [0.00000]<br><b>VBP</b> [0.00000]<br><b>WDT</b> [0.00000]<br><b>JJ</b> [0.00000]<br><b>WP</b> [0.00000]<br><b>VBZ</b> [0.00000]<br><b>DT</b> [0.00000]<br><b>RP</b> [0.00000]<br><b>$</b> [0.00000]<br><b>NN</b> [0.00000]<br><b>FW</b> [0.00000]<br><b>POS</b> [0.00000]<br><b>.</b> [0.00000]<br><b>TO</b> [0.00000]<br><b>PRP</b> [0.00000]<br><b>RB</b> [0.00000]<br><b>-LRB-</b> [0.00000]<br><b>:</b> [0.00000]<br><b>NNS</b> [0.00000]<br><b>NNP</b> [0.00000]<br><b>VB</b> [0.00000]<br><b>WRB</b> [0.00000]<br><b>CC</b> [0.00000]<br><b>PDT</b> [0.00000]<br><b>RBS</b> [0.00000]<br><b>RBR</b> [0.00000]<br><b>CD</b> [0.00000]<br><b>START</b> [0.00000]<br><b>-NONE-</b> [0.00000]<br><b>IN</b> [0.00000]<br><b>WP$</b> [0.00000]<br><b>MD</b> [0.00000]<br><b>NNPS</b> [0.00000]<br><b>-RRB-</b> [0.00000]<br><b>JJS</b> [0.00000]<br><b>JJR</b> [0.00000]<br><b>SYM</b> [0.00000]<br><b>UH</b> [0.00000]</td></tr><tr><td></td><td></td><td bgcolor='lightcyan'>[2,3]<br><b>NN</b> [0.00000]</td><td bgcolor='lightcyan'>[2,4]</td><td bgcolor='lightcyan'>[2,5]<br><b>PRP$</b> [0.00000]<br><b>VBG</b> [0.00000]<br><b>VBD</b> [0.00000]<br><b>``</b> [0.00000]<br><b>VBN</b> [0.00000]<br><b>,</b> [0.00000]<br><b>''</b> [0.00000]<br><b>VBP</b> [0.00000]<br><b>WDT</b> [0.00000]<br><b>JJ</b> [0.00000]<br><b>WP</b> [0.00000]<br><b>VBZ</b> [0.00000]<br><b>DT</b> [0.00000]<br><b>RP</b> [0.00000]<br><b>NN</b> [0.00000]<br><b>FW</b> [0.00000]<br><b>POS</b> [0.00000]<br><b>.</b> [0.00000]<br><b>TO</b> [0.00000]<br><b>PRP</b> [0.00000]<br><b>RB</b> [0.00000]<br><b>-LRB-</b> [0.00000]<br><b>:</b> [0.00000]<br><b>NNS</b> [0.00000]<br><b>NNP</b> [0.00000]<br><b>VB</b> [0.00000]<br><b>WRB</b> [0.00000]<br><b>CC</b> [0.00000]<br><b>CD</b> [0.00000]<br><b>START</b> [0.00000]<br><b>-NONE-</b> [0.00000]<br><b>IN</b> [0.00000]<br><b>WP$</b> [0.00000]<br><b>NNPS</b> [0.00000]<br><b>-RRB-</b> [0.00000]<br><b>JJS</b> [0.00000]<br><b>JJR</b> [0.00000]</td></tr><tr><td></td><td></td><td></td><td bgcolor='lightcyan'>[3,4]<br><b>NNS</b> [0.00000]</td><td bgcolor='lightcyan'>[3,5]<br><b>PRP$</b> [0.00000]<br><b>VBG</b> [0.00000]<br><b>VBD</b> [0.00000]<br><b>``</b> [0.00000]<br><b>VBN</b> [0.00000]<br><b>,</b> [0.00000]<br><b>''</b> [0.00000]<br><b>VBP</b> [0.00000]<br><b>WDT</b> [0.00000]<br><b>JJ</b> [0.00000]<br><b>WP</b> [0.00000]<br><b>VBZ</b> [0.00000]<br><b>DT</b> [0.00000]<br><b>RP</b> [0.00000]<br><b>NN</b> [0.00000]<br><b>POS</b> [0.00000]<br><b>TO</b> [0.00000]<br><b>PRP</b> [0.00000]<br><b>RB</b> [0.00000]<br><b>-LRB-</b> [0.00000]<br><b>:</b> [0.00000]<br><b>NNS</b> [0.00000]<br><b>NNP</b> [0.00000]<br><b>VB</b> [0.00000]<br><b>WRB</b> [0.00000]<br><b>CC</b> [0.00000]<br><b>CD</b> [0.00000]<br><b>START</b> [0.00000]<br><b>-NONE-</b> [0.00000]<br><b>IN</b> [0.00000]<br><b>WP$</b> [0.00000]<br><b>MD</b> [0.00000]<br><b>NNPS</b> [0.00000]<br><b>JJS</b> [0.00000]<br><b>JJR</b> [0.00000]</td></tr><tr><td></td><td></td><td></td><td></td><td bgcolor='lightcyan'>[4,5]<br><b>``</b> [0.00000]<br>&nbsp; (k=None, `` -> END [0.00280899])<br><b>NNPS</b> [0.00000]<br>&nbsp; (k=None, NNPS -> END [0.0204918])<br><b>END</b> [0.00000]<br><b>NN</b> [0.00000]<br>&nbsp; (k=None, NN -> END [0.000455719])<br><b>-RRB-</b> [0.00000]<br>&nbsp; (k=None, -RRB- -> END [0.0634921])<br><b>CD</b> [0.00000]<br>&nbsp; (k=None, CD -> END [0.000564016])<br><b>,</b> [0.00000]<br>&nbsp; (k=None, , -> END [0.000409333])<br><b>.</b> [0.00000]<br>&nbsp; (k=None, . -> END [0.929272])<br><b>''</b> [0.00000]<br>&nbsp; (k=None, '' -> END [0.329971])<br><b>-NONE-</b> [0.00000]<br>&nbsp; (k=None, -NONE- -> END [0.000151699])<br><b>RB</b> [0.00000]<br>&nbsp; (k=None, RB -> END [0.000354359])<br><b>IN</b> [0.00000]<br>&nbsp; (k=None, IN -> END [0.000507254])<br><b>DT</b> [0.00000]<br>&nbsp; (k=None, DT -> END [0.000122474])<br><b>:</b> [0.00000]<br>&nbsp; (k=None, : -> END [0.0763766])<br><b>NNS</b> [0.00000]<br>&nbsp; (k=None, NNS -> END [0.000330743])<br><b>NNP</b> [0.00000]<br>&nbsp; (k=None, NNP -> END [0.000743889])</td></tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-249-705beb1edc19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparse_CYK_improved\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<s> a dozen dinosaurs </s>'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#parse_CYK_improved('<s> a dozen dinosaurs debate deals for daily dessert delivery . </s>'.split(), pcfg)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-248-746feb12a1a4>\u001b[0m in \u001b[0;36mparse_CYK_improved\u001b[0;34m(words, grammar)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mdisplay_CYK_chart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrammar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mparse_CYK_improved\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<s> a dozen </s>'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-186-b28ea693bd10>\u001b[0m in \u001b[0;36mbuild_tree\u001b[0;34m(words, back, symbol, i, j)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbackpointer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# X -> 'word' production\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parse_CYK_improved('<s> a dozen dinosaurs </s>'.split(), pcfg)\n",
    "#parse_CYK_improved('<s> a dozen dinosaurs debate deals for daily dessert delivery . </s>'.split(), pcfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<tr><td><i><s><i></td><td><i>a<i></td><td><i>dozen<i></td><td><i></s><i></td></tr><tr><td bgcolor='lightcyan'>[0,1]<br><b>START</b> [1.00000]</td><td bgcolor='lightcyan'>[0,2]</td><td bgcolor='lightcyan'>[0,3]</td><td bgcolor='lightcyan'>[0,4]<br><b>START</b> [0.00000]</td></tr><tr><td></td><td bgcolor='lightcyan'>[1,2]<br><b>NN</b> [0.00000]<br><b>LS</b> [0.00000]<br><b>JJ</b> [0.00000]<br><b>IN</b> [0.00000]<br><b>DT</b> [0.00000]<br><b>NNP</b> [0.00000]</td><td bgcolor='lightcyan'>[1,3]</td><td bgcolor='lightcyan'>[1,4]<br><b>PRP$</b> [0.00000]<br><b>VBG</b> [0.00000]<br><b>VBD</b> [0.00000]<br><b>``</b> [0.00000]<br><b>VBN</b> [0.00000]<br><b>,</b> [0.00000]<br><b>''</b> [0.00000]<br><b>VBP</b> [0.00000]<br><b>WDT</b> [0.00000]<br><b>JJ</b> [0.00000]<br><b>WP</b> [0.00000]<br><b>VBZ</b> [0.00000]<br><b>DT</b> [0.00000]<br><b>RP</b> [0.00000]<br><b>$</b> [0.00000]<br><b>NN</b> [0.00000]<br><b>FW</b> [0.00000]<br><b>POS</b> [0.00000]<br><b>.</b> [0.00000]<br><b>TO</b> [0.00000]<br><b>PRP</b> [0.00000]<br><b>RB</b> [0.00000]<br><b>-LRB-</b> [0.00000]<br><b>:</b> [0.00000]<br><b>NNS</b> [0.00000]<br><b>NNP</b> [0.00000]<br><b>VB</b> [0.00000]<br><b>WRB</b> [0.00000]<br><b>CC</b> [0.00000]<br><b>PDT</b> [0.00000]<br><b>RBS</b> [0.00000]<br><b>RBR</b> [0.00000]<br><b>CD</b> [0.00000]<br><b>START</b> [0.00000]<br><b>-NONE-</b> [0.00000]<br><b>IN</b> [0.00000]<br><b>WP$</b> [0.00000]<br><b>MD</b> [0.00000]<br><b>NNPS</b> [0.00000]<br><b>-RRB-</b> [0.00000]<br><b>JJS</b> [0.00000]<br><b>JJR</b> [0.00000]<br><b>SYM</b> [0.00000]<br><b>UH</b> [0.00000]</td></tr><tr><td></td><td></td><td bgcolor='lightcyan'>[2,3]<br><b>NN</b> [0.00000]</td><td bgcolor='lightcyan'>[2,4]<br><b>PRP$</b> [0.00000]<br><b>VBG</b> [0.00000]<br><b>VBD</b> [0.00000]<br><b>``</b> [0.00000]<br><b>VBN</b> [0.00000]<br><b>,</b> [0.00000]<br><b>''</b> [0.00000]<br><b>VBP</b> [0.00000]<br><b>WDT</b> [0.00000]<br><b>JJ</b> [0.00000]<br><b>WP</b> [0.00000]<br><b>VBZ</b> [0.00000]<br><b>DT</b> [0.00000]<br><b>RP</b> [0.00000]<br><b>NN</b> [0.00000]<br><b>FW</b> [0.00000]<br><b>POS</b> [0.00000]<br><b>.</b> [0.00000]<br><b>TO</b> [0.00000]<br><b>PRP</b> [0.00000]<br><b>RB</b> [0.00000]<br><b>-LRB-</b> [0.00000]<br><b>:</b> [0.00000]<br><b>NNS</b> [0.00000]<br><b>NNP</b> [0.00000]<br><b>VB</b> [0.00000]<br><b>WRB</b> [0.00000]<br><b>CC</b> [0.00000]<br><b>CD</b> [0.00000]<br><b>START</b> [0.00000]<br><b>-NONE-</b> [0.00000]<br><b>IN</b> [0.00000]<br><b>WP$</b> [0.00000]<br><b>NNPS</b> [0.00000]<br><b>-RRB-</b> [0.00000]<br><b>JJS</b> [0.00000]<br><b>JJR</b> [0.00000]</td></tr><tr><td></td><td></td><td></td><td bgcolor='lightcyan'>[3,4]<br><b>``</b> [0.00000]<br>&nbsp; (k=None, `` -> END [0.00280899])<br><b>NNPS</b> [0.00000]<br>&nbsp; (k=None, NNPS -> END [0.0204918])<br><b>END</b> [0.00000]<br><b>NN</b> [0.00000]<br>&nbsp; (k=None, NN -> END [0.000455719])<br><b>-RRB-</b> [0.00000]<br>&nbsp; (k=None, -RRB- -> END [0.0634921])<br><b>CD</b> [0.00000]<br>&nbsp; (k=None, CD -> END [0.000564016])<br><b>,</b> [0.00000]<br>&nbsp; (k=None, , -> END [0.000409333])<br><b>.</b> [0.00000]<br>&nbsp; (k=None, . -> END [0.929272])<br><b>''</b> [0.00000]<br>&nbsp; (k=None, '' -> END [0.329971])<br><b>-NONE-</b> [0.00000]<br>&nbsp; (k=None, -NONE- -> END [0.000151699])<br><b>RB</b> [0.00000]<br>&nbsp; (k=None, RB -> END [0.000354359])<br><b>IN</b> [0.00000]<br>&nbsp; (k=None, IN -> END [0.000507254])<br><b>DT</b> [0.00000]<br>&nbsp; (k=None, DT -> END [0.000122474])<br><b>:</b> [0.00000]<br>&nbsp; (k=None, : -> END [0.0763766])<br><b>NNS</b> [0.00000]<br>&nbsp; (k=None, NNS -> END [0.000330743])<br><b>NNP</b> [0.00000]<br>&nbsp; (k=None, NNP -> END [0.000743889])</td></tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-248-746feb12a1a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrammar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mparse_CYK_improved\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<s> a dozen </s>'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-248-746feb12a1a4>\u001b[0m in \u001b[0;36mparse_CYK_improved\u001b[0;34m(words, grammar)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mdisplay_CYK_chart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrammar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mparse_CYK_improved\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<s> a dozen </s>'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-186-b28ea693bd10>\u001b[0m in \u001b[0;36mbuild_tree\u001b[0;34m(words, back, symbol, i, j)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbackpointer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# X -> 'word' production\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Doubling the sentence length took a noticably longer time.\n",
    "# Lets take advantage of the grammar structure\n",
    "# Ie, as shown in the tree above, the HMM parsing will be a long tree, with one split to a non terminal at each level, \n",
    "# with the other going deeper\n",
    "\n",
    "# So, we only need to look at certain productions on the chart\n",
    "# Ie, once we have filled in all the non terminals, there is only one way to go\n",
    "# Which is straight along the top of the chart :D\n",
    "\n",
    "def parse_CYK_improved(words, grammar):\n",
    "    table = defaultdict(dict)    \n",
    "    back = defaultdict(dict)\n",
    "    \n",
    "    # righter-most index j\n",
    "    for j in range(1, len(words)+1):\n",
    "        # insert token preterminal rewrites, POS -> 'word'\n",
    "        token = words[j-1]\n",
    "        for prod in grammar.productions(rhs=token):\n",
    "            if len(prod.rhs()) == 1:\n",
    "                table[j-1,j][prod.lhs()] = prod.prob()\n",
    "        # deal with pesky unary productions \n",
    "        changes = True\n",
    "        cell = table[j-1,j]\n",
    "        while changes:\n",
    "            # repeat this loop until no rule changes; will infinitely\n",
    "            # loop for grammars with a unary cycle\n",
    "            changes = False\n",
    "            for non_term in list(cell.keys()):\n",
    "                prob = cell[non_term]\n",
    "                for prod in grammar.productions(rhs=non_term):\n",
    "                    if len(prod.rhs()) == 1:\n",
    "                        unary_prob = prod.prob() * prob\n",
    "                        if unary_prob > cell.get(prod.lhs(), 0):\n",
    "                            cell[prod.lhs()] = unary_prob\n",
    "                            back[j-1,j][prod.lhs()] = (None, prod)\n",
    "                            changes = True\n",
    "\n",
    "        \n",
    "    # So, now all the non terminals are dealt with :D\n",
    "    #display_CYK_chart(words, table, back)\n",
    "    \n",
    "    for j in range (0, len(words) - 1) :\n",
    "        \n",
    "        left_cell = table[len(words) - (j+2),len(words) - (j+1)]\n",
    "        #print left_cell\n",
    "        right_cell = table[len(words) - (j+1),len(words)]\n",
    "        #print right_cell\n",
    "        cell = table[len(words) - (j+2),len(words)] #FIX\n",
    "        # find binary productions which handle a valid symbol A from left cell, X -> A B\n",
    "        \n",
    "        for left_nt, left_prob in left_cell.items():\n",
    "            for prod in grammar.productions(rhs=left_nt):\n",
    "                if len(prod.rhs()) == 2:\n",
    "                    # check if the left and right cells have a valid parse\n",
    "                    right_prob = right_cell.get(prod.rhs()[1])\n",
    "                    if left_prob != None and right_prob != None:\n",
    "                        \n",
    "                        # score the partial parse\n",
    "                        prob = prod.prob() * left_prob * right_prob\n",
    "                        if prob > cell.get(prod.lhs(), 0.0):\n",
    "                            # if it exceeds the current best analysis, update the cell\n",
    "                            cell[prod.lhs()] = prob\n",
    "                            # and store a record of how we got here\n",
    "                            back[i,j][prod.lhs()] = (len(words) - (1+j), prod) #FIX!\n",
    "        \n",
    "    display_CYK_chart(words, table, back)\n",
    "    return build_tree(words, back, grammar.start(), i=0, j=len(words))\n",
    "    \n",
    "parse_CYK_improved('<s> a dozen </s>'.split(), pcfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do it\n",
      "0.545074939728\n",
      "0.561192989349\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "parse_CYK('<s> a dozen dinosaurs debate deals for daily dessert delivery . </s>'.split(), pcfg)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "start = time.time()\n",
    "parse_CYK_improved('<s> a dozen dinosaurs debate deals for daily dessert delivery . </s>'.split(), pcfg)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: higher-order tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction:** Implement second order HMM tagger where the transition distribution considers the previous two tags as context, $p(t_i|t_{i-2},t_{i-1})$, in place of the single previous tag in the first order HMM. Feel free to go to even higher orders. You will have to be careful with low count events, as some perfectly valid sequences of three tags may not have been seen in training, so some smoothing will be needed. One simple method is to average the 1st order and 2nd order estimates, i.e., using for transition parameters $0.5 \\times p(t_i|t_{i-2},t_{i-1}) + 0.5 \\times p(t_i|t_{i-1})$. Your implementation should implement this HMM as an equivalent PCFG grammar, which you validate over the test sentence above (or other sentences you make up; but see OOV discussion below). \n",
    "\n",
    "(1 bonus mark) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A final word\n",
    "\n",
    "HMMs are not usually implemented as PCFGs, in practice. Instead more tailored and optimised algorithms are used which are specific to the HMM. This homework aims to emphasise the similarities between the two approaches, and elucidate the link between the CYK and Viterbi algorithms.\n",
    "\n",
    "Another important aspect is handling out-of-vocabulary words OOVs, i.e., words encountered in testing but not seen in training. The test sentence above was constructed to avoid this issue, and I suggest that if you test with other sentences, that you keep to the training vocabulary. Dealing with OOVs is out of scope, for now, although we will discuss how these can be handled in various contexts later in the subject."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
