{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in the python script containing the same code as the load the data notebook\n",
    "%run loadData.py\n",
    "# now we can access train, dev, and test\n",
    "# along with trainSents, devSents testSents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Phonograph records are generally described by their diameter in inches (12\", 10\", 7\"), the rotational speed in rpm at which they are played (16 2\\u20443, 33 1\\u20443, 45, 78), and their time capacity resulting from a combination of those parameters (LP \\u2013 long playing 33 1\\u20443 rpm, SP \\u2013 78 rpm single, EP \\u2013 12-inch single or extended play, 33 or 45 rpm); their reproductive quality or level of fidelity (high-fidelity, orthophonic, full-range, etc.), and the number of audio channels provided (mono, stereo, quad, etc.).'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSents[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'answer': u'long playing',\n",
       " u'answer_sentence': 2,\n",
       " u'question': u'What does LP stand for when it comes to time capacity?'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = trainSents[0]\n",
    "questions = train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared Workflow Thoughts (dealing with .ipynb notebooks)\n",
    "\n",
    "Think with each feature we do below, create generalized functions that can be easily composed with easy names, split by type.\n",
    "\n",
    "Then create/use small demo template below using the locked document/questions above to get intuition, check sanity, iterate quickly, to help keep us all on the same page.\n",
    "\n",
    "This way we keep everything well contained/documented/explainable, will help with report writing.\n",
    "\n",
    "Then in separate notebook we do statistical valid/testing for error exploration/analysis, using generalized functions above - easily changeable/copyable.\n",
    "\n",
    "Finally put it all in a python file that will do full run. Write TODOs to illustrate next steps/improvements, that way can stay on top/track/improve upon easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Retreival\n",
    "\n",
    "The first part of your basic QA system will use a bag-of-words (BOW) vector space model to identify the sentence in the Wikipedia article which is most likely to contain the answer to a question, using standard information retrieval techniques. Here the \"query\" is the question, the \"documents\" are actually sentences, and each Wikipedia article should be viewed as separate \"document collection\". You should apply various preprocessing steps appropriate to this situation, including term weighting; if you are at all uncertain about what choices to make, you should evaluate them using the dev data, and use the results to justify your choice in your report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TODO\n",
    "\n",
    "* Improving tuning of preprocessing/lemmatize functions for use QA case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tuning functions\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Follow lemmatize function from guide notebook: WSTA_N1B_preprocessing.ipynb\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(word):\n",
    "    lemma = lemmatizer.lemmatize(word,'v')\n",
    "    if lemma == word:\n",
    "        lemma = lemmatizer.lemmatize(word,'n')\n",
    "    return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Core functions\n",
    "\n",
    "def vectorize_documents(text_documents):\n",
    "\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    vector_documents = vectorizer.fit_transform(text_documents)\n",
    "    \n",
    "    return [vector_documents, vectorizer]\n",
    "\n",
    "def vectorize_query(vectorizer, text_query):\n",
    "    return vectorizer.transform([text_query])\n",
    "\n",
    "def process_neighbours(vector_documents):\n",
    "    \n",
    "    neighbours = NearestNeighbors(1, algorithm=\"brute\", metric=\"cosine\")\n",
    "    neighbours.fit(vector_documents)\n",
    "    \n",
    "    return neighbours\n",
    "\n",
    "def closest_document(neighbours, vector_query):\n",
    "\n",
    "    result = neighbours.kneighbors(vector_query, 1, return_distance=True)\n",
    "\n",
    "    result_index = result[1][0][0]\n",
    "    result_similarity = result[0][0][0]\n",
    "    \n",
    "    return [result_similarity, result_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Demonstration function\n",
    "\n",
    "def demo_process_set(questions, documents):\n",
    "    \n",
    "    vector_documents, vectorizer = vectorize_documents(documents)\n",
    "    analyze = vectorizer.build_analyzer()\n",
    "    neighbours = process_neighbours(vector_documents)\n",
    "\n",
    "    print \"=\" * 20\n",
    "    print \"Vector documents shape: {0}\".format(vector_documents.shape)\n",
    "    print \"Actual documents length: {0}\".format(len(documents))\n",
    "    print \"=\" * 20, \"\\n\"\n",
    "    \n",
    "    for question in questions[10:10+3]:\n",
    "        \n",
    "        text_query = question[\"question\"]\n",
    "\n",
    "        print \"Text query:\\n\\n\\t{0}\\n\".format(text_query)\n",
    "\n",
    "        vector_query = vectorize_query(vectorizer, text_query)\n",
    "\n",
    "        print \"Vector query shape:\\n\\n\\t{0}\".format(vector_query.shape)\n",
    "\n",
    "        result_similarity, result_index  = closest_document(neighbours, vector_query)\n",
    "        \n",
    "        print\n",
    "\n",
    "        print \"Result:\\n\\n\\tSimilarity ({0}), Index ({1})\\n\".format(result_similarity, result_index)\n",
    "\n",
    "        print\n",
    "\n",
    "        print \"Query (text):\\n\\n\\t{0}\\n\".format(text_query)\n",
    "        print \"Document (text):\\n\\n\\t{0}\".format(documents[result_index].encode(\"utf-8\"))\n",
    "\n",
    "        print\n",
    "\n",
    "        print \"Query (vector text):\\n\"\n",
    "        pp.pprint(analyze(text_query))\n",
    "        print\n",
    "        \n",
    "        print \"Document (vector text): \\n\\n\"\n",
    "        pp.pprint(analyze(documents[result_index]))\n",
    "        \n",
    "        print \"\\n\", \"=\" * 20, \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Vector documents shape: (463, 2425)\n",
      "Actual documents length: 463\n",
      "==================== \n",
      "\n",
      "Text query:\n",
      "\n",
      "\tWhat was the original intent of the phonautograph?\n",
      "\n",
      "Vector query shape:\n",
      "\n",
      "\t(1, 2425)\n",
      "\n",
      "Result:\n",
      "\n",
      "\tSimilarity (0.72338690096), Index (9)\n",
      "\n",
      "\n",
      "Query (text):\n",
      "\n",
      "\tWhat was the original intent of the phonautograph?\n",
      "\n",
      "Document (text):\n",
      "\n",
      "\tThe phonautograph, patented by LÃ©on Scott in 1857, used a vibrating diaphragm and stylus to graphically record sound waves as tracings on sheets of paper, purely for visual analysis and without any intent of playing them back.\n",
      "\n",
      "Query (vector text):\n",
      "\n",
      "[u'original', u'intent', u'phonautograph']\n",
      "\n",
      "Document (vector text): \n",
      "\n",
      "\n",
      "[   u'phonautograph',\n",
      "    u'patented',\n",
      "    u'l\\xe9on',\n",
      "    u'scott',\n",
      "    u'1857',\n",
      "    u'used',\n",
      "    u'vibrating',\n",
      "    u'diaphragm',\n",
      "    u'stylus',\n",
      "    u'graphically',\n",
      "    u'record',\n",
      "    u'sound',\n",
      "    u'waves',\n",
      "    u'tracings',\n",
      "    u'sheets',\n",
      "    u'paper',\n",
      "    u'purely',\n",
      "    u'visual',\n",
      "    u'analysis',\n",
      "    u'intent',\n",
      "    u'playing']\n",
      "\n",
      "==================== \n",
      "\n",
      "Text query:\n",
      "\n",
      "\tIn what years where phonautograms converted to audible sound?\n",
      "\n",
      "Vector query shape:\n",
      "\n",
      "\t(1, 2425)\n",
      "\n",
      "Result:\n",
      "\n",
      "\tSimilarity (0.608183037117), Index (10)\n",
      "\n",
      "\n",
      "Query (text):\n",
      "\n",
      "\tIn what years where phonautograms converted to audible sound?\n",
      "\n",
      "Document (text):\n",
      "\n",
      "\tIn the 2000s, these tracings were first scanned by audio engineers and digitally converted into audible sound.\n",
      "\n",
      "Query (vector text):\n",
      "\n",
      "[u'years', u'phonautograms', u'converted', u'audible', u'sound']\n",
      "\n",
      "Document (vector text): \n",
      "\n",
      "\n",
      "[   u'2000s',\n",
      "    u'tracings',\n",
      "    u'scanned',\n",
      "    u'audio',\n",
      "    u'engineers',\n",
      "    u'digitally',\n",
      "    u'converted',\n",
      "    u'audible',\n",
      "    u'sound']\n",
      "\n",
      "==================== \n",
      "\n",
      "Text query:\n",
      "\n",
      "\tWhat year were the earliest known recordings of sound?\n",
      "\n",
      "Vector query shape:\n",
      "\n",
      "\t(1, 2425)\n",
      "\n",
      "Result:\n",
      "\n",
      "\tSimilarity (0.60589739321), Index (12)\n",
      "\n",
      "\n",
      "Query (text):\n",
      "\n",
      "\tWhat year were the earliest known recordings of sound?\n",
      "\n",
      "Document (text):\n",
      "\n",
      "\tAlong with a tuning fork tone and unintelligible snippets recorded as early as 1857, these are the earliest known recordings of sound.\n",
      "\n",
      "Query (vector text):\n",
      "\n",
      "[u'year', u'earliest', u'known', u'recordings', u'sound']\n",
      "\n",
      "Document (vector text): \n",
      "\n",
      "\n",
      "[   u'tuning',\n",
      "    u'fork',\n",
      "    u'tone',\n",
      "    u'unintelligible',\n",
      "    u'snippets',\n",
      "    u'recorded',\n",
      "    u'early',\n",
      "    u'1857',\n",
      "    u'earliest',\n",
      "    u'known',\n",
      "    u'recordings',\n",
      "    u'sound']\n",
      "\n",
      "==================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "demo_process_set(questions, documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TODO\n",
    "\n",
    "* TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TODO\n",
    "\n",
    "* TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
