{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in the python script containing the same code as the load the data notebook\n",
    "%run loadData.py\n",
    "# now we can access train, dev, and test\n",
    "# along with trainSents, devSents testSents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shim names for later clean\n",
    "\n",
    "train_question_set = train\n",
    "train_document_set = trainSents\n",
    "\n",
    "dev_question_set = dev\n",
    "dev_document_set = devSents\n",
    "\n",
    "test_question_set = test\n",
    "test_document_set = testSents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rapid_size = 1\n",
    "\n",
    "rapid_question_set = train_question_set[:rapid_size]\n",
    "rapid_document_set = train_document_set[:rapid_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shim for easier name spacing\n",
    "\n",
    "DATA = {\n",
    "    \"rapid\" : {\n",
    "            \"question_set\": rapid_question_set,\n",
    "            \"document_set\": rapid_document_set,\n",
    "    },\n",
    "    \"train\" : {\n",
    "            \"question_set\": train_question_set,\n",
    "            \"document_set\": train_document_set,\n",
    "    },\n",
    "    \"dev\" : {\n",
    "            \"question_set\": dev_question_set,\n",
    "            \"document_set\": dev_document_set,\n",
    "    },\n",
    "    \"test\" : {\n",
    "            \"question_set\": test_question_set,\n",
    "            \"document_set\": test_document_set,\n",
    "    }    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from string import punctuation  \n",
    "\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import csv\n",
    "\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Core functions\n",
    "\n",
    "classifier = './stanford/classifiers/english.all.3class.distsim.crf.ser.gz'\n",
    "jar = './stanford/stanford-ner.jar'\n",
    "\n",
    "sTagger = StanfordNERTagger(classifier,jar)\n",
    "\n",
    "punct_tokens = set(punctuation)\n",
    "extra_tokens = set([\"what\", \"where\", \"how\", \"when\", \"who\"])\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filter_tokens = extra_tokens.union(punct_tokens).union(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location = ['where','what place',u'where is', u'what country',u'along with', u'where are',u'on what', u'what city', u'in the', u'where did','where']\n",
    "number = [u'how many',u'how much','when','what year',u'when did', u'what year', u'when was',u'how long',u'when were', 'when']\n",
    "person = [u'who was', u'who is', u'which contestant',u'who wrote', u'who said', u'who did', u'who has', u'who played','who','whom','who',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getQuestionType(question):\n",
    "    \n",
    "    # fix: speed up\n",
    "    \n",
    "    question = question.lower()\n",
    "    \n",
    "    for ele in person:\n",
    "        if ele in question:\n",
    "            return 'PERSON'\n",
    "    for ele in  location:                       \n",
    "        if ele in question:\n",
    "            return 'LOCATION'\n",
    "    for ele in  number:  \n",
    "        if ele in question:\n",
    "            return 'NUMBER'\n",
    "    return 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Shim function for later clean\n",
    "\n",
    "def getStanfordTagging(datasetName):\n",
    "    fnameTrain = './preCompTags/stanfordTaggedTrain.txt'\n",
    "    fnameDev = './preCompTags/stanfordTaggedDev.txt'\n",
    "    fnameTest = './preCompTags/stanfordTaggedTest.txt'\n",
    "    \n",
    "    theFilePath = ''\n",
    "    theSents = []\n",
    "    if (datasetName == 'train'):\n",
    "        theFilePath = fnameTrain\n",
    "        theSents = trainSents\n",
    "    elif (datasetName == 'dev'):\n",
    "        theFilePath = fnameDev\n",
    "        theSents = devSents\n",
    "    elif (datasetName == 'test'):\n",
    "        theFilePath = fnameTest\n",
    "        theSents = testSents\n",
    "    else :\n",
    "        raise ValueError('Incorrect datasetName: ' + datasetName + ', choose from - \"train\", \"dev\", \"test\" ') \n",
    "    if (os.path.exists(theFilePath)):\n",
    "        with open(theFilePath, \"rb\") as fp:\n",
    "            stanfordTags = pickle.load(fp)\n",
    "            return stanfordTags\n",
    "    \n",
    "    else :\n",
    "        #Need to create taggings!\n",
    "        taggedSentsList = []\n",
    "        for sents in theSents:\n",
    "            tokenisedSents = [word_tokenize(sent) for sent in sents]\n",
    "            classifiedSents = sTagger.tag_sents(tokenisedSents)\n",
    "            taggedSentsList.append(classifiedSents)\n",
    "        #And save them\n",
    "        with open(theFilePath, \"wb\") as fp: \n",
    "            pickle.dump(taggedSentsList, fp)\n",
    "        return taggedSentsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_train_set = getStanfordTagging('train')\n",
    "tagged_dev_set = getStanfordTagging('dev')\n",
    "tagged_test_set = getStanfordTagging('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_rapid_set = tagged_train_set[:rapid_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shim for easier name spacing\n",
    "\n",
    "DATA[\"rapid\"][\"tagged_set\"] = tagged_rapid_set\n",
    "DATA[\"train\"][\"tagged_set\"] = tagged_train_set\n",
    "DATA[\"dev\"][\"tagged_set\"] = tagged_dev_set\n",
    "DATA[\"test\"][\"tagged_set\"] = tagged_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From: WSTA_N10_word_vectors\n",
    "\n",
    "import gensim\n",
    "from nltk.data import find\n",
    "\n",
    "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))\n",
    "word2vec_model = gensim.models.Word2Vec.load_word2vec_format(word2vec_sample, binary=False) # Use this if newer gensim: gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing tuning functions\n",
    "\n",
    "# Follow lemmatize function from guide notebook: WSTA_N1B_preprocessing.ipynb\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "word_tokenizer = nltk.tokenize.WordPunctTokenizer() #word_tokenize #tokenize.regexp.WordPunctTokenizer()\n",
    "\n",
    "def lemmatize(word):\n",
    "    lemma = lemmatizer.lemmatize(word,'v')\n",
    "    if lemma == word:\n",
    "        lemma = lemmatizer.lemmatize(word,'n')\n",
    "    return lemma\n",
    "\n",
    "def pre_process_tf_idf(line):\n",
    "    tokenized_sentence = word_tokenizer.tokenize(line.lower())\n",
    "    lemmatized_sentence = [lemmatize(token) for token in tokenized_sentence]\n",
    "    filtered_sentence = [token for token in lemmatized_sentence if token not in filter_tokens]\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Core functions\n",
    "\n",
    "def vectorize_documents(text_documents):\n",
    "\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', tokenizer=pre_process_tf_idf)\n",
    "    vector_documents = vectorizer.fit_transform(text_documents)\n",
    "    \n",
    "    return [vector_documents, vectorizer]\n",
    "\n",
    "def vectorize_query(vectorizer, text_query):\n",
    "    return vectorizer.transform([text_query])\n",
    "\n",
    "def process_neighbours(vector_documents):\n",
    "    \n",
    "    neighbours = NearestNeighbors(1, algorithm=\"brute\", metric=\"cosine\")\n",
    "    neighbours.fit(vector_documents)\n",
    "    \n",
    "    return neighbours\n",
    "\n",
    "def closest_document(neighbours, vector_query):\n",
    "\n",
    "    result = neighbours.kneighbors(vector_query, 1, return_distance=True)\n",
    "\n",
    "    result_index = result[1][0][0]\n",
    "    result_distance = result[0][0][0]\n",
    "    \n",
    "    return [result_distance, result_index]\n",
    "\n",
    "def closest_documents(neighbours, vector_query, n):\n",
    "\n",
    "    result = neighbours.kneighbors(vector_query, n, return_distance=True)\n",
    "\n",
    "    result_indices = result[1][0]\n",
    "    result_distances = result[0][0]\n",
    "    \n",
    "    return sorted(zip(result_indices, result_distances), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model, datasets    \n",
    "from sklearn import cross_validation \n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_results(predictions, classifications):\n",
    "    print \"Accuracy: \", accuracy_score(classifications, predictions)\n",
    "    print classification_report(classifications, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(name, data) :\n",
    "\n",
    "    vec = DATA[name][\"X_vec\"]\n",
    "    X = DATA[name][\"X\"]\n",
    "    Y = DATA[name][\"Y\"]\n",
    "\n",
    "    clf = linear_model.LogisticRegression(C=1e5)\n",
    "#     clf = AdaBoostClassifier(n_estimators=100)\n",
    "#     clf = RandomForestClassifier(n_estimators=10)\n",
    "    #clf = svm.SVC()\n",
    "#     clf = GaussianNB()\n",
    "    \n",
    "    print \"Model: \", clf\n",
    "    \n",
    "    print\n",
    "    print \"Data Slice: \"\n",
    "    print\n",
    "    print \"Shape X/Y: \", X.shape, Y.shape\n",
    "#     print \"Types X: \", vec.get_feature_names() \n",
    "    print \"Example X: \", X[0]\n",
    "    print \"Example Y: \", Y[0]\n",
    "    print\n",
    "    print \"Training model...\"\n",
    "    \n",
    "    clf.fit(X,Y)\n",
    "    \n",
    "    print \"Cross validating...\"\n",
    "\n",
    "    predictions = cross_validation.cross_val_predict(clf, X, Y, cv=10)\n",
    "    \n",
    "    print\n",
    "    print \"Model results: \"\n",
    "    print\n",
    "\n",
    "    check_results(predictions, Y)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_w2v(x):\n",
    "    return word2vec_model.vocab.get(x) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_sentences(sentences):\n",
    "    \n",
    "    vector_sentences, vectorizer = vectorize_documents(sentences)\n",
    "    analyze = vectorizer.build_analyzer()\n",
    "    neighbours = process_neighbours(vector_sentences)\n",
    "       \n",
    "    return {\n",
    "            \"vector_sentences\": vector_sentences,\n",
    "            \"vectorizer\": vectorizer,\n",
    "            \"analyze\": analyze,\n",
    "            \"neighbours\": neighbours\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_feature(candidate_result, question, question_text_vector, analyze, sentences, y_sup=False):\n",
    "    \n",
    "    text_query = question[\"question\"]\n",
    "        \n",
    "    result_index = candidate_result[0]\n",
    "    result_distance = candidate_result[1]    \n",
    "    \n",
    "    result_text_vector = set(filter(f_w2v, analyze(sentences[result_index])))\n",
    "\n",
    "    if len(question_text_vector) > 0 and len(result_text_vector) > 0:\n",
    "\n",
    "        current_w2v_simil = word2vec_model.n_similarity(question_text_vector, result_text_vector)\n",
    "        question_type = getQuestionType(text_query)\n",
    "\n",
    "        new_x = {\n",
    "                \"tf-idf\": result_distance, \n",
    "                \"w2v\": current_w2v_simil,\n",
    "                \"qtype\": question_type,\n",
    "                \"len_sent\": len(sentences[result_index])\n",
    "        }\n",
    "\n",
    "        new_y = None\n",
    "        \n",
    "        if not y_sup:\n",
    "            new_y = int(result_index == question[\"answer_sentence\"])\n",
    "\n",
    "        return [new_x, new_y]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_enhancement(question, neighbours, vector_query, analyze, sentences, y_sup=False):\n",
    "    \n",
    "    text_query = question[\"question\"]\n",
    "    question_text_vector = set(filter(f_w2v, analyze(text_query)))\n",
    "    \n",
    "    candidate_results = closest_documents(neighbours, vector_query, 5)\n",
    "    features = filter(None, [process_feature(x, question, question_text_vector, analyze, sentences, y_sup) for x in candidate_results])\n",
    "    \n",
    "    return {\n",
    "        \"candidate_results\": candidate_results,\n",
    "        \"features\": features\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_query(question, vectorizer, neighbours, analyze):\n",
    "    \n",
    "    text_query = question[\"question\"]\n",
    "    vector_query = vectorize_query(vectorizer, text_query)\n",
    "\n",
    "    result_distance, result_index = closest_document(neighbours, vector_query)\n",
    "    \n",
    "    return {\n",
    "            \"vector_query\": vector_query,\n",
    "            \"result_distance\": result_distance,\n",
    "            \"result_index\": result_index\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recursive_default_dict():\n",
    "    return defaultdict(recursive_default_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_part_a_output(name, data, args):\n",
    "    \n",
    "    cached = args.get(\"cached\")\n",
    "    \n",
    "    use_enhancement = args.get(\"use_enhancement\")\n",
    "    train_enhancement = args.get(\"train_enhancement\")\n",
    "    \n",
    "    enhancement_dataset = args.get(\"enhancement_dataset\")\n",
    "    \n",
    "    y_sup = args.get(\"y_sup\")\n",
    "    \n",
    "    question_set = data[name][\"question_set\"]\n",
    "    document_set = data[name][\"document_set\"]\n",
    "    \n",
    "    part_a_output = []\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    index_to_x = {}\n",
    "    \n",
    "    cache_dict = None\n",
    "    \n",
    "    if cached:\n",
    "        \n",
    "        cache_dict = data[name][\"part_a_cache_dict\"]\n",
    "        \n",
    "        x_best = cache_dict.get(\"X_best\")\n",
    "        \n",
    "        if x_best == None:\n",
    "            cache_dict[\"X_best\"] = recursive_default_dict()\n",
    "        \n",
    "#         X = data[name][\"X\"]\n",
    "#         Y = data[name][\"Y\"]        \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        cache_dict = {}\n",
    "        \n",
    "        cache_dict[\"sen_cache\"] = []\n",
    "        \n",
    "        cache_dict[\"query_cache\"] = []\n",
    "        \n",
    "        cache_dict[\"X_best\"] = recursive_default_dict()\n",
    "        \n",
    "        if use_enhancement:\n",
    "            \n",
    "            cache_dict[\"enhancement_cache\"] = []\n",
    "                \n",
    "        \n",
    "    for i, questions in enumerate(question_set):\n",
    "        \n",
    "        sentences = document_set[i]\n",
    "        \n",
    "        sen_cache = None\n",
    "\n",
    "        if cached:\n",
    "            \n",
    "            sen_cache_item = cache_dict[\"sen_cache\"][i]\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            sen_cache_item = process_sentences(sentences)\n",
    "            cache_dict[\"sen_cache\"].append(sen_cache_item)\n",
    "            \n",
    "            cache_dict[\"query_cache\"].append([])\n",
    "            \n",
    "            if use_enhancement:\n",
    "                \n",
    "                cache_dict[\"enhancement_cache\"].append([])\n",
    "\n",
    "        for j, question in enumerate(questions):\n",
    "            \n",
    "            query_cache_item = None\n",
    "            result_index = None\n",
    "            \n",
    "            if cached:\n",
    "                \n",
    "                query_cache_item = cache_dict[\"query_cache\"][i][j]\n",
    "                result_index = query_cache_item[\"result_index\"]\n",
    "                \n",
    "                if use_enhancement:\n",
    "                    \n",
    "                    enhancement_cache_item = cache_dict[\"enhancement_cache\"][i][j]\n",
    "\n",
    "                    model = data[enhancement_dataset][\"model\"]\n",
    "                    vec = data[enhancement_dataset][\"X_vec\"]\n",
    "\n",
    "                    candidate_results = enhancement_cache_item[\"candidate_results\"]\n",
    "                    new_xs = [feature[0] for feature in enhancement_cache_item[\"features\"]]\n",
    "\n",
    "                    if len(new_xs) > 0:\n",
    "\n",
    "                        new_features = vec.transform(new_xs) #.toarray()\n",
    "\n",
    "                        prob_ys = model.predict_proba(new_features)\n",
    "                        best_y_index = np.argmax(prob_ys[:, 1])\n",
    "                        \n",
    "                        cache_dict[\"X_best\"][i][j] = new_xs[best_y_index]\n",
    "\n",
    "                        result_index = candidate_results[best_y_index][0]\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                query_cache_item = process_query(question, sen_cache_item[\"vectorizer\"], sen_cache_item[\"neighbours\"], sen_cache_item[\"analyze\"])\n",
    "                cache_dict[\"query_cache\"][i].append(query_cache_item)\n",
    "                \n",
    "                result_index = query_cache_item[\"result_index\"]\n",
    "                \n",
    "                if use_enhancement:\n",
    "                    \n",
    "                    enhancement_cache_item = process_enhancement(question, sen_cache_item[\"neighbours\"], query_cache_item[\"vector_query\"], sen_cache_item[\"analyze\"], sentences, y_sup)\n",
    "                    cache_dict[\"enhancement_cache\"][i].append(enhancement_cache_item)                    \n",
    "                \n",
    "                if train_enhancement:\n",
    "\n",
    "                    new_xs = [feature[0] for feature in enhancement_cache_item[\"features\"]]\n",
    "                    new_ys = [feature[1] for feature in enhancement_cache_item[\"features\"]]\n",
    "\n",
    "                    X += new_xs\n",
    "                    Y += new_ys\n",
    "            \n",
    "            result = {\n",
    "                \"set_index\" : i,\n",
    "                \"question_index\" : j,\n",
    "                \"sentence_index\" : result_index\n",
    "            }\n",
    "\n",
    "            part_a_output.append(result)\n",
    "            \n",
    "#             if j > 1:\n",
    "#                 break\n",
    "                \n",
    "#         if i > 1:\n",
    "#             break\n",
    "            \n",
    "    if not cached:\n",
    "        \n",
    "        data[name][\"part_a_cache_dict\"] = cache_dict\n",
    "        \n",
    "        if train_enhancement:\n",
    "        \n",
    "            vec = DictVectorizer()                \n",
    "            X = vec.fit_transform(X) #.toarray()\n",
    "            Y = np.array(Y)\n",
    "\n",
    "            data[name][\"X_vec\"] = vec\n",
    "            data[name][\"X\"] = X\n",
    "            data[name][\"Y\"] = Y\n",
    "\n",
    "            print \"Shape X/Y: \", data[name][\"X\"].shape, data[name][\"Y\"].shape\n",
    "#             print \"Types X: \", vec.get_feature_names()        \n",
    "            print \"Example X: \", X[0]\n",
    "            print \"Example Y: \", Y[0]        \n",
    "        \n",
    "    return part_a_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_part_a(name, data, args):\n",
    "    \n",
    "    data[name][\"a_output_answer_set\"] = generate_part_a_output(name, data, args)\n",
    "    \n",
    "    gen_model = args.get(\"gen_model\")\n",
    "    \n",
    "    if gen_model:\n",
    "        data[name][\"model\"] = train_model(name, data)\n",
    "    \n",
    "    print\n",
    "    print \"Part A Output: \"\n",
    "    print\n",
    "    pp.pprint(data[name][\"a_output_answer_set\"][:rapid_size])\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shim function for later clean\n",
    "\n",
    "def evaluate_retrieval(name, data, args):\n",
    "    \n",
    "    question_set = data[name][\"question_set\"]\n",
    "    a_output_answer_set = data[name][\"a_output_answer_set\"]\n",
    "    \n",
    "    correct = []\n",
    "    wrong = []\n",
    "    \n",
    "    for result_a in a_output_answer_set:\n",
    "        \n",
    "        question = question_set[result_a[\"set_index\"]][result_a[\"question_index\"]]\n",
    "        \n",
    "        answer_sentence = question[\"answer_sentence\"]\n",
    "        predicted_answer_sentence = result_a[\"sentence_index\"]\n",
    "        \n",
    "        if answer_sentence == predicted_answer_sentence:\n",
    "            correct.append(result_a)\n",
    "        else:\n",
    "            wrong.append(result_a)\n",
    "        \n",
    "#         break\n",
    "            \n",
    "    return (correct, wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_generic(name, data, process_type, process_func, args):\n",
    "\n",
    "    (correct, wrong) = process_func(name, data, args)\n",
    "    \n",
    "    data[name][process_type + \"_correct\"] = correct\n",
    "    data[name][process_type + \"_wrong\"] = wrong\n",
    "#     data[name][process_type + \"_full\"] = full\n",
    "    \n",
    "    total = len(correct) + len(wrong)\n",
    "    avg = len(correct) * 1.0 / total\n",
    "    \n",
    "    print process_type.capitalize() + \" Correct: \", len(correct)\n",
    "    print process_type.capitalize() + \" Wrong: \", len(wrong)\n",
    "    print process_type.capitalize() + \" Total: \", total\n",
    "    print process_type.capitalize() + \" Overall Average %: \", avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_retrieval(name, data, stats=False, args={}):\n",
    "    print \"Processing retrieval: \", name\n",
    "    process_part_a(name, data, args)\n",
    "    if stats:\n",
    "        process_generic(name, data, \"retrieval\", evaluate_retrieval, args)\n",
    "        \n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing retrieval:  rapid\n",
      "Shape X/Y:  (2010, 7) (2010,)\n",
      "Example X:    (0, 0)\t41.0\n",
      "  (0, 2)\t1.0\n",
      "  (0, 5)\t0.810818811715\n",
      "  (0, 6)\t0.554025564417\n",
      "Example Y:  0\n",
      "Model:  LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "\n",
      "Data Slice: \n",
      "\n",
      "Shape X/Y:  (2010, 7) (2010,)\n",
      "Example X:    (0, 0)\t41.0\n",
      "  (0, 2)\t1.0\n",
      "  (0, 5)\t0.810818811715\n",
      "  (0, 6)\t0.554025564417\n",
      "Example Y:  0\n",
      "\n",
      "Training model...\n",
      "Cross validating...\n",
      "\n",
      "Model results: \n",
      "\n",
      "Accuracy:  0.876119402985\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93      1740\n",
      "          1       0.60      0.23      0.33       270\n",
      "\n",
      "avg / total       0.85      0.88      0.85      2010\n",
      "\n",
      "\n",
      "Part A Output: \n",
      "\n",
      "[{   'question_index': 0, 'sentence_index': 149, 'set_index': 0}]\n",
      "\n",
      "Retrieval Correct:  156\n",
      "Retrieval Wrong:  248\n",
      "Retrieval Total:  404\n",
      "Retrieval Overall Average %:  0.386138613861\n",
      "\n",
      "Processing retrieval:  rapid\n",
      "Model:  LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "\n",
      "Data Slice: \n",
      "\n",
      "Shape X/Y:  (2010, 7) (2010,)\n",
      "Example X:    (0, 0)\t41.0\n",
      "  (0, 2)\t1.0\n",
      "  (0, 5)\t0.810818811715\n",
      "  (0, 6)\t0.554025564417\n",
      "Example Y:  0\n",
      "\n",
      "Training model...\n",
      "Cross validating...\n",
      "\n",
      "Model results: \n",
      "\n",
      "Accuracy:  0.876119402985\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93      1740\n",
      "          1       0.60      0.23      0.33       270\n",
      "\n",
      "avg / total       0.85      0.88      0.85      2010\n",
      "\n",
      "\n",
      "Part A Output: \n",
      "\n",
      "[{   'question_index': 0, 'sentence_index': 149, 'set_index': 0}]\n",
      "\n",
      "Retrieval Correct:  156\n",
      "Retrieval Wrong:  248\n",
      "Retrieval Total:  404\n",
      "Retrieval Overall Average %:  0.386138613861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_retrieval(\"rapid\", DATA, True, {\"cached\" : False, \n",
    "                                        \"train_enhancement\": True,\n",
    "                                        \"use_enhancement\": True,\n",
    "                                        \"enhancement_dataset\": \"rapid\",\n",
    "                                        \"y_sup\": False,\n",
    "                                        \"gen_model\": True})                                        \n",
    "\n",
    "process_retrieval(\"rapid\", DATA, True, {\"cached\" : True, \n",
    "                                        \"train_enhancement\": False,\n",
    "                                        \"use_enhancement\": False,\n",
    "                                        \"enhancement_dataset\": \"rapid\",\n",
    "                                        \"y_sup\": False,\n",
    "                                        \"gen_model\": True})\n",
    "\n",
    "# process_retrieval(\"rapid\", DATA, True, {\"cached\" : True, \n",
    "#                                         \"train_enhancement\": False,\n",
    "#                                         \"use_enhancement\": True,\n",
    "#                                         \"enhancement_dataset\": \"rapid\",\n",
    "#                                         \"y_sup\": False,\n",
    "#                                         \"gen_model\": False})\n",
    "\n",
    "# process_retrieval(\"rapid\", DATA, True, {\"cached\" : True, \n",
    "#                                         \"train_enhancement\": False,\n",
    "#                                         \"use_enhancement\": False,\n",
    "#                                         \"enhancement_dataset\": \"train\",\n",
    "#                                         \"y_sup\": False,\n",
    "#                                         \"gen_model\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing retrieval:  dev\n",
      "\n",
      "Part A Output: \n",
      "\n",
      "[{   'question_index': 0, 'sentence_index': 71, 'set_index': 0}]\n",
      "\n",
      "Retrieval Correct:  5259\n",
      "Retrieval Wrong:  3204\n",
      "Retrieval Total:  8463\n",
      "Retrieval Overall Average %:  0.621410847217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# process_retrieval(\"dev\", DATA, True, {\"cached\" : False, \n",
    "#                                         \"train_enhancement\": True,\n",
    "#                                         \"use_enhancement\": True,\n",
    "#                                         \"enhancement_dataset\": \"dev\",\n",
    "#                                         \"y_sup\": False,\n",
    "#                                         \"gen_model\": True})                                      \n",
    "\n",
    "# process_retrieval(\"dev\", DATA, True, {   \"cached\" : True, \n",
    "#                                         \"train_enhancement\": False,\n",
    "#                                         \"use_enhancement\": False,\n",
    "#                                         \"enhancement_dataset\": \"dev\",\n",
    "#                                         \"y_sup\": False,\n",
    "#                                         \"gen_model\": True})                                      \n",
    "\n",
    "process_retrieval(\"dev\", DATA, True, {   \"cached\" : True, \n",
    "                                        \"train_enhancement\": False,\n",
    "                                        \"use_enhancement\": True,\n",
    "                                        \"enhancement_dataset\": \"dev\",\n",
    "                                        \"y_sup\": False,\n",
    "                                        \"gen_model\": False})    \n",
    "\n",
    "# process_retrieval(\"dev\", DATA, True, {   \"cached\" : True, \n",
    "#                                         \"train_enhancement\": False,\n",
    "#                                         \"use_enhancement\": True,\n",
    "#                                         \"enhancement_dataset\": \"train\",\n",
    "#                                         \"y_sup\": False,\n",
    "#                                         \"gen_model\": False})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing retrieval:  train\n",
      "Shape X/Y:  (346425, 7) (346425,)\n",
      "Example X:    (0, 0)\t41.0\n",
      "  (0, 2)\t1.0\n",
      "  (0, 5)\t0.810818811715\n",
      "  (0, 6)\t0.554025564417\n",
      "Example Y:  0\n",
      "Model:  LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "\n",
      "Data Slice: \n",
      "\n",
      "Shape X/Y:  (346425, 7) (346425,)\n",
      "Example X:    (0, 0)\t41.0\n",
      "  (0, 2)\t1.0\n",
      "  (0, 5)\t0.810818811715\n",
      "  (0, 6)\t0.554025564417\n",
      "Example Y:  0\n",
      "\n",
      "Training model...\n",
      "Cross validating...\n",
      "\n",
      "Model results: \n",
      "\n",
      "Accuracy:  0.884277982247\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93    288180\n",
      "          1       0.74      0.48      0.58     58245\n",
      "\n",
      "avg / total       0.87      0.88      0.87    346425\n",
      "\n",
      "\n",
      "Part A Output: \n",
      "\n",
      "[{   'question_index': 0, 'sentence_index': 149, 'set_index': 0}]\n",
      "\n",
      "Retrieval Correct:  43679\n",
      "Retrieval Wrong:  26480\n",
      "Retrieval Total:  70159\n",
      "Retrieval Overall Average %:  0.622571587394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_retrieval(\"train\", DATA, True, {\"cached\" : False, \n",
    "                                        \"train_enhancement\": True,\n",
    "                                        \"use_enhancement\": True,\n",
    "                                        \"enhancement_dataset\": \"train\",\n",
    "                                        \"gen_model\": True})                                     \n",
    "\n",
    "# process_retrieval(\"train\", DATA, True, {\"cached\" : True, \n",
    "#                                         \"train_enhancement\": False,\n",
    "#                                         \"use_enhancement\": False,\n",
    "#                                         \"enhancement_dataset\": \"train\",\n",
    "#                                         \"y_sup\": False,\n",
    "#                                         \"gen_model\": True})                                        \n",
    "\n",
    "\n",
    "# process_retrieval(\"train\", DATA, True, {\"cached\" : True, \n",
    "#                                         \"train_enhancement\": False,\n",
    "#                                         \"use_enhancement\": True,\n",
    "#                                         \"enhancement_dataset\": \"train\",\n",
    "#                                         \"y_sup\": False,\n",
    "#                                         \"gen_model\": False})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# process_retrieval(\"test\", DATA, False, {\"cached\" : False, \n",
    "#                                         \"train_enhancement\": False,\n",
    "#                                         \"use_enhancement\": True,\n",
    "#                                         \"enhancement_dataset\": \"dev\",\n",
    "#                                         \"y_sup\": True})                                       \n",
    "\n",
    "# process_retrieval(\"test\", DATA, False, {\"cached\" : True, \n",
    "#                                         \"train_enhancement\": False,\n",
    "#                                         \"use_enhancement\": False,\n",
    "#                                         \"enhancement_dataset\": \"dev\",\n",
    "#                                         \"y_sup\": True})                                       \n",
    "\n",
    "process_retrieval(\"test\", DATA, False, {\"cached\" : True, \n",
    "                                        \"train_enhancement\": False,\n",
    "                                        \"use_enhancement\": True,\n",
    "                                        \"enhancement_dataset\": \"dev\",\n",
    "                                        \"y_sup\": True})                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing retrieval:  test\n",
      "\n",
      "Part A Output: \n",
      "\n",
      "[{   'question_index': 0, 'sentence_index': 283, 'set_index': 0}]\n",
      "\n",
      "\n",
      "Processing retrieval:  test\n",
      "\n",
      "Part A Output: \n",
      "\n",
      "[{   'question_index': 0, 'sentence_index': 353, 'set_index': 0}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_retrieval(\"test\", DATA, False, {\"cached\" : False, \n",
    "                                        \"train_enhancement\": False,\n",
    "                                        \"use_enhancement\": True,\n",
    "                                        \"enhancement_dataset\": \"train\",\n",
    "                                        \"y_sup\": True})                                       \n",
    "\n",
    "# process_retrieval(\"test\", DATA, False, {\"cached\" : True, \n",
    "#                                         \"train_enhancement\": False,\n",
    "#                                         \"use_enhancement\": False,\n",
    "#                                         \"enhancement_dataset\": \"train\",\n",
    "#                                         \"y_sup\": True})                                       \n",
    "\n",
    "process_retrieval(\"test\", DATA, False, {\"cached\" : True, \n",
    "                                        \"train_enhancement\": False,\n",
    "                                        \"use_enhancement\": True,\n",
    "                                        \"enhancement_dataset\": \"train\",\n",
    "                                        \"y_sup\": True})                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shim function for later clean\n",
    "\n",
    "# Thanks for this list to save me typing it : http://stackoverflow.com/questions/493174/is-there-a-way-to-convert-number-words-to-integers\\n\",\n",
    "numInWords = [\"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\",\n",
    "        \"nine\", \"ten\", \"eleven\", \"twelve\", \"thirteen\", \"fourteen\", \"fifteen\",\n",
    "        \"sixteen\", \"seventeen\", \"eighteen\", \"nineteen\", \"twenty\", \"thirty\", \"forty\", \"fifty\", \"sixty\", \"seventy\", \"eighty\", \"ninety\"\n",
    "       , \"hundred\", \"thousand\", \"million\", \"billion\", \"trillion\"]\n",
    "\n",
    "punctuation = [\"''\",'``','(','.',':', ',',')']\n",
    "\n",
    "\n",
    "months = [\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"]\n",
    "\n",
    "def isPunctuation(word):\n",
    "    return word in punctuation\n",
    "\n",
    "def isCapitalised (word):\n",
    "    if len(word) == 0:\n",
    "        return False\n",
    "    return word[0].isupper()\n",
    "\n",
    "# Obtained from training data\n",
    "postUnits = [u'%', u'century', u'years', u'percent', u'years ago', u'days', u'months', u'km', u'hours', u'times', u'inches', u'\\xb0C', u'minutes', u'acres', u'\\xb0F', u'weeks', u'people', u'sq mi', u'mi', u'ft', u'feet', u'metres', u'mm', u'square miles', u'miles', u'pm', u'per cent', u'year', u'copies', u'yuan', u'men', u'square feet', u'third', u'kilometres', u'nm', u'tonnes', u'species', u'decades', u'barrels', u'tons', u'largest', u'centuries', u'km2']\n",
    "preUnits = [u'$',u'around', u'late', u'early', u'nearly', u'since', u'approximately', u'number']\n",
    "\n",
    "# Returns true if the word represents a number\\n\",\n",
    "def isNumber(word):\n",
    "    pattern = \".?(\\\\d)+((,|.)(\\\\d)+)*\"\n",
    "    if re.match(pattern,word) :\n",
    "        return True\n",
    "    if word.lower() in numInWords:\n",
    "        return True\n",
    "    if word in months:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def isStopWord(word):\n",
    "    return word.lower() in stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grammar = \"\"\" ANS: {<JJ>?<N.*>*}\n",
    "                   {<DT>?<N.*>*}\n",
    "                   }<UH|POS|VB|VBG|RP|DT|MD|PRP$|TO|RB|JJS|PDT|IN|PRP|VBP|VBN|RBS|WRB|WP|EX|VBZ|WDT|VBD>{\n",
    "                    \"\"\"\n",
    "cp = nltk.RegexpParser(grammar) \n",
    "\n",
    "def chunk(words):\n",
    "    tokenWS = nltk.pos_tag(nltk.word_tokenize(words))\n",
    "    chunks =  cp.parse(tokenWS)\n",
    "    possAnswers = []\n",
    "    for subtree in chunks.subtrees():\n",
    "        if subtree.label() == 'ANS':\n",
    "            possAnswers.append((' '.join(word for word, pos in subtree.leaves()),'O'))\n",
    "    possAnswers.append((\"Nope\", \"CRAP\")) # To ensure nothing has 0 tags\n",
    "    return possAnswers    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_non_chunked_words_as_single_tags(words):\n",
    "    chunked_output = chunk(words)\n",
    "    token_words = nltk.pos_tag(nltk.word_tokenize(words))\n",
    "    if len(chunked_output) == 0:\n",
    "        chunked_words = [\"DEREKWANG\"]\n",
    "    else:\n",
    "        chunked_words = [nltk.word_tokenize(word_tag_pair[0]) for word_tag_pair in chunked_output ]    \n",
    "    all_word_tags = []\n",
    "    \n",
    "    current_chunk_index = 0\n",
    "    current_chunk_word = 0\n",
    "    current_chunk_list = chunked_words[0]\n",
    "    \n",
    "    for word_tag_pair in token_words:\n",
    "        word = word_tag_pair[0]\n",
    "        if word == current_chunk_list[current_chunk_word]:\n",
    "            # Need to move onto next word\n",
    "            if current_chunk_word == len(current_chunk_list) - 1:\n",
    "                # last word in this current chunk\n",
    "                all_word_tags.append(chunked_output[current_chunk_index])\n",
    "                current_chunk_index += 1\n",
    "                current_chunk_word = 0\n",
    "                if current_chunk_index == len(chunked_words):\n",
    "                    current_chunk_list = [\"NOPE\"]\n",
    "                else:\n",
    "                    current_chunk_list = chunked_words[current_chunk_index]\n",
    "            else :\n",
    "                current_chunk_word += 1\n",
    "        else :\n",
    "            # Need to add word, as it's not in a chunk :(\n",
    "            all_word_tags.append((word,'O'))\n",
    "    return all_word_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shim function for later clean\n",
    "\n",
    "def slow_refine_word_tags(taggedWordList):\n",
    "    newWordTags = []\n",
    "    for (word, tag) in taggedWordList:\n",
    "        if (tag == 'ORGANIZATION'):\n",
    "            tag = 'O'\n",
    "        if (tag == 'O'):\n",
    "            #Might be a number\n",
    "            if isNumber(word):\n",
    "                tag = 'NUMBER'\n",
    "            elif word in preUnits:\n",
    "                tag = 'PRENUM'\n",
    "            elif isPunctuation(word):\n",
    "                tag = 'PUNC'\n",
    "            elif word in postUnits:\n",
    "                tag = 'POSTNUM'\n",
    "            elif isCapitalised(word):\n",
    "                tag = \"OTHERCAP\"\n",
    "        newWordTags.append((word, tag))\n",
    "    \n",
    "    newWordTags = combineTags (newWordTags)\n",
    "    other_processed_tags = process_others(newWordTags)\n",
    "    return other_processed_tags\n",
    "        \n",
    "def combineTags(wordTags):\n",
    "    \n",
    "    newTags = []\n",
    "    prevWord = wordTags[0][0]\n",
    "    prevTag = wordTags[0][1]\n",
    "    \n",
    "    for (word, tag) in wordTags[1:]:\n",
    "        if tag == 'NUMBER' and prevTag == 'PRENUM':\n",
    "            prevTag = 'NUMBER'\n",
    "        elif prevTag == 'PRENUM':\n",
    "            prevTag = 'O'\n",
    "        if tag == 'POSTNUM' and prevTag == \"NUMBER\":\n",
    "            tag = \"NUMBER\"\n",
    "        elif tag == \"POSTNUM\":\n",
    "            tag = \"O\"\n",
    "        newTags.append((prevWord, prevTag))\n",
    "        prevWord = word\n",
    "        prevTag = tag\n",
    "    newTags.append((prevWord, prevTag))\n",
    "        \n",
    "    newNewTags = []\n",
    "    prevWord = newTags[0][0]\n",
    "    prevTag = newTags[0][1]\n",
    "    if (prevTag == \"OTHERCAP\" and newTags[1][1] != \"OTHERCAP\"):\n",
    "        prevTag = \"O\"\n",
    "        \n",
    "    for (word, tag) in newTags[1:]:\n",
    "#         print tag, prevTag\n",
    "        if tag == prevTag :\n",
    "            if word == '%':\n",
    "                prevWord += word\n",
    "            else :\n",
    "                if prevWord == '$':\n",
    "                    prevWord += word\n",
    "                else :\n",
    "                    prevWord += ' ' + word\n",
    "        else :\n",
    "            newNewTags.append((prevWord, prevTag))\n",
    "            prevWord = word\n",
    "            prevTag = tag\n",
    "            \n",
    "    newNewTags.append((prevWord, prevTag))\n",
    "    \n",
    "    return newNewTags\n",
    "\n",
    "def process_others(words_with_tags):\n",
    "    new_taggings = []\n",
    "    for (words, tag) in words_with_tags:\n",
    "        if tag == 'O':\n",
    "            chunk_results = add_non_chunked_words_as_single_tags(words)\n",
    "            for (word,tag) in chunk_results:\n",
    "                new_taggings.append((word, tag))\n",
    "            #new_taggings.append((words,tag))\n",
    "        else :\n",
    "            new_taggings.append((words, tag))\n",
    "    return new_taggings\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Shim function for later clean\n",
    "\n",
    "def fast_refine_word_tags(taggedWordList):\n",
    "    newWordTags = []\n",
    "    for (word, tag) in taggedWordList:\n",
    "        if (tag == 'ORGANIZATION'):\n",
    "            tag = 'O'\n",
    "        if (tag == 'O'):\n",
    "            #Might be a number\n",
    "            if isNumber(word):\n",
    "                tag = 'NUMBER'\n",
    "            elif isCapitalised(word):\n",
    "                tag = 'OTHERCAP'\n",
    "            elif word in preUnits:\n",
    "                tag = 'PRENUM'\n",
    "            elif word in postUnits:\n",
    "                tag = 'POSTNUM'\n",
    "            elif isStopWord(word):\n",
    "                tag = 'STOPWORD'\n",
    "            elif isPunctuation(word):\n",
    "                tag = 'PUNC'\n",
    "\n",
    "        newWordTags.append((word, tag))\n",
    "    \n",
    "    newWordTags = combineTags (newWordTags)\n",
    "    return newWordTags\n",
    "        \n",
    "def combineTags(wordTags):\n",
    "    \n",
    "    newTags = []\n",
    "    prevWord = wordTags[0][0]\n",
    "    prevTag = wordTags[0][1]\n",
    "    \n",
    "    for (word, tag) in wordTags[1:]:\n",
    "        if tag == 'NUMBER' and prevTag == 'PRENUM':\n",
    "            prevTag = 'NUMBER'\n",
    "        elif prevTag == 'PRENUM':\n",
    "            prevTag = 'O'\n",
    "        if tag == 'POSTNUM' and prevTag == \"NUMBER\":\n",
    "            tag = \"NUMBER\"\n",
    "        elif tag == \"POSTNUM\":\n",
    "            tag = \"O\"\n",
    "        newTags.append((prevWord, prevTag))\n",
    "        prevWord = word\n",
    "        prevTag = tag\n",
    "    newTags.append((prevWord, prevTag))\n",
    "    \n",
    "#     print newTags\n",
    "    \n",
    "    newNewTags = []\n",
    "    prevWord = newTags[0][0]\n",
    "    prevTag = newTags[0][1]\n",
    "    if (prevTag == \"OTHERCAP\"):\n",
    "        prevTag = \"O\"\n",
    "        \n",
    "    for (word, tag) in newTags[1:]:\n",
    "#         print tag, prevTag\n",
    "        if tag == prevTag :\n",
    "            prevWord += ' ' + word\n",
    "        else :\n",
    "            newNewTags.append((prevWord, prevTag))\n",
    "            prevWord = word\n",
    "            prevTag = tag\n",
    "            \n",
    "    newNewTags.append((prevWord, prevTag))\n",
    "    \n",
    "    return newNewTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_part_b_output(name, data, args):\n",
    "    \n",
    "    question_set = data[name][\"question_set\"]\n",
    "    a_output_answer_set = data[name][\"a_output_answer_set\"]\n",
    "    tagged_set = data[name][\"tagged_set\"]\n",
    "    \n",
    "    refine_func = args.get(\"refine_func\")\n",
    "    \n",
    "    part_b_output = []\n",
    "    \n",
    "    for result_a in a_output_answer_set:\n",
    "        \n",
    "        stanford_tags = tagged_set[result_a[\"set_index\"]][result_a[\"sentence_index\"]]\n",
    "        \n",
    "        filtered_tags = refine_func(stanford_tags)\n",
    "        \n",
    "        question = question_set[result_a[\"set_index\"]][result_a[\"question_index\"]][\"question\"]\n",
    "        \n",
    "        result_b = {\n",
    "            \"set_index\"  : result_a[\"set_index\"],\n",
    "            \"question_index\" : result_a[\"question_index\"],\n",
    "            \"sentence_index\" : result_a[\"sentence_index\"],\n",
    "            \"candidates\" : filtered_tags\n",
    "        }\n",
    "        \n",
    "        part_b_output.append(result_b)\n",
    "        \n",
    "    return part_b_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_part_b(name, data, args):\n",
    "    \n",
    "    data[name][\"b_output_answer_set\"] = generate_part_b_output(name, data, args)\n",
    "    \n",
    "    print\n",
    "    print \"Part B Output: \"\n",
    "    pp.pprint(data[name][\"b_output_answer_set\"][:rapid_size])\n",
    "    print    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Shim function for later clean\n",
    "\n",
    "def evaluate_ner(name, data, args):\n",
    "    \n",
    "    question_set = data[name][\"question_set\"]\n",
    "    b_output_answer_set = data[name][\"b_output_answer_set\"]\n",
    "    \n",
    "    correct = []\n",
    "    wrong = []\n",
    "    \n",
    "    for result_b in b_output_answer_set:\n",
    "        \n",
    "        answer = question_set[result_b[\"set_index\"]][result_b[\"question_index\"]][\"answer\"]\n",
    "        \n",
    "        possible_candidates = result_b[\"candidates\"]\n",
    "        \n",
    "        answer_exists_in_candidates = False\n",
    "        \n",
    "        for candidate in possible_candidates:\n",
    "            \n",
    "            candidate_string = candidate[0]\n",
    "            \n",
    "            if candidate_string == answer:\n",
    "                \n",
    "                answer_exists_in_candidates = True\n",
    "                \n",
    "                break\n",
    "        \n",
    "        if answer_exists_in_candidates:\n",
    "            correct.append(result_b)\n",
    "        else :\n",
    "            wrong.append(result_b)\n",
    "            \n",
    "    return (correct, wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_ner(name, data, stats=False, args={}):\n",
    "    print \"Processing ner: \", name\n",
    "    process_part_b(name, data, args)\n",
    "    if stats:\n",
    "        process_generic(name, data, \"ner\", evaluate_ner, args)\n",
    "        \n",
    "        correct_ner = len(data[name][\"ner_correct\"])\n",
    "        correct_ret = len(data[name][\"retrieval_correct\"])\n",
    "        \n",
    "        avg = correct_ner * 1.0 / correct_ret\n",
    "        \n",
    "        print \"ner\".capitalize() + \" Correct Average of Previous %: \", avg\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ner:  rapid\n",
      "\n",
      "Part B Output: \n",
      "[   {   'candidates': [   (u'They', 'O'),\n",
      "                          (u'had', 'O'),\n",
      "                          (u'a', 'O'),\n",
      "                          (u'playing time', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'eight minutes', 'NUMBER'),\n",
      "                          (u'.', 'PUNC')],\n",
      "        'question_index': 0,\n",
      "        'sentence_index': 149,\n",
      "        'set_index': 0}]\n",
      "\n",
      "Ner Correct:  74\n",
      "Ner Wrong:  330\n",
      "Ner Total:  404\n",
      "Ner Overall Average %:  0.183168316832\n",
      "Ner Correct Average of Previous %:  0.474358974359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_ner(\"rapid\", DATA, True, {\"refine_func\": slow_refine_word_tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ner:  dev\n",
      "\n",
      "Part B Output: \n",
      "[   {   'candidates': [   (u'Infrared', 'O'),\n",
      "                          (u'is', 'STOPWORD'),\n",
      "                          (u'used', u'O'),\n",
      "                          (u'in', 'STOPWORD'),\n",
      "                          (u'night vision equipment', u'O'),\n",
      "                          (u'when there is', 'STOPWORD'),\n",
      "                          (u'insufficient visible light', u'O'),\n",
      "                          (u'to', 'STOPWORD'),\n",
      "                          (u'see', u'O'),\n",
      "                          (u'.', 'PUNC')],\n",
      "        'question_index': 0,\n",
      "        'sentence_index': 71,\n",
      "        'set_index': 0}]\n",
      "\n",
      "Ner Correct:  2606\n",
      "Ner Wrong:  5857\n",
      "Ner Total:  8463\n",
      "Ner Overall Average %:  0.307928630509\n",
      "Ner Correct Average of Previous %:  0.495531469861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_ner(\"dev\", DATA, True, {\"refine_func\": fast_refine_word_tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ner:  train\n",
      "\n",
      "Part B Output: \n",
      "[   {   'candidates': [   (u'They', 'O'),\n",
      "                          (u'had a', 'STOPWORD'),\n",
      "                          (u'playing time', u'O'),\n",
      "                          (u'of', 'STOPWORD'),\n",
      "                          (u'eight minutes', 'NUMBER'),\n",
      "                          (u'.', 'PUNC')],\n",
      "        'question_index': 0,\n",
      "        'sentence_index': 149,\n",
      "        'set_index': 0}]\n",
      "\n",
      "Ner Correct:  21249\n",
      "Ner Wrong:  48910\n",
      "Ner Total:  70159\n",
      "Ner Overall Average %:  0.302869197109\n",
      "Ner Correct Average of Previous %:  0.486480917603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_ner(\"train\", DATA, True, {\"refine_func\": fast_refine_word_tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ner:  test\n",
      "Warning: parsing empty text\n",
      "\n",
      "Part B Output: \n",
      "[   {   'candidates': [   (u'The', 'O'),\n",
      "                          (u'Crimean War', 'OTHERCAP'),\n",
      "                          (u'marked', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'ascendancy', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'France', u'LOCATION'),\n",
      "                          (u'to', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'position', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'pre-eminent power', 'O'),\n",
      "                          (u'on', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'Continent', 'OTHERCAP'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u':411', 'NUMBER'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'continued decline', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'Ottoman Empire', 'OTHERCAP'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'and', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'beginning', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'a', 'O'),\n",
      "                          (u'decline', 'O'),\n",
      "                          (u'for', 'O'),\n",
      "                          (u'Tsarist', 'OTHERCAP'),\n",
      "                          (u'Russia', u'LOCATION'),\n",
      "                          (u'.', 'PUNC')],\n",
      "        'question_index': 0,\n",
      "        'sentence_index': 353,\n",
      "        'set_index': 0}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_ner(\"test\", DATA, False, {\"refine_func\": slow_refine_word_tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.parse.stanford import StanfordDependencyParser\n",
    "\n",
    "import os\n",
    "os.environ['CLASSPATH'] = 'stanford-parser-full-2016-10-31'\n",
    "\n",
    "dep_parser = StanfordDependencyParser(model_path=\"./englishPCFG.ser.gz\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove the non-word entities from answer-entities\n",
    "def process_answer_entities(anwser_entities):\n",
    "    new_anwser_entities =[]\n",
    "    for (entity,entity_type) in anwser_entities:\n",
    "        tokenized_entity = word_tokenize(entity)\n",
    "        #print tokenized_entity\n",
    "        temp = []\n",
    "        for ele in tokenized_entity:\n",
    "            temp.append(ele.encode('utf-8'))\n",
    "        temp = ' '.join(temp)\n",
    "        new_anwser_entities.append(temp)\n",
    "    result = ' '.join(new_anwser_entities)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, answers whose content words all appear in the question should be ranked lowest.\n",
    "\n",
    "def first_filter(question, answer_entities):\n",
    "   \n",
    "    ranked_list = []\n",
    "    \n",
    "    question = set(pre_process_tf_idf(question))\n",
    "    \n",
    "#     print question\n",
    "#     print\n",
    "    \n",
    "    for entity in answer_entities:\n",
    "\n",
    "        raw_span = entity[0]\n",
    "        span_tag = entity[1]\n",
    "        \n",
    "        set_span = set(pre_process_tf_idf(raw_span))\n",
    "        \n",
    "        if span_tag != \"O\" and span_tag != \"STOPWORD\" and span_tag !=\"PUNC\":\n",
    "            \n",
    "            if set_span.issubset(question):\n",
    "                ranked_list.append([entity, 1])\n",
    "#                 print \"IN\", raw_span, span_tag, set_span, question\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                ranked_list.append([entity, 2])\n",
    "#                 print \"OUT\", raw_span, span_tag, set_span, question\n",
    "    #print ranked_list\n",
    "    #generate answer entity list\n",
    "    answer = process_answer_entities(answer_entities)\n",
    "    \n",
    "    tree = []\n",
    "    same_list = []\n",
    "    for ele in ranked_list:\n",
    "        same_list.append(ele[1])\n",
    "    if 1 not in same_list:\n",
    "        try:\n",
    "            tree =[parse.tree() for parse in dep_parser.raw_parse(answer)]   \n",
    "        except AssertionError:\n",
    "            return sorted(ranked_list, key=lambda x: x[1], reverse=True)\n",
    "        else:\n",
    "            ranked_list.append([tree[0].label(),1])\n",
    "            #print tree[0].label()\n",
    "    return sorted(ranked_list, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # First, answers whose content words all appear in the question should be ranked lowest.\n",
    "\n",
    "# def first_filter(question, answer_entities):\n",
    "   \n",
    "#     ranked_list = []\n",
    "    \n",
    "#     question = set(pre_process_tf_idf(question))\n",
    "    \n",
    "# #     print question\n",
    "# #     print\n",
    "    \n",
    "#     for entity in answer_entities:\n",
    "\n",
    "#         raw_span = entity[0]\n",
    "#         span_tag = entity[1]\n",
    "        \n",
    "#         set_span = set(pre_process_tf_idf(raw_span))\n",
    "        \n",
    "#         if span_tag != \"O\" and span_tag != \"STOPWORD\" and span_tag !=\"PUNC\":\n",
    "            \n",
    "#             if set_span.issubset(question):\n",
    "                \n",
    "#                 ranked_list.append([entity, 1])\n",
    "# #                 print \"IN\", raw_span, span_tag, set_span, question\n",
    "                \n",
    "#             else:\n",
    "                \n",
    "#                 ranked_list.append([entity, 2])\n",
    "# #                 print \"OUT\", raw_span, span_tag, set_span, question\n",
    "    \n",
    "#     return sorted(ranked_list, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, answers whose content words all appear in the question should be ranked lowest.\n",
    "\n",
    "def first_filter_object(question, answer_entities):\n",
    "   \n",
    "    ranked_list = []\n",
    "    \n",
    "    question = set(pre_process_tf_idf(question))\n",
    "    \n",
    "#     print question\n",
    "#     print\n",
    "    \n",
    "    for entity in answer_entities:\n",
    "\n",
    "        raw_span = entity[0]\n",
    "        span_tag = entity[1]\n",
    "        \n",
    "        set_span = set(pre_process_tf_idf(raw_span))\n",
    "        \n",
    "        if span_tag != \"STOPWORD\" and span_tag !=\"PUNC\": #span_tag != \"O\" and\n",
    "            \n",
    "            if span_tag == \"O\":\n",
    "                \n",
    "                if len(set_span) > 1:\n",
    "                    ranked_list.append([entity, 0])\n",
    "            \n",
    "            elif set_span.issubset(question):\n",
    "                \n",
    "                ranked_list.append([entity, 1])\n",
    "#                 print \"IN\", raw_span, span_tag, set_span, question\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                ranked_list.append([entity, 2])\n",
    "#                 print \"OUT\", raw_span, span_tag, set_span, question\n",
    "    \n",
    "    return sorted(ranked_list, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, answers whose content words all appear in the question should be ranked lowest.\n",
    "\n",
    "def first_filter_object_stop(question, answer_entities):\n",
    "   \n",
    "    ranked_list = []\n",
    "    \n",
    "    question = set(pre_process_tf_idf(question))\n",
    "    \n",
    "#     print question\n",
    "#     print\n",
    "    \n",
    "    for entity in answer_entities:\n",
    "\n",
    "        raw_span = entity[0]\n",
    "        span_tag = entity[1]\n",
    "        \n",
    "        set_span = set(pre_process_tf_idf(raw_span))\n",
    "        \n",
    "        if span_tag !=\"PUNC\": #span_tag != \"O\" and\n",
    "            \n",
    "            if span_tag == \"O\" or span_tag == \"STOPWORD\":\n",
    "                \n",
    "                if len(set_span) > 1:\n",
    "                    \n",
    "                    ranked_list.append([entity, 0])\n",
    "            \n",
    "            elif set_span.issubset(question):\n",
    "                \n",
    "                ranked_list.append([entity, 1])\n",
    "#                 print \"IN\", raw_span, span_tag, set_span, question\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                ranked_list.append([entity, 2])\n",
    "#                 print \"OUT\", raw_span, span_tag, set_span, question\n",
    "    \n",
    "    return sorted(ranked_list, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Second, answers which match the question type should be ranked higher than those that don't; for this, you\n",
    "# should build a simple rule-based question type classifier based on key words (e.g. questions which contain \"who\" are\n",
    "# people).\n",
    "\n",
    "# First, answers whose content words all appear in the question should be ranked lowest.\n",
    "\n",
    "def second_filter(question, ranked_list):\n",
    "   \n",
    "    question_type = getQuestionType(question)\n",
    "#     print question_type\n",
    "    \n",
    "    for index, answer in enumerate(ranked_list):\n",
    "        \n",
    "        entity_tag = answer[0][1]\n",
    "        \n",
    "        if entity_tag == question_type:\n",
    "#             print \"MATCH\", answer[0], question_type, question\n",
    "            ranked_list[index].append(2)\n",
    "#             ranked_list[index][1] += 1\n",
    "        else:\n",
    "            ranked_list[index].append(1)\n",
    "#             ranked_list[index][1] -= 1\n",
    "            \n",
    "    return ranked_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pre_process_open_class(line):\n",
    "    tokenized_sentence = word_tokenizer.tokenize(line.lower())\n",
    "    lemmatized_sentence = [lemmatize(token) for token in tokenized_sentence]\n",
    "    filtered_sentence = [token for token in lemmatized_sentence if token not in filter_tokens]\n",
    "    tagged_sent = nltk.pos_tag(lemmatized_sentence)\n",
    "    final = []\n",
    "       \n",
    "    for word, tag in tagged_sent:\n",
    "        #expand the open-class word to noun,verb,adj and adv\n",
    "        if \"V\" in tag or \"NN\" in tag or 'JJ' in tag or 'RB' in tag:\n",
    "#             final.append((word,tag))\n",
    "            final.append(word)\n",
    "            \n",
    "#     print \"RESULT: \", final\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Third, among entities of the same type, the prefered entity should be the one which is closer in the sentence to a\n",
    "# closed-class word from the question.\n",
    "\n",
    "def third_filter(question, possAnswers, ranked_list):\n",
    "    \n",
    "    question = pre_process_open_class(question)\n",
    "\n",
    "    answer_sent = \" \".join([x[0] for x in possAnswers])\n",
    "    answer_sent = pre_process_tf_idf(answer_sent)\n",
    "    raw_answer_sent = \" \".join(answer_sent)\n",
    "    \n",
    "#     print \"QUESTION: \"\n",
    "#     pp.pprint(question)\n",
    "#     print \"ANSWER: \"\n",
    "#     pp.pprint(answer_sent)\n",
    "#     pp.pprint(raw_answer_sent)\n",
    "    \n",
    "    for index, answer in enumerate(ranked_list):\n",
    "\n",
    "        span_tag = answer[0][1]\n",
    "        raw_span = answer[0][0]\n",
    "\n",
    "        proc_span = pre_process_tf_idf(raw_span)\n",
    "\n",
    "        raw_proc_span = \" \".join(proc_span)\n",
    "        new_raw_proc_span = \"-\".join(proc_span)\n",
    "\n",
    "        raw_answer_sent = raw_answer_sent.replace(raw_proc_span, new_raw_proc_span)\n",
    "    \n",
    "    answer_sent = raw_answer_sent.split(\" \")\n",
    "    \n",
    "    avg_dict = defaultdict(float)\n",
    "    \n",
    "    for open_class in question:\n",
    "        \n",
    "        if open_class in answer_sent:\n",
    "            \n",
    "            open_class_locations = [i for i, x in enumerate(answer_sent) if x == open_class]\n",
    "            \n",
    "#             print \"OPEN CLASS: \", repr(open_class)\n",
    "\n",
    "            for index, answer in enumerate(ranked_list):\n",
    "\n",
    "                span_tag = answer[0][1]\n",
    "                raw_span = answer[0][0]\n",
    "\n",
    "                proc_span = pre_process_tf_idf(raw_span)\n",
    "                \n",
    "                raw_proc_span = \" \".join(proc_span)\n",
    "                new_raw_proc_span = \"-\".join(proc_span)\n",
    "                \n",
    "                proc_span_locations = [i for i, x in enumerate(answer_sent) if x == new_raw_proc_span]\n",
    "                \n",
    "                min_dist = len(answer_sent)\n",
    "                min_dist_ind = (None, None)\n",
    "                \n",
    "                for loc1 in proc_span_locations:\n",
    "                    \n",
    "                    for loc2 in open_class_locations:\n",
    "                        \n",
    "                        dist = abs(loc1 - loc2)\n",
    "                        \n",
    "                        if dist < min_dist:\n",
    "                            \n",
    "                            min_dist = dist\n",
    "                            min_dist_ind = (loc1, loc2)\n",
    "                \n",
    "#                 print \"PROC: \", proc_span_locations\n",
    "#                 print \"OPEN CLASS: \", open_class_locations                \n",
    "                scale = (len(answer_sent) - min_dist) * 1.0 / len(answer_sent)\n",
    "#                 print \"JOINT: \", min_dist_ind, scale\n",
    "                avg_dict[index] += scale\n",
    "#                 ranked_list[index][1] *= scale\n",
    "    \n",
    "    for key, value in avg_dict.iteritems():\n",
    "        ranked_list[key].append(value / len(question))\n",
    "\n",
    "    return ranked_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduce_rank(ranking_list):\n",
    "    \n",
    "    new_ranking = []\n",
    "    \n",
    "    for rank in ranking_list:\n",
    "        \n",
    "        new_rank = ( rank[1] + rank[2] )\n",
    "        \n",
    "        if len(rank) == 4:\n",
    "             new_rank *= rank[3]\n",
    "        \n",
    "        new_ranking.append([rank[0], new_rank])\n",
    "        \n",
    "    return sorted(new_ranking, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_result(fourth_pass):\n",
    "    top_answer = fourth_pass[0]\n",
    "    predicted_answer = top_answer[0][0]    \n",
    "    \n",
    "    return predicted_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def multi_pass(first_filter_funcs, question, candidates, mem=None):\n",
    "    \n",
    "    if len(first_filter_funcs) > 0:\n",
    "    \n",
    "        first_pass = first_filter_funcs.pop(0)(question, candidates)\n",
    "\n",
    "        try:\n",
    "            second_pass = second_filter(question, first_pass)\n",
    "        except IndexError:\n",
    "            second_pass = []        \n",
    "        \n",
    "#         second_pass = second_filter(question, first_pass)\n",
    "\n",
    "        third_pass = third_filter(question, candidates, second_pass)\n",
    "\n",
    "        fourth_pass = reduce_rank(third_pass)\n",
    "\n",
    "        if len(fourth_pass) > 0:\n",
    "            \n",
    "            predicted_answer = get_result(fourth_pass)\n",
    "            \n",
    "            return [fourth_pass, third_pass, predicted_answer]\n",
    "        else:\n",
    "            return multi_pass(first_filter_funcs, question, candidates, [fourth_pass, third_pass])\n",
    "    else:\n",
    "        \n",
    "        hits = [x for x in candidates if x[1] != \"PUNC\" or x[1] == \"STOPWORDS\"]                        \n",
    "        predicted_answer = random.choice(hits)[0]\n",
    "        \n",
    "        return mem + [predicted_answer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_feature(feature, rela_proc, question_proc, question_type, a_new_x):\n",
    "    \n",
    "#     pp.pprint(feature)    \n",
    "    \n",
    "    open_dist = 0.5\n",
    "    \n",
    "    if len(feature) > 3:\n",
    "        open_dist = feature[3]\n",
    "        \n",
    "        \n",
    "    c_feature =  {\n",
    "            \"answer_type\": feature[0][1],\n",
    "            \"question_type\": question_type,\n",
    "            \"first\" : feature[1],\n",
    "            \"second\": feature[2],\n",
    "            \"open_dist\": open_dist,            \n",
    "    }\n",
    "    \n",
    "#     answer_proc = feature[0][0].split(\" \") #pre_process_tf_idf(feature[0][0].encode('ascii', 'ignore'))\n",
    "        \n",
    "#     for x in answer_proc:\n",
    "        \n",
    "#         if rela_proc.get(x):\n",
    "            \n",
    "#             relations = rela_proc[x]\n",
    "            \n",
    "#             for y in relations:\n",
    "            \n",
    "#                 for z in question_proc:\n",
    "                    \n",
    "#                     feature_name = \"DSQ: {0} {1} {2}\".format(z, y[2], y[1]).encode('ascii', 'ignore')\n",
    "#                     c_feature[feature_name] = 1.0\n",
    "                \n",
    "#             feature_name = \"DAQ: {0}, {1}\".format(x, y).encode('ascii', 'ignore')\n",
    "#             c_feature[feature_name] = 1.0\n",
    "    \n",
    "    c_feature.update(a_new_x)\n",
    "    \n",
    "    return c_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dep_tree(string):\n",
    "    \n",
    "    parses = [parse for parse in dep_parser.raw_parse(string.encode('ascii', 'ignore'))]\n",
    "    \n",
    "    if len(parses) > 0:\n",
    "        return parses[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def processed_relations(string):\n",
    "    \n",
    "    dep = get_dep_tree(string)\n",
    "    \n",
    "    l = list(dep.triples())\n",
    "\n",
    "    rela_struct = defaultdict(list)\n",
    "\n",
    "    prune = { \"CC\": True, \".\": True, \": True,\": True, \":\": True, \"-LRB-\": True, \"-RRB-\": True, \"POS\": True, \"DT\": True, \"IN\": True, \"TO\": True }\n",
    "\n",
    "    for a in l:\n",
    "\n",
    "        source_tuple = a[0]\n",
    "\n",
    "        relation = a[1]\n",
    "\n",
    "        sink_tuple = a[2]\n",
    "\n",
    "        source_word = source_tuple[0]\n",
    "        source_word_tag = source_tuple[1]\n",
    "\n",
    "        sink_word = sink_tuple[0]\n",
    "        sink_word_tag = sink_tuple[1]\n",
    "        \n",
    "#         print source_tuple, relation, sink_tuple\n",
    "\n",
    "        if source_word not in prune and sink_word_tag not in prune:   \n",
    "            rela_struct[source_word].append((relation, \"->\", sink_word))   \n",
    "            rela_struct[sink_word].append((relation, \"<-\", source_word))                        \n",
    "\n",
    "    return rela_struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_part_c_output(name, data, args):\n",
    "        \n",
    "    question_set = data[name][\"question_set\"]\n",
    "    document_set = data[name][\"document_set\"]\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    part_c_output = []\n",
    "    \n",
    "    cached = args.get(\"cached\")\n",
    "    enhancement_dataset = args.get(\"enhancement_dataset\")\n",
    "    \n",
    "    train_enhancement = args.get(\"train_enhancement\")\n",
    "    use_enhancement = args.get(\"use_enhancement\")\n",
    "    \n",
    "    cache_dict = None\n",
    "    data_a_cache_dict = data[name][\"part_a_cache_dict\"]\n",
    "    \n",
    "    if cached:\n",
    "        \n",
    "        cache_dict = data[name][\"part_c_cache_dict\"]\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        cache_dict = {}\n",
    "        \n",
    "        cache_dict[\"pass_cache\"] = []\n",
    "        \n",
    "        if use_enhancement:\n",
    "            \n",
    "            cache_dict[\"enhancement_cache\"] = []    \n",
    "        \n",
    "    b_output_answer_set = data[name][\"b_output_answer_set\"]\n",
    "    \n",
    "    if use_enhancement:\n",
    "\n",
    "        model = data[enhancement_dataset][\"part_c_cache_dict\"][\"model\"]\n",
    "        vec = data[enhancement_dataset][\"part_c_cache_dict\"][\"X_vec\"]\n",
    "    \n",
    "    for i, result_b in enumerate(b_output_answer_set):\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print \"Processed: {0}\".format(i)\n",
    "        \n",
    "        predicted_answer = None        \n",
    "        \n",
    "        question = question_set[result_b[\"set_index\"]][result_b[\"question_index\"]][\"question\"]\n",
    "        candidate_sentence = document_set[result_b[\"set_index\"]][result_b[\"sentence_index\"]]\n",
    "        \n",
    "        if train_enhancement:\n",
    "            actual_answer = question_set[result_b[\"set_index\"]][result_b[\"question_index\"]][\"answer\"]\n",
    "        \n",
    "        question_type = getQuestionType(question)\n",
    "        question_proc = pre_process_tf_idf(question.encode('ascii', 'ignore'))\n",
    "        rela_proc = processed_relations(candidate_sentence)\n",
    "        \n",
    "        if cached:\n",
    "            \n",
    "            (fourth_pass, third_pass, predicted_answer) = cache_dict[\"pass_cache\"][i]\n",
    "            \n",
    "            if use_enhancement:\n",
    "                \n",
    "#                 a_new_x = data_a_cache_dict[\"X_best\"][result_b[\"set_index\"]][result_b[\"question_index\"]]\n",
    "                a_new_x = {}\n",
    "                new_xs = [build_feature(x, rela_proc, question_proc, question_type, a_new_x) for x in third_pass]\n",
    "                \n",
    "#                 pp.pprint(new_xs)\n",
    "\n",
    "                if len(new_xs) > 0:\n",
    "\n",
    "                    new_features = vec.transform(new_xs) #.toarray()\n",
    "\n",
    "                    prob_ys = model.predict_proba(new_features)\n",
    "                    best_y_index = np.argmax(prob_ys[:, 1])\n",
    "\n",
    "                    predicted_answer = third_pass[best_y_index][0][0]\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            (fourth_pass, third_pass, predicted_answer) = multi_pass([first_filter, first_filter_object, first_filter_object_stop], question, result_b[\"candidates\"])\n",
    "            \n",
    "            cache_dict[\"pass_cache\"].append((fourth_pass, third_pass, predicted_answer))\n",
    "                        \n",
    "            if train_enhancement:\n",
    "\n",
    "#                 a_new_x = data_a_cache_dict[\"X_best\"][result_b[\"set_index\"]][result_b[\"question_index\"]]\n",
    "                a_new_x = {}\n",
    "                \n",
    "                new_xs = [build_feature(x, rela_proc, question_proc, question_type, a_new_x) for x in third_pass]\n",
    "                new_ys = [int(feature[0][0] == actual_answer) for feature in third_pass]\n",
    "                \n",
    "#                 pp.pprint(new_xs)\n",
    "#                 pp.pprint(new_ys)\n",
    "\n",
    "                X += new_xs\n",
    "                Y += new_ys\n",
    "        \n",
    "        predicted_answer = predicted_answer.replace(\" %\", \"%\").replace(\"$ \", \"$\")\n",
    "\n",
    "        result_c = {\n",
    "            \"set_index\"  : result_b[\"set_index\"],\n",
    "            \"question_index\" : result_b[\"question_index\"],\n",
    "            \"sentence_index\" : result_b[\"sentence_index\"],\n",
    "            \"candidates\": result_b[\"candidates\"],\n",
    "            \"ranked_answers\": fourth_pass,\n",
    "            \"vector_ranked_answers\": third_pass,\n",
    "            \"predicted_answer\" : predicted_answer\n",
    "        }\n",
    "        \n",
    "        part_c_output.append(result_c)\n",
    "        \n",
    "#         if i > 10:\n",
    "#             break\n",
    "           \n",
    "    if not cached:\n",
    "        \n",
    "        if train_enhancement:\n",
    "        \n",
    "            vec = DictVectorizer()                \n",
    "            X = vec.fit_transform(X) #.toarray()\n",
    "            Y = np.array(Y)\n",
    "\n",
    "            cache_dict[\"X_vec\"] = vec\n",
    "            cache_dict[\"X\"] = X\n",
    "            cache_dict[\"Y\"] = Y\n",
    "\n",
    "            print \"Shape X/Y: \", cache_dict[\"X\"].shape, cache_dict[\"Y\"].shape\n",
    "#             print \"Types X: \", vec.get_feature_names()        \n",
    "            print \"Example X: \", X[0]\n",
    "            print \"Example Y: \", Y[0]            \n",
    "        \n",
    "        data[name][\"part_c_cache_dict\"] = cache_dict            \n",
    "        \n",
    "    return part_c_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model_c(name, data, cache) :\n",
    "\n",
    "    vec = DATA[name][cache][\"X_vec\"]\n",
    "    X = DATA[name][cache][\"X\"]\n",
    "    Y = DATA[name][cache][\"Y\"]\n",
    "\n",
    "    clf = linear_model.LogisticRegression(C=1e5)\n",
    "#     clf = AdaBoostClassifier(n_estimators=100)\n",
    "#     clf = RandomForestClassifier(n_estimators=10)\n",
    "    #clf = svm.SVC()\n",
    "#     clf = GaussianNB()\n",
    "    \n",
    "    print \"Model: \", clf\n",
    "    \n",
    "    print\n",
    "    print \"Data Slice: \"\n",
    "    print\n",
    "    print \"Shape X/Y: \", X.shape, Y.shape\n",
    "#     print \"Types X: \", vec.get_feature_names() \n",
    "    print \"Example X: \", X[0]\n",
    "    print \"Example Y: \", Y[0]\n",
    "    print\n",
    "    print \"Training model...\"\n",
    "    \n",
    "    clf.fit(X,Y)\n",
    "    \n",
    "    print \"Cross validating...\"\n",
    "\n",
    "    predictions = cross_validation.cross_val_predict(clf, X, Y, cv=10)\n",
    "    \n",
    "    print\n",
    "    print \"Model results: \"\n",
    "    print\n",
    "\n",
    "    check_results(predictions, Y)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_part_c(name, data, args):\n",
    "    \n",
    "    data[name][\"c_output_answer_set\"] = generate_part_c_output(name, data, args)\n",
    "    \n",
    "    gen_model = args.get(\"gen_model\")    \n",
    "    \n",
    "    if gen_model:\n",
    "        data[name][\"part_c_cache_dict\"][\"model\"] = train_model_c(name, data, \"part_c_cache_dict\")    \n",
    "    \n",
    "    print\n",
    "    print \"Part C Output: \"\n",
    "    pp.pprint(data[name][\"c_output_answer_set\"][:rapid_size])\n",
    "    print    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For each question, evaluate if the answer is present as an entity\n",
    "\n",
    "def evaluate_rank(name, data, args):\n",
    "    \n",
    "    question_set = data[name][\"question_set\"]\n",
    "    document_set = data[name][\"document_set\"]\n",
    "    \n",
    "    correct = []\n",
    "    wrong = []\n",
    "    \n",
    "#     partial = []\n",
    "    \n",
    "    c_output_answer_set = data[name][\"c_output_answer_set\"]\n",
    "    \n",
    "    for result_c in c_output_answer_set:\n",
    "        \n",
    "        question = question_set[result_c[\"set_index\"]][result_c[\"question_index\"]][\"question\"]\n",
    "        answer =  question_set[result_c[\"set_index\"]][result_c[\"question_index\"]][\"answer\"]\n",
    "        \n",
    "        predicted_answer = result_c[\"predicted_answer\"]\n",
    "        vector_ranked_answers = result_c[\"vector_ranked_answers\"]                \n",
    "\n",
    "        if (predicted_answer == answer):\n",
    "            correct.append(result_c)\n",
    "        else :\n",
    "            wrong.append(result_c)\n",
    "            \n",
    "#             print(answer, predicted_answer)\n",
    "#             print vector_ranked_answers\n",
    "#             break\n",
    "        #print correct\n",
    "    return (correct, wrong)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_rank(name, data, stats=False, args={}):\n",
    "    print \"Processing rank: \", name\n",
    "    process_part_c(name, data, args)\n",
    "    if stats:\n",
    "        process_generic(name, data, \"rank\", evaluate_rank, args)\n",
    "        \n",
    "        \n",
    "        correct_rank = len(data[name][\"rank_correct\"])\n",
    "        correct_ner = len(data[name][\"ner_correct\"])\n",
    "        \n",
    "        avg = correct_rank * 1.0 / correct_ner\n",
    "        \n",
    "        print \"rank\".capitalize() + \" Correct Average of Previous %: \", avg        \n",
    "        \n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rank:  rapid\n",
      "Processed: 0\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xe2 in position 151: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-121-a130ec356af8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m                                     \u001b[1;34m\"gen_model\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                     \u001b[1;34m\"use_enhancement\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                                     \"enhancement_dataset\": \"rapid\"})\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# process_rank(\"rapid\", DATA, True, {\"cached\" : True,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-120-367a1a3c6f03>\u001b[0m in \u001b[0;36mprocess_rank\u001b[1;34m(name, data, stats, args)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprocess_rank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Processing rank: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprocess_part_c\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mprocess_generic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rank\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_rank\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-118-1ae5dc745c88>\u001b[0m in \u001b[0;36mprocess_part_c\u001b[1;34m(name, data, args)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprocess_part_c\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"c_output_answer_set\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_part_c_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mgen_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"gen_model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-116-e9e171811d7e>\u001b[0m in \u001b[0;36mgenerate_part_c_output\u001b[1;34m(name, data, args)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             \u001b[1;33m(\u001b[0m\u001b[0mfourth_pass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthird_pass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_answer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmulti_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfirst_filter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst_filter_object\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst_filter_object_stop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_b\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"candidates\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[0mcache_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"pass_cache\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfourth_pass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthird_pass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_answer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-112-25bd9cda852a>\u001b[0m in \u001b[0;36mmulti_pass\u001b[1;34m(first_filter_funcs, question, candidates, mem)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_filter_funcs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mfirst_pass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfirst_filter_funcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-90-b0fcdac18e0f>\u001b[0m in \u001b[0;36mfirst_filter\u001b[1;34m(question, answer_entities)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msame_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mparse\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdep_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_parse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mranked_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/work/anaconda3/envs/py27/lib/python2.7/site-packages/nltk/parse/stanford.pyc\u001b[0m in \u001b[0;36mraw_parse\u001b[1;34m(self, sentence, verbose)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \"\"\"\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_parse_sents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mraw_parse_sents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/work/anaconda3/envs/py27/lib/python2.7/site-packages/nltk/parse/stanford.pyc\u001b[0m in \u001b[0;36mraw_parse_sents\u001b[1;34m(self, sentences, verbose)\u001b[0m\n\u001b[0;32m    148\u001b[0m             \u001b[1;34m'-outputFormat'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_OUTPUT_FORMAT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         ]\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_trees_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtagged_parse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xe2 in position 151: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "process_rank(\"rapid\", DATA, True, {\"cached\" : False,\n",
    "                                    \"train_enhancement\": True,\n",
    "                                    \"gen_model\": True,\n",
    "                                    \"use_enhancement\": False,\n",
    "                                    \"enhancement_dataset\": \"rapid\"})\n",
    "\n",
    "# process_rank(\"rapid\", DATA, True, {\"cached\" : True,\n",
    "#                                     \"train_enhancement\": False,\n",
    "#                                     \"gen_model\": False,\n",
    "#                                     \"use_enhancement\": True,\n",
    "#                                     \"enhancement_dataset\": \"rapid\"})\n",
    "\n",
    "# process_rank(\"rapid\", DATA, True, {\"cached\" : True,\n",
    "#                                     \"train_enhancement\": False,\n",
    "#                                     \"gen_model\": False,\n",
    "#                                     \"use_enhancement\": True,\n",
    "#                                     \"enhancement_dataset\": \"dev\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len(DATA[\"train\"][\"c_output_answer_set\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rank:  dev\n",
      "\n",
      "Part C Output: \n",
      "[   {   'candidates': [   (u'Infrared', 'O'),\n",
      "                          (u'is', 'STOPWORD'),\n",
      "                          (u'used', u'O'),\n",
      "                          (u'in', 'STOPWORD'),\n",
      "                          (u'night vision equipment', u'O'),\n",
      "                          (u'when there is', 'STOPWORD'),\n",
      "                          (u'insufficient visible light', u'O'),\n",
      "                          (u'to', 'STOPWORD'),\n",
      "                          (u'see', u'O'),\n",
      "                          (u'.', 'PUNC')],\n",
      "        'predicted_answer': u'night vision equipment',\n",
      "        'question_index': 0,\n",
      "        'ranked_answers': [   [   (u'night vision equipment', 'O'),\n",
      "                                  0.2777777777777778],\n",
      "                              [(u'visible light', 'O'), 0.16666666666666666]],\n",
      "        'sentence_index': 71,\n",
      "        'set_index': 0,\n",
      "        'vector_ranked_answers': [   [   (u'night vision equipment', 'O'),\n",
      "                                         0,\n",
      "                                         2,\n",
      "                                         0.1388888888888889],\n",
      "                                     [   (u'visible light', 'O'),\n",
      "                                         0,\n",
      "                                         2,\n",
      "                                         0.08333333333333333]]}]\n",
      "\n",
      "Rank Correct:  2156\n",
      "Rank Wrong:  6307\n",
      "Rank Total:  8463\n",
      "Rank Overall Average %:  0.254755996691\n",
      "Rank Correct Average of Previous %:  0.827321565618\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# process_rank(\"dev\", DATA, True, {\"cached\" : False,\n",
    "#                                     \"train_enhancement\": True,\n",
    "#                                     \"gen_model\": True,\n",
    "#                                     \"use_enhancement\": False,\n",
    "#                                     \"enhancement_dataset\": \"dev\"})\n",
    "\n",
    "# process_rank(\"dev\", DATA, True, {   \"cached\" : True,\n",
    "#                                     \"train_enhancement\": False,\n",
    "#                                     \"gen_model\": False,\n",
    "#                                     \"use_enhancement\": True,\n",
    "#                                     \"enhancement_dataset\": \"dev\"})        \n",
    "\n",
    "process_rank(\"dev\", DATA, True, {   \"cached\" : True,\n",
    "                                    \"train_enhancement\": False,\n",
    "                                    \"gen_model\": False,\n",
    "                                    \"use_enhancement\": True,\n",
    "                                    \"enhancement_dataset\": \"dev\"})                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rank:  train\n",
      "Shape X/Y:  (285521, 1369381) (285521,)\n",
      "Example X:    (0, 1)\t1.0\n",
      "  (0, 6)\t2.0\n",
      "  (0, 512028)\t1.0\n",
      "  (0, 512057)\t1.0\n",
      "  (0, 512279)\t1.0\n",
      "  (0, 512479)\t1.0\n",
      "  (0, 512510)\t1.0\n",
      "  (0, 881799)\t1.0\n",
      "  (0, 881815)\t1.0\n",
      "  (0, 881921)\t1.0\n",
      "  (0, 882027)\t1.0\n",
      "  (0, 882051)\t1.0\n",
      "  (0, 1369375)\t0.0952380952381\n",
      "  (0, 1369377)\t1.0\n",
      "  (0, 1369380)\t2.0\n",
      "Example Y:  0\n",
      "Model:  LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "\n",
      "Data Slice: \n",
      "\n",
      "Shape X/Y:  (285521, 1369381) (285521,)\n",
      "Example X:    (0, 1)\t1.0\n",
      "  (0, 6)\t2.0\n",
      "  (0, 512028)\t1.0\n",
      "  (0, 512057)\t1.0\n",
      "  (0, 512279)\t1.0\n",
      "  (0, 512479)\t1.0\n",
      "  (0, 512510)\t1.0\n",
      "  (0, 881799)\t1.0\n",
      "  (0, 881815)\t1.0\n",
      "  (0, 881921)\t1.0\n",
      "  (0, 882027)\t1.0\n",
      "  (0, 882051)\t1.0\n",
      "  (0, 1369375)\t0.0952380952381\n",
      "  (0, 1369377)\t1.0\n",
      "  (0, 1369380)\t2.0\n",
      "Example Y:  0\n",
      "\n",
      "Training model...\n",
      "Cross validating...\n",
      "\n",
      "Model results: \n",
      "\n",
      "Accuracy:  0.93684177346\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.99      0.97    268066\n",
      "          1       0.40      0.07      0.12     17455\n",
      "\n",
      "avg / total       0.91      0.94      0.92    285521\n",
      "\n",
      "\n",
      "Part C Output: \n",
      "[   {   'candidates': [   (u'They', 'O'),\n",
      "                          (u'had a', 'STOPWORD'),\n",
      "                          (u'playing time', u'O'),\n",
      "                          (u'of', 'STOPWORD'),\n",
      "                          (u'eight minutes', 'NUMBER'),\n",
      "                          (u'.', 'PUNC')],\n",
      "        'predicted_answer': u'eight minutes',\n",
      "        'question_index': 0,\n",
      "        'ranked_answers': [   [   (u'eight minutes', 'NUMBER'),\n",
      "                                  0.38095238095238093]],\n",
      "        'sentence_index': 149,\n",
      "        'set_index': 0,\n",
      "        'vector_ranked_answers': [   [   (u'eight minutes', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.09523809523809523]]}]\n",
      "\n",
      "Rank Correct:  11105\n",
      "Rank Wrong:  59054\n",
      "Rank Total:  70159\n",
      "Rank Overall Average %:  0.15828332787\n",
      "Rank Correct Average of Previous %:  0.522612828839\n",
      "\n",
      "Processing rank:  train\n",
      "\n",
      "Part C Output: \n",
      "[   {   'candidates': [   (u'They', 'O'),\n",
      "                          (u'had a', 'STOPWORD'),\n",
      "                          (u'playing time', u'O'),\n",
      "                          (u'of', 'STOPWORD'),\n",
      "                          (u'eight minutes', 'NUMBER'),\n",
      "                          (u'.', 'PUNC')],\n",
      "        'predicted_answer': u'eight minutes',\n",
      "        'question_index': 0,\n",
      "        'ranked_answers': [   [   (u'eight minutes', 'NUMBER'),\n",
      "                                  0.38095238095238093]],\n",
      "        'sentence_index': 149,\n",
      "        'set_index': 0,\n",
      "        'vector_ranked_answers': [   [   (u'eight minutes', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.09523809523809523]]}]\n",
      "\n",
      "Rank Correct:  17335\n",
      "Rank Wrong:  52824\n",
      "Rank Total:  70159\n",
      "Rank Overall Average %:  0.247081628872\n",
      "Rank Correct Average of Previous %:  0.815803096616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_rank(\"train\", DATA, True, {\"cached\" : False,\n",
    "                                    \"train_enhancement\": True,\n",
    "                                    \"gen_model\": True,\n",
    "                                    \"use_enhancement\": False,\n",
    "                                    \"enhancement_dataset\": \"train\"})\n",
    "\n",
    "process_rank(\"train\", DATA, True, {   \"cached\" : True,\n",
    "                                    \"train_enhancement\": False,\n",
    "                                    \"gen_model\": False,\n",
    "                                    \"use_enhancement\": True,\n",
    "                                    \"enhancement_dataset\": \"train\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rank:  test\n",
      "\n",
      "Part C Output: \n",
      "[   {   'candidates': [   (u'The', 'O'),\n",
      "                          (u'Crimean War', 'OTHERCAP'),\n",
      "                          (u'marked', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'ascendancy', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'France', u'LOCATION'),\n",
      "                          (u'to', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'position', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'pre-eminent power', 'O'),\n",
      "                          (u'on', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'Continent', 'OTHERCAP'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u':411', 'NUMBER'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'continued decline', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'Ottoman Empire', 'OTHERCAP'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'and', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'beginning', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'a', 'O'),\n",
      "                          (u'decline', 'O'),\n",
      "                          (u'for', 'O'),\n",
      "                          (u'Tsarist', 'OTHERCAP'),\n",
      "                          (u'Russia', u'LOCATION'),\n",
      "                          (u'.', 'PUNC')],\n",
      "        'predicted_answer': u':411',\n",
      "        'question_index': 0,\n",
      "        'ranked_answers': [   [(u':411', 'NUMBER'), 0.6117647058823529],\n",
      "                              [   (u'Ottoman Empire', 'OTHERCAP'),\n",
      "                                  0.5647058823529412],\n",
      "                              [(u'Tsarist', 'OTHERCAP'), 0.5294117647058822],\n",
      "                              [   (u'Russia', u'LOCATION'),\n",
      "                                  0.49411764705882355],\n",
      "                              [   (u'Continent', 'OTHERCAP'),\n",
      "                                  0.4235294117647059],\n",
      "                              [   (u'France', u'LOCATION'),\n",
      "                                  0.24705882352941178],\n",
      "                              [   (u'Crimean War', 'OTHERCAP'),\n",
      "                                  0.09411764705882353]],\n",
      "        'sentence_index': 353,\n",
      "        'set_index': 0,\n",
      "        'vector_ranked_answers': [   [   (u'France', u'LOCATION'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.08235294117647059],\n",
      "                                     [   (u'Continent', 'OTHERCAP'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.1411764705882353],\n",
      "                                     [   (u':411', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.15294117647058822],\n",
      "                                     [   (u'Ottoman Empire', 'OTHERCAP'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.18823529411764706],\n",
      "                                     [   (u'Tsarist', 'OTHERCAP'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.1764705882352941],\n",
      "                                     [   (u'Russia', u'LOCATION'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.16470588235294117],\n",
      "                                     [   (u'Crimean War', 'OTHERCAP'),\n",
      "                                         1,\n",
      "                                         1,\n",
      "                                         0.047058823529411764]]}]\n",
      "\n",
      "\n",
      "Processing rank:  test\n",
      "\n",
      "Part C Output: \n",
      "[   {   'candidates': [   (u'The', 'O'),\n",
      "                          (u'Crimean War', 'OTHERCAP'),\n",
      "                          (u'marked', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'ascendancy', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'France', u'LOCATION'),\n",
      "                          (u'to', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'position', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'pre-eminent power', 'O'),\n",
      "                          (u'on', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'Continent', 'OTHERCAP'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u':411', 'NUMBER'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'continued decline', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'Ottoman Empire', 'OTHERCAP'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'and', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'beginning', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'a', 'O'),\n",
      "                          (u'decline', 'O'),\n",
      "                          (u'for', 'O'),\n",
      "                          (u'Tsarist', 'OTHERCAP'),\n",
      "                          (u'Russia', u'LOCATION'),\n",
      "                          (u'.', 'PUNC')],\n",
      "        'predicted_answer': u':411',\n",
      "        'question_index': 0,\n",
      "        'ranked_answers': [   [(u':411', 'NUMBER'), 0.6117647058823529],\n",
      "                              [   (u'Ottoman Empire', 'OTHERCAP'),\n",
      "                                  0.5647058823529412],\n",
      "                              [(u'Tsarist', 'OTHERCAP'), 0.5294117647058822],\n",
      "                              [   (u'Russia', u'LOCATION'),\n",
      "                                  0.49411764705882355],\n",
      "                              [   (u'Continent', 'OTHERCAP'),\n",
      "                                  0.4235294117647059],\n",
      "                              [   (u'France', u'LOCATION'),\n",
      "                                  0.24705882352941178],\n",
      "                              [   (u'Crimean War', 'OTHERCAP'),\n",
      "                                  0.09411764705882353]],\n",
      "        'sentence_index': 353,\n",
      "        'set_index': 0,\n",
      "        'vector_ranked_answers': [   [   (u'France', u'LOCATION'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.08235294117647059],\n",
      "                                     [   (u'Continent', 'OTHERCAP'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.1411764705882353],\n",
      "                                     [   (u':411', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.15294117647058822],\n",
      "                                     [   (u'Ottoman Empire', 'OTHERCAP'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.18823529411764706],\n",
      "                                     [   (u'Tsarist', 'OTHERCAP'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.1764705882352941],\n",
      "                                     [   (u'Russia', u'LOCATION'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.16470588235294117],\n",
      "                                     [   (u'Crimean War', 'OTHERCAP'),\n",
      "                                         1,\n",
      "                                         1,\n",
      "                                         0.047058823529411764]]}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_rank(\"test\", DATA, False, {\"cached\" : False,\n",
    "                                    \"train_enhancement\": False,\n",
    "                                    \"gen_model\": False,\n",
    "                                    \"use_enhancement\": False,\n",
    "                                    \"enhancement_dataset\": \"dev\"})\n",
    "\n",
    "process_rank(\"test\", DATA, False, {   \"cached\" : True,\n",
    "                                    \"train_enhancement\": False,\n",
    "                                    \"gen_model\": False,\n",
    "                                    \"use_enhancement\": True,\n",
    "                                    \"enhancement_dataset\": \"dev\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rank:  test\n",
      "\n",
      "Part C Output: \n",
      "[   {   'candidates': [   (u'The', 'O'),\n",
      "                          (u'Crimean War', 'OTHERCAP'),\n",
      "                          (u'marked', u'O'),\n",
      "                          (u'the', 'STOPWORD'),\n",
      "                          (u'ascendancy', u'O'),\n",
      "                          (u'of', 'STOPWORD'),\n",
      "                          (u'France', u'LOCATION'),\n",
      "                          (u'to the', 'STOPWORD'),\n",
      "                          (u'position', u'O'),\n",
      "                          (u'of', 'STOPWORD'),\n",
      "                          (u'pre-eminent power', u'O'),\n",
      "                          (u'on the', 'STOPWORD'),\n",
      "                          (u'Continent', 'OTHERCAP'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u':411', 'NUMBER'),\n",
      "                          (u'the', 'STOPWORD'),\n",
      "                          (u'continued decline', u'O'),\n",
      "                          (u'of the', 'STOPWORD'),\n",
      "                          (u'Ottoman Empire', 'OTHERCAP'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'and the', 'STOPWORD'),\n",
      "                          (u'beginning', u'O'),\n",
      "                          (u'of a', 'STOPWORD'),\n",
      "                          (u'decline', u'O'),\n",
      "                          (u'for', 'STOPWORD'),\n",
      "                          (u'Tsarist', 'OTHERCAP'),\n",
      "                          (u'Russia', u'LOCATION'),\n",
      "                          (u'.', 'PUNC')],\n",
      "        'predicted_answer': u':411',\n",
      "        'question_index': 0,\n",
      "        'ranked_answers': [   [(u':411', 'NUMBER'), 0.6117647058823529],\n",
      "                              [   (u'Ottoman Empire', 'OTHERCAP'),\n",
      "                                  0.5647058823529412],\n",
      "                              [(u'Tsarist', 'OTHERCAP'), 0.5294117647058822],\n",
      "                              [   (u'Russia', u'LOCATION'),\n",
      "                                  0.49411764705882355],\n",
      "                              [   (u'Continent', 'OTHERCAP'),\n",
      "                                  0.4235294117647059],\n",
      "                              [   (u'France', u'LOCATION'),\n",
      "                                  0.24705882352941178],\n",
      "                              [   (u'Crimean War', 'OTHERCAP'),\n",
      "                                  0.09411764705882353]],\n",
      "        'sentence_index': 353,\n",
      "        'set_index': 0,\n",
      "        'vector_ranked_answers': [   [   (u'France', u'LOCATION'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.08235294117647059],\n",
      "                                     [   (u'Continent', 'OTHERCAP'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.1411764705882353],\n",
      "                                     [   (u':411', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.15294117647058822],\n",
      "                                     [   (u'Ottoman Empire', 'OTHERCAP'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.18823529411764706],\n",
      "                                     [   (u'Tsarist', 'OTHERCAP'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.1764705882352941],\n",
      "                                     [   (u'Russia', u'LOCATION'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.16470588235294117],\n",
      "                                     [   (u'Crimean War', 'OTHERCAP'),\n",
      "                                         1,\n",
      "                                         1,\n",
      "                                         0.047058823529411764]]}]\n",
      "\n",
      "\n",
      "Processing rank:  test\n",
      "\n",
      "Part C Output: \n",
      "[   {   'candidates': [   (u'The', 'O'),\n",
      "                          (u'Crimean War', 'OTHERCAP'),\n",
      "                          (u'marked', u'O'),\n",
      "                          (u'the', 'STOPWORD'),\n",
      "                          (u'ascendancy', u'O'),\n",
      "                          (u'of', 'STOPWORD'),\n",
      "                          (u'France', u'LOCATION'),\n",
      "                          (u'to the', 'STOPWORD'),\n",
      "                          (u'position', u'O'),\n",
      "                          (u'of', 'STOPWORD'),\n",
      "                          (u'pre-eminent power', u'O'),\n",
      "                          (u'on the', 'STOPWORD'),\n",
      "                          (u'Continent', 'OTHERCAP'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u':411', 'NUMBER'),\n",
      "                          (u'the', 'STOPWORD'),\n",
      "                          (u'continued decline', u'O'),\n",
      "                          (u'of the', 'STOPWORD'),\n",
      "                          (u'Ottoman Empire', 'OTHERCAP'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'and the', 'STOPWORD'),\n",
      "                          (u'beginning', u'O'),\n",
      "                          (u'of a', 'STOPWORD'),\n",
      "                          (u'decline', u'O'),\n",
      "                          (u'for', 'STOPWORD'),\n",
      "                          (u'Tsarist', 'OTHERCAP'),\n",
      "                          (u'Russia', u'LOCATION'),\n",
      "                          (u'.', 'PUNC')],\n",
      "        'predicted_answer': u':411',\n",
      "        'question_index': 0,\n",
      "        'ranked_answers': [   [(u':411', 'NUMBER'), 0.6117647058823529],\n",
      "                              [   (u'Ottoman Empire', 'OTHERCAP'),\n",
      "                                  0.5647058823529412],\n",
      "                              [(u'Tsarist', 'OTHERCAP'), 0.5294117647058822],\n",
      "                              [   (u'Russia', u'LOCATION'),\n",
      "                                  0.49411764705882355],\n",
      "                              [   (u'Continent', 'OTHERCAP'),\n",
      "                                  0.4235294117647059],\n",
      "                              [   (u'France', u'LOCATION'),\n",
      "                                  0.24705882352941178],\n",
      "                              [   (u'Crimean War', 'OTHERCAP'),\n",
      "                                  0.09411764705882353]],\n",
      "        'sentence_index': 353,\n",
      "        'set_index': 0,\n",
      "        'vector_ranked_answers': [   [   (u'France', u'LOCATION'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.08235294117647059],\n",
      "                                     [   (u'Continent', 'OTHERCAP'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.1411764705882353],\n",
      "                                     [   (u':411', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.15294117647058822],\n",
      "                                     [   (u'Ottoman Empire', 'OTHERCAP'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.18823529411764706],\n",
      "                                     [   (u'Tsarist', 'OTHERCAP'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.1764705882352941],\n",
      "                                     [   (u'Russia', u'LOCATION'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.16470588235294117],\n",
      "                                     [   (u'Crimean War', 'OTHERCAP'),\n",
      "                                         1,\n",
      "                                         1,\n",
      "                                         0.047058823529411764]]}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_rank(\"test\", DATA, False, {\"cached\" : False,\n",
    "                                    \"train_enhancement\": False,\n",
    "                                    \"gen_model\": False,\n",
    "                                    \"use_enhancement\": False,\n",
    "                                    \"enhancement_dataset\": \"train\"})\n",
    "\n",
    "process_rank(\"test\", DATA, False, {   \"cached\" : True,\n",
    "                                    \"train_enhancement\": False,\n",
    "                                    \"gen_model\": False,\n",
    "                                    \"use_enhancement\": True,\n",
    "                                    \"enhancement_dataset\": \"train\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_submit(name, data):\n",
    "    \n",
    "    headers = ['id', 'answer']\n",
    "    \n",
    "    c_output_answer_set = data[name][\"c_output_answer_set\"]       \n",
    "\n",
    "    with open(name + '.submit.csv', 'w') as f:\n",
    "\n",
    "        f_csv = csv.DictWriter(f, headers)\n",
    "        f_csv.writeheader()\n",
    "\n",
    "        for index, result_c in enumerate(c_output_answer_set):\n",
    "            \n",
    "            predicted_answer = result_c[\"predicted_answer\"]\n",
    "            \n",
    "            if predicted_answer is not None:\n",
    "                f_csv.writerows([{'id':index+1,'answer':predicted_answer.encode(\"utf-8\")}])\n",
    "            else:\n",
    "                f_csv.writerows([{'id':index+1,'answer':\"NONE\"}])\n",
    "            \n",
    "#             if isinstance( answer_list[index]['answer'], int):\n",
    "                \n",
    "#                 f_csv.writerows([{'id':index+1,'answer':answer_list[index]['answer'][0][0]}])\n",
    "                \n",
    "#             else:\n",
    "                \n",
    "#                 f_csv.writerows([{'id':index+1,'answer':answer_list[index]['answer'][0][0].encode(\"utf-8\")}])        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "process_submit(\"rapid\", DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_submit(\"test\", DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_wrong_debug(name, data):\n",
    "    \n",
    "    question_set = data[name][\"question_set\"]\n",
    "    document_set = data[name][\"document_set\"]\n",
    "    rank_wrong = data[name][\"rank_wrong\"]\n",
    "    rank_correct = data[name][\"rank_correct\"]\n",
    "    \n",
    "    for i, result_wrong in enumerate(rank_correct):\n",
    "        \n",
    "        question = question_set[result_wrong[\"set_index\"]][result_wrong[\"question_index\"]]\n",
    "        candidate_sentence = document_set[result_wrong[\"set_index\"]][result_wrong[\"sentence_index\"]]\n",
    "        correct_sentence = document_set[result_wrong[\"set_index\"]][question[\"answer_sentence\"]]\n",
    "        \n",
    "        candidates = result_wrong[\"candidates\"]\n",
    "        ranked_answers = result_wrong[\"ranked_answers\"]\n",
    "        vector_ranked_answers = result_wrong[\"vector_ranked_answers\"]\n",
    "        predicted_answer = result_wrong[\"predicted_answer\"]\n",
    "        \n",
    "#         if i == 299:\n",
    "#         if question[\"answer_sentence\"] == result_wrong[\"sentence_index\"] and i % 100 == 0:\n",
    "        if question[\"answer\"].replace(\" \", \"\") in predicted_answer.replace(\" \", \"\"): # and i % 10 == 0:\n",
    "#             if len(set(question[\"answer\"].replace(\" \", \"\")).intersection(punct_tokens)) > 0:\n",
    "\n",
    "                print \"=\" * 20\n",
    "                print \"=\" * 20\n",
    "\n",
    "                print \"Question: \"\n",
    "                print\n",
    "                pp.pprint(question[\"question\"])\n",
    "\n",
    "                print\n",
    "                print \"Correct Sentence: (Part A)\"\n",
    "                print\n",
    "                pp.pprint(correct_sentence)\n",
    "                print\n",
    "                print \"Chosen Sentence: (Part A)\"\n",
    "                print\n",
    "                pp.pprint(candidate_sentence)\n",
    "                print\n",
    "\n",
    "                print \"Candidate Answers: (Part B)\"\n",
    "                print\n",
    "                pp.pprint(candidates)\n",
    "                print\n",
    "                print \"Ranked Answers: (Part C)\"\n",
    "                print\n",
    "                pp.pprint(ranked_answers)\n",
    "                print\n",
    "                print\n",
    "                print \"Vector Ranked Answers: (Part C)\"\n",
    "                print\n",
    "                pp.pprint(vector_ranked_answers)\n",
    "                print            \n",
    "                print \"Predicted Answer: (Part C)\"\n",
    "                print\n",
    "                pp.pprint(predicted_answer)\n",
    "                print\n",
    "                print \"Correct Answer: (Part C)\"\n",
    "                print\n",
    "                pp.pprint(question[\"answer\"])     \n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# log_wrong_debug(\"rapid\", DATA)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
