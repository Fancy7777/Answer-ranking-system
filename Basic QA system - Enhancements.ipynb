{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in the python script containing the same code as the load the data notebook\n",
    "%run loadData.py\n",
    "# now we can access train, dev, and test\n",
    "# along with trainSents, devSents testSents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shim names for later clean\n",
    "\n",
    "train_question_set = train\n",
    "train_document_set = trainSents\n",
    "\n",
    "dev_question_set = dev\n",
    "dev_document_set = devSents\n",
    "\n",
    "test_question_set = test\n",
    "test_document_set = testSents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rapid_size = 1\n",
    "\n",
    "rapid_question_set = train_question_set[:rapid_size]\n",
    "rapid_document_set = train_document_set[:rapid_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shim for easier name spacing\n",
    "\n",
    "DATA = {\n",
    "    \"rapid\" : {\n",
    "            \"question_set\": rapid_question_set,\n",
    "            \"document_set\": rapid_document_set,\n",
    "    },\n",
    "    \"train\" : {\n",
    "            \"question_set\": train_question_set,\n",
    "            \"document_set\": train_document_set,\n",
    "    },\n",
    "    \"dev\" : {\n",
    "            \"question_set\": dev_question_set,\n",
    "            \"document_set\": dev_document_set,\n",
    "    },\n",
    "    \"test\" : {\n",
    "            \"question_set\": test_question_set,\n",
    "            \"document_set\": test_document_set,\n",
    "    }    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from string import punctuation  \n",
    "\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import csv\n",
    "\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Core functions\n",
    "\n",
    "classifier = './stanford/classifiers/english.all.3class.distsim.crf.ser.gz'\n",
    "jar = './stanford/stanford-ner.jar'\n",
    "\n",
    "sTagger = StanfordNERTagger(classifier,jar)\n",
    "\n",
    "punct_tokens = set(punctuation)\n",
    "extra_tokens = set([\"what\", \"where\", \"how\", \"when\", \"who\"])\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filter_tokens = extra_tokens.union(punct_tokens).union(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shim function for later clean\n",
    "\n",
    "def getQuestionType(question):\n",
    "    if 'Who' in question:\n",
    "        return \"PERSON\"\n",
    "    if 'where' in question:\n",
    "        return \"LOCATION\"\n",
    "    if 'How many' in question:\n",
    "        return \"NUMBER\"\n",
    "    if 'How much' in question:\n",
    "        return \"NUMBER\"\n",
    "    if 'When' in question:\n",
    "        return \"NUMBER\"\n",
    "    if 'what year' in question:\n",
    "        return \"NUMBER\"\n",
    "    else:\n",
    "        return \"O\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Shim function for later clean\n",
    "\n",
    "def getStanfordTagging(datasetName):\n",
    "    fnameTrain = './preCompTags/stanfordTaggedTrain.txt'\n",
    "    fnameDev = './preCompTags/stanfordTaggedDev.txt'\n",
    "    fnameTest = './preCompTags/stanfordTaggedTest.txt'\n",
    "    \n",
    "    theFilePath = ''\n",
    "    theSents = []\n",
    "    if (datasetName == 'train'):\n",
    "        theFilePath = fnameTrain\n",
    "        theSents = trainSents\n",
    "    elif (datasetName == 'dev'):\n",
    "        theFilePath = fnameDev\n",
    "        theSents = devSents\n",
    "    elif (datasetName == 'test'):\n",
    "        theFilePath = fnameTest\n",
    "        theSents = testSents\n",
    "    else :\n",
    "        raise ValueError('Incorrect datasetName: ' + datasetName + ', choose from - \"train\", \"dev\", \"test\" ') \n",
    "    if (os.path.exists(theFilePath)):\n",
    "        with open(theFilePath, \"rb\") as fp:\n",
    "            stanfordTags = pickle.load(fp)\n",
    "            return stanfordTags\n",
    "    \n",
    "    else :\n",
    "        #Need to create taggings!\n",
    "        taggedSentsList = []\n",
    "        for sents in theSents:\n",
    "            tokenisedSents = [word_tokenize(sent) for sent in sents]\n",
    "            classifiedSents = sTagger.tag_sents(tokenisedSents)\n",
    "            taggedSentsList.append(classifiedSents)\n",
    "        #And save them\n",
    "        with open(theFilePath, \"wb\") as fp: \n",
    "            pickle.dump(taggedSentsList, fp)\n",
    "        return taggedSentsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_train_set = getStanfordTagging('train')\n",
    "tagged_dev_set = getStanfordTagging('dev')\n",
    "tagged_test_set = getStanfordTagging('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_rapid_set = tagged_train_set[:rapid_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shim for easier name spacing\n",
    "\n",
    "DATA[\"rapid\"][\"tagged_set\"] = tagged_rapid_set\n",
    "DATA[\"train\"][\"tagged_set\"] = tagged_train_set\n",
    "DATA[\"dev\"][\"tagged_set\"] = tagged_dev_set\n",
    "DATA[\"test\"][\"tagged_set\"] = tagged_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From: WSTA_N10_word_vectors\n",
    "\n",
    "import gensim\n",
    "from nltk.data import find\n",
    "\n",
    "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))\n",
    "word2vec_model = gensim.models.Word2Vec.load_word2vec_format(word2vec_sample, binary=False) # Use this if newer gensim: gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing tuning functions\n",
    "\n",
    "# Follow lemmatize function from guide notebook: WSTA_N1B_preprocessing.ipynb\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "word_tokenizer = nltk.tokenize.WordPunctTokenizer() #word_tokenize #tokenize.regexp.WordPunctTokenizer()\n",
    "\n",
    "def lemmatize(word):\n",
    "    lemma = lemmatizer.lemmatize(word,'v')\n",
    "    if lemma == word:\n",
    "        lemma = lemmatizer.lemmatize(word,'n')\n",
    "    return lemma\n",
    "\n",
    "def pre_process_tf_idf(line):\n",
    "    tokenized_sentence = word_tokenizer.tokenize(line.lower())\n",
    "    lemmatized_sentence = [lemmatize(token) for token in tokenized_sentence]\n",
    "    filtered_sentence = [token for token in lemmatized_sentence if token not in filter_tokens]\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Core functions\n",
    "\n",
    "def vectorize_documents(text_documents):\n",
    "\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', tokenizer=pre_process_tf_idf)\n",
    "    vector_documents = vectorizer.fit_transform(text_documents)\n",
    "    \n",
    "    return [vector_documents, vectorizer]\n",
    "\n",
    "def vectorize_query(vectorizer, text_query):\n",
    "    return vectorizer.transform([text_query])\n",
    "\n",
    "def process_neighbours(vector_documents):\n",
    "    \n",
    "    neighbours = NearestNeighbors(1, algorithm=\"brute\", metric=\"cosine\")\n",
    "    neighbours.fit(vector_documents)\n",
    "    \n",
    "    return neighbours\n",
    "\n",
    "def closest_document(neighbours, vector_query):\n",
    "\n",
    "    result = neighbours.kneighbors(vector_query, 1, return_distance=True)\n",
    "\n",
    "    result_index = result[1][0][0]\n",
    "    result_distance = result[0][0][0]\n",
    "    \n",
    "    return [result_distance, result_index]\n",
    "\n",
    "def closest_documents(neighbours, vector_query, n):\n",
    "\n",
    "    result = neighbours.kneighbors(vector_query, n, return_distance=True)\n",
    "\n",
    "    result_indices = result[1][0]\n",
    "    result_distances = result[0][0]\n",
    "    \n",
    "    return sorted(zip(result_indices, result_distances), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model, datasets    \n",
    "from sklearn import cross_validation \n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_results(predictions, classifications):\n",
    "    print \"Accuracy: \", accuracy_score(classifications, predictions)\n",
    "    print classification_report(classifications, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(name, data) :\n",
    "\n",
    "    vec = DATA[name][\"X_vec\"]\n",
    "    X = DATA[name][\"X\"]\n",
    "    Y = DATA[name][\"Y\"]\n",
    "\n",
    "    clf = linear_model.LogisticRegression(C=1e5)\n",
    "#     clf = AdaBoostClassifier(n_estimators=100)\n",
    "#     clf = RandomForestClassifier(n_estimators=10)\n",
    "    #clf = svm.SVC()\n",
    "#     clf = GaussianNB()\n",
    "    \n",
    "    print \"Model: \", clf\n",
    "    \n",
    "    print\n",
    "    print \"Data Slice: \"\n",
    "    print\n",
    "    print \"Shape X/Y: \", X.shape, Y.shape\n",
    "    print \"Types X: \", vec.get_feature_names() \n",
    "    print \"Example X: \", X[0]\n",
    "    print \"Example Y: \", Y[0]\n",
    "    print\n",
    "    print \"Training model...\"\n",
    "    \n",
    "    clf.fit(X,Y)\n",
    "    \n",
    "    print \"Cross validating...\"\n",
    "\n",
    "    predictions = cross_validation.cross_val_predict(clf, X, Y, cv=10)\n",
    "    \n",
    "    print\n",
    "    print \"Model results: \"\n",
    "    print\n",
    "\n",
    "    check_results(predictions, Y)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_w2v(x):\n",
    "    return word2vec_model.vocab.get(x) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_sentences(sentences):\n",
    "    \n",
    "    vector_sentences, vectorizer = vectorize_documents(sentences)\n",
    "    analyze = vectorizer.build_analyzer()\n",
    "    neighbours = process_neighbours(vector_sentences)\n",
    "       \n",
    "    return {\n",
    "            \"vector_sentences\": vector_sentences,\n",
    "            \"vectorizer\": vectorizer,\n",
    "            \"analyze\": analyze,\n",
    "            \"neighbours\": neighbours\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_feature(candidate_result, question, question_text_vector, analyze, sentences, y_sup=False):\n",
    "    \n",
    "    text_query = question[\"question\"]\n",
    "        \n",
    "    result_index = candidate_result[0]\n",
    "    result_distance = candidate_result[1]    \n",
    "    \n",
    "    result_text_vector = set(filter(f_w2v, analyze(sentences[result_index])))\n",
    "\n",
    "    if len(question_text_vector) > 0 and len(result_text_vector) > 0:\n",
    "\n",
    "        current_w2v_simil = word2vec_model.n_similarity(question_text_vector, result_text_vector)\n",
    "        question_type = getQuestionType(text_query)\n",
    "\n",
    "        new_x = {\n",
    "                \"tf-idf\": result_distance, \n",
    "                \"w2v\": current_w2v_simil,\n",
    "                \"qtype\": question_type,\n",
    "                \"len_sent\": len(sentences[result_index])\n",
    "        }\n",
    "\n",
    "        new_y = None\n",
    "        \n",
    "        if not y_sup:\n",
    "            new_y = int(result_index == question[\"answer_sentence\"])\n",
    "\n",
    "        return [new_x, new_y]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_enhancement(question, neighbours, vector_query, analyze, sentences, y_sup=False):\n",
    "    \n",
    "    text_query = question[\"question\"]\n",
    "    question_text_vector = set(filter(f_w2v, analyze(text_query)))\n",
    "    \n",
    "    candidate_results = closest_documents(neighbours, vector_query, 5)\n",
    "    features = filter(None, [process_feature(x, question, question_text_vector, analyze, sentences, y_sup) for x in candidate_results])\n",
    "    \n",
    "    return {\n",
    "        \"candidate_results\": candidate_results,\n",
    "        \"features\": features\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_query(question, vectorizer, neighbours, analyze):\n",
    "    \n",
    "    text_query = question[\"question\"]\n",
    "    vector_query = vectorize_query(vectorizer, text_query)\n",
    "\n",
    "    result_distance, result_index = closest_document(neighbours, vector_query)\n",
    "    \n",
    "    return {\n",
    "            \"vector_query\": vector_query,\n",
    "            \"result_distance\": result_distance,\n",
    "            \"result_index\": result_index\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_part_a_output(name, data, args):\n",
    "    \n",
    "    cached = args.get(\"cached\")\n",
    "    \n",
    "    use_enhancement = args.get(\"use_enhancement\")\n",
    "    train_enhancement = args.get(\"train_enhancement\")\n",
    "    \n",
    "    enhancement_dataset = args.get(\"enhancement_dataset\")\n",
    "    \n",
    "    y_sup = args.get(\"y_sup\")\n",
    "    \n",
    "    question_set = data[name][\"question_set\"]\n",
    "    document_set = data[name][\"document_set\"]\n",
    "    \n",
    "    part_a_output = []\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    cache_dict = None\n",
    "    \n",
    "    if cached:\n",
    "        \n",
    "        cache_dict = data[name][\"part_a_cache_dict\"]\n",
    "        \n",
    "#         X = data[name][\"X\"]\n",
    "#         Y = data[name][\"Y\"]        \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        cache_dict = {}\n",
    "        \n",
    "        cache_dict[\"sen_cache\"] = []\n",
    "        \n",
    "        cache_dict[\"query_cache\"] = []\n",
    "        \n",
    "        if use_enhancement:\n",
    "            \n",
    "            cache_dict[\"enhancement_cache\"] = []\n",
    "                \n",
    "        \n",
    "    for i, questions in enumerate(question_set):\n",
    "        \n",
    "        sentences = document_set[i]\n",
    "        \n",
    "        sen_cache = None\n",
    "\n",
    "        if cached:\n",
    "            \n",
    "            sen_cache_item = cache_dict[\"sen_cache\"][i]\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            sen_cache_item = process_sentences(sentences)\n",
    "            cache_dict[\"sen_cache\"].append(sen_cache_item)\n",
    "            \n",
    "            cache_dict[\"query_cache\"].append([])\n",
    "            \n",
    "            if use_enhancement:\n",
    "                \n",
    "                cache_dict[\"enhancement_cache\"].append([])\n",
    "\n",
    "        for j, question in enumerate(questions):\n",
    "            \n",
    "            query_cache_item = None\n",
    "            result_index = None\n",
    "            \n",
    "            if cached:\n",
    "                \n",
    "                query_cache_item = cache_dict[\"query_cache\"][i][j]\n",
    "                result_index = query_cache_item[\"result_index\"]\n",
    "                \n",
    "                if use_enhancement:\n",
    "                    \n",
    "                    enhancement_cache_item = cache_dict[\"enhancement_cache\"][i][j]\n",
    "\n",
    "                    model = data[enhancement_dataset][\"model\"]\n",
    "                    vec = data[enhancement_dataset][\"X_vec\"]\n",
    "\n",
    "                    candidate_results = enhancement_cache_item[\"candidate_results\"]\n",
    "                    new_xs = [feature[0] for feature in enhancement_cache_item[\"features\"]]\n",
    "\n",
    "                    if len(new_xs) > 0:\n",
    "\n",
    "                        new_features = vec.transform(new_xs).toarray()\n",
    "\n",
    "                        prob_ys = model.predict_proba(new_features)\n",
    "                        best_y_index = np.argmax(prob_ys[:, 1])\n",
    "\n",
    "                        result_index = candidate_results[best_y_index][0]\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                query_cache_item = process_query(question, sen_cache_item[\"vectorizer\"], sen_cache_item[\"neighbours\"], sen_cache_item[\"analyze\"])\n",
    "                cache_dict[\"query_cache\"][i].append(query_cache_item)\n",
    "                \n",
    "                result_index = query_cache_item[\"result_index\"]\n",
    "                \n",
    "                if use_enhancement:\n",
    "                    \n",
    "                    enhancement_cache_item = process_enhancement(question, sen_cache_item[\"neighbours\"], query_cache_item[\"vector_query\"], sen_cache_item[\"analyze\"], sentences, y_sup)\n",
    "                    cache_dict[\"enhancement_cache\"][i].append(enhancement_cache_item)                    \n",
    "                \n",
    "                if train_enhancement:\n",
    "\n",
    "                    new_xs = [feature[0] for feature in enhancement_cache_item[\"features\"]]\n",
    "                    new_ys = [feature[1] for feature in enhancement_cache_item[\"features\"]]\n",
    "\n",
    "                    X += new_xs\n",
    "                    Y += new_ys\n",
    "            \n",
    "            result = {\n",
    "                \"set_index\" : i,\n",
    "                \"question_index\" : j,\n",
    "                \"sentence_index\" : result_index\n",
    "            }\n",
    "\n",
    "            part_a_output.append(result)\n",
    "            \n",
    "#             if j > 1:\n",
    "#                 break\n",
    "                \n",
    "#         if i > 1:\n",
    "#             break\n",
    "            \n",
    "    if not cached:\n",
    "        \n",
    "        data[name][\"part_a_cache_dict\"] = cache_dict\n",
    "        \n",
    "        if train_enhancement:\n",
    "        \n",
    "            vec = DictVectorizer()                \n",
    "            X = vec.fit_transform(X).toarray()\n",
    "            Y = np.array(Y)\n",
    "\n",
    "            data[name][\"X_vec\"] = vec\n",
    "            data[name][\"X\"] = X\n",
    "            data[name][\"Y\"] = Y\n",
    "\n",
    "            print \"Shape X/Y: \", data[name][\"X\"].shape, data[name][\"Y\"].shape\n",
    "            print \"Types X: \", vec.get_feature_names()        \n",
    "            print \"Example X: \", X[0]\n",
    "            print \"Example Y: \", Y[0]        \n",
    "        \n",
    "    return part_a_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_part_a(name, data, args):\n",
    "    \n",
    "    data[name][\"a_output_answer_set\"] = generate_part_a_output(name, data, args)\n",
    "    \n",
    "    gen_model = args.get(\"gen_model\")\n",
    "    \n",
    "    if gen_model:\n",
    "        data[name][\"model\"] = train_model(name, data)\n",
    "    \n",
    "    print\n",
    "    print \"Part A Output: \"\n",
    "    print\n",
    "    pp.pprint(data[name][\"a_output_answer_set\"][:rapid_size])\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shim function for later clean\n",
    "\n",
    "def evaluate_retrieval(name, data, args):\n",
    "    \n",
    "    question_set = data[name][\"question_set\"]\n",
    "    a_output_answer_set = data[name][\"a_output_answer_set\"]\n",
    "    \n",
    "    correct = []\n",
    "    wrong = []\n",
    "    \n",
    "    for result_a in a_output_answer_set:\n",
    "        \n",
    "        question = question_set[result_a[\"set_index\"]][result_a[\"question_index\"]]\n",
    "        \n",
    "        answer_sentence = question[\"answer_sentence\"]\n",
    "        predicted_answer_sentence = result_a[\"sentence_index\"]\n",
    "        \n",
    "        if answer_sentence == predicted_answer_sentence:\n",
    "            correct.append(result_a)\n",
    "        else:\n",
    "            wrong.append(result_a)\n",
    "        \n",
    "#         break\n",
    "            \n",
    "    return (correct, wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_generic(name, data, process_type, process_func, args):\n",
    "\n",
    "    (correct, wrong) = process_func(name, data, args)\n",
    "    \n",
    "    data[name][process_type + \"_correct\"] = correct\n",
    "    data[name][process_type + \"_wrong\"] = wrong\n",
    "#     data[name][process_type + \"_full\"] = full\n",
    "    \n",
    "    total = len(correct) + len(wrong)\n",
    "    avg = len(correct) * 1.0 / total\n",
    "    \n",
    "    print process_type.capitalize() + \" Correct: \", len(correct)\n",
    "    print process_type.capitalize() + \" Wrong: \", len(wrong)\n",
    "    print process_type.capitalize() + \" Total: \", total\n",
    "    print process_type.capitalize() + \" Overall Average %: \", avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_retrieval(name, data, stats=False, args={}):\n",
    "    print \"Processing retrieval: \", name\n",
    "    process_part_a(name, data, args)\n",
    "    if stats:\n",
    "        process_generic(name, data, \"retrieval\", evaluate_retrieval, args)\n",
    "        \n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing retrieval:  rapid\n",
      "\n",
      "Part A Output: \n",
      "\n",
      "[{   'question_index': 0, 'sentence_index': 149, 'set_index': 0}]\n",
      "\n",
      "Retrieval Correct:  156\n",
      "Retrieval Wrong:  248\n",
      "Retrieval Total:  404\n",
      "Retrieval Overall Average %:  0.386138613861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# process_retrieval(\"rapid\", DATA, True, {\"cached\" : False, \n",
    "#                                         \"train_enhancement\": True,\n",
    "#                                         \"use_enhancement\": True,\n",
    "#                                         \"enhancement_dataset\": \"rapid\",\n",
    "#                                         \"y_sup\": False,\n",
    "#                                         \"gen_model\": True})                                        \n",
    "\n",
    "# process_retrieval(\"rapid\", DATA, True, {\"cached\" : True, \n",
    "#                                         \"train_enhancement\": False,\n",
    "#                                         \"use_enhancement\": False,\n",
    "#                                         \"enhancement_dataset\": \"rapid\",\n",
    "#                                         \"y_sup\": False,\n",
    "#                                         \"gen_model\": True})\n",
    "\n",
    "process_retrieval(\"rapid\", DATA, True, {\"cached\" : True, \n",
    "                                        \"train_enhancement\": False,\n",
    "                                        \"use_enhancement\": False,\n",
    "                                        \"enhancement_dataset\": \"train\",\n",
    "                                        \"y_sup\": False,\n",
    "                                        \"gen_model\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing retrieval:  dev\n",
      "\n",
      "Part A Output: \n",
      "\n",
      "[{   'question_index': 0, 'sentence_index': 71, 'set_index': 0}]\n",
      "\n",
      "Retrieval Correct:  5246\n",
      "Retrieval Wrong:  3217\n",
      "Retrieval Total:  8463\n",
      "Retrieval Overall Average %:  0.619874748907\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# process_retrieval(\"dev\", DATA, True, {\"cached\" : False, \n",
    "#                                         \"train_enhancement\": True,\n",
    "#                                         \"use_enhancement\": True,\n",
    "#                                         \"enhancement_dataset\": \"dev\",\n",
    "#                                         \"y_sup\": False,\n",
    "#                                         \"gen_model\": True})                                      \n",
    "\n",
    "# process_retrieval(\"dev\", DATA, True, {   \"cached\" : True, \n",
    "#                                         \"train_enhancement\": False,\n",
    "#                                         \"use_enhancement\": False,\n",
    "#                                         \"enhancement_dataset\": \"dev\",\n",
    "#                                         \"y_sup\": False,\n",
    "#                                         \"gen_model\": True})                                      \n",
    "\n",
    "process_retrieval(\"dev\", DATA, True, {   \"cached\" : True, \n",
    "                                        \"train_enhancement\": False,\n",
    "                                        \"use_enhancement\": True,\n",
    "                                        \"enhancement_dataset\": \"train\",\n",
    "                                        \"y_sup\": False,\n",
    "                                        \"gen_model\": False})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing retrieval:  train\n",
      "\n",
      "Part A Output: \n",
      "\n",
      "[{   'question_index': 0, 'sentence_index': 253, 'set_index': 0}]\n",
      "\n",
      "Retrieval Correct:  45324\n",
      "Retrieval Wrong:  24835\n",
      "Retrieval Total:  70159\n",
      "Retrieval Overall Average %:  0.646018329794\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# process_retrieval(\"train\", DATA, True, {\"cached\" : False, \n",
    "#                                         \"train_enhancement\": True,\n",
    "#                                         \"use_enhancement\": True,\n",
    "#                                         \"enhancement_dataset\": \"train\",\n",
    "#                                         \"gen_model\": True})                                     \n",
    "\n",
    "# process_retrieval(\"train\", DATA, True, {\"cached\" : True, \n",
    "#                                         \"train_enhancement\": False,\n",
    "#                                         \"use_enhancement\": False,\n",
    "#                                         \"enhancement_dataset\": \"train\",\n",
    "#                                         \"y_sup\": False,\n",
    "#                                         \"gen_model\": True})                                        \n",
    "\n",
    "\n",
    "process_retrieval(\"train\", DATA, True, {\"cached\" : True, \n",
    "                                        \"train_enhancement\": False,\n",
    "                                        \"use_enhancement\": True,\n",
    "                                        \"enhancement_dataset\": \"train\",\n",
    "                                        \"y_sup\": False,\n",
    "                                        \"gen_model\": False})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing retrieval:  test\n",
      "\n",
      "Part A Output: \n",
      "\n",
      "[{   'question_index': 0, 'sentence_index': 353, 'set_index': 0}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# process_retrieval(\"test\", DATA, False, {\"cached\" : False, \n",
    "#                                         \"train_enhancement\": False,\n",
    "#                                         \"use_enhancement\": True,\n",
    "#                                         \"enhancement_dataset\": \"train\",\n",
    "#                                         \"y_sup\": True})                                       \n",
    "\n",
    "# process_retrieval(\"test\", DATA, False, {\"cached\" : True, \n",
    "#                                         \"train_enhancement\": False,\n",
    "#                                         \"use_enhancement\": False,\n",
    "#                                         \"enhancement_dataset\": \"train\",\n",
    "#                                         \"y_sup\": True})                                       \n",
    "\n",
    "process_retrieval(\"test\", DATA, False, {\"cached\" : True, \n",
    "                                        \"train_enhancement\": False,\n",
    "                                        \"use_enhancement\": True,\n",
    "                                        \"enhancement_dataset\": \"train\",\n",
    "                                        \"y_sup\": True})                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shim function for later clean\n",
    "\n",
    "# Thanks for this list to save me typing it : http://stackoverflow.com/questions/493174/is-there-a-way-to-convert-number-words-to-integers\\n\",\n",
    "numInWords = [\"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\",\n",
    "        \"nine\", \"ten\", \"eleven\", \"twelve\", \"thirteen\", \"fourteen\", \"fifteen\",\n",
    "        \"sixteen\", \"seventeen\", \"eighteen\", \"nineteen\", \"twenty\", \"thirty\", \"forty\", \"fifty\", \"sixty\", \"seventy\", \"eighty\", \"ninety\"\n",
    "       , \"hundred\", \"thousand\", \"million\", \"billion\", \"trillion\"]\n",
    "\n",
    "punctuation = [\"''\",'``','(','.',':', ',',')']\n",
    "\n",
    "\n",
    "months = [\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"]\n",
    "\n",
    "def isPunctuation(word):\n",
    "    return word in punctuation\n",
    "\n",
    "def isCapitalised (word):\n",
    "    if len(word) == 0:\n",
    "        return False\n",
    "    return word[0].isupper()\n",
    "\n",
    "# Obtained from training data\n",
    "postUnits = [u'%', u'century', u'years', u'percent', u'years ago', u'days', u'months', u'km', u'hours', u'times', u'inches', u'\\xb0C', u'minutes', u'acres', u'\\xb0F', u'weeks', u'people', u'sq mi', u'mi', u'ft', u'feet', u'metres', u'mm', u'square miles', u'miles', u'pm', u'per cent', u'year', u'copies', u'yuan', u'men', u'square feet', u'third', u'kilometres', u'nm', u'tonnes', u'species', u'decades', u'barrels', u'tons', u'largest', u'centuries', u'km2']\n",
    "preUnits = [u'$',u'around', u'late', u'early', u'nearly', u'since', u'approximately', u'number']\n",
    "\n",
    "# Returns true if the word represents a number\\n\",\n",
    "def isNumber(word):\n",
    "    pattern = \".?(\\\\d)+((,|.)(\\\\d)+)*\"\n",
    "    if re.match(pattern,word) :\n",
    "        return True\n",
    "    if word.lower() in numInWords:\n",
    "        return True\n",
    "    if word in months:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def isStopWord(word):\n",
    "    return word.lower() in stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grammar = \"\"\" ANS: {<JJ>?<N.*>*}\n",
    "                   {<DT>?<N.*>*}\n",
    "                   }<UH|POS|VB|VBG|RP|DT|MD|PRP$|TO|RB|JJS|PDT|IN|PRP|VBP|VBN|RBS|WRB|WP|EX|VBZ|WDT|VBD>{\n",
    "                    \"\"\"\n",
    "cp = nltk.RegexpParser(grammar) \n",
    "\n",
    "def chunk(words):\n",
    "    tokenWS = nltk.pos_tag(nltk.word_tokenize(words))\n",
    "    chunks =  cp.parse(tokenWS)\n",
    "    possAnswers = []\n",
    "    for subtree in chunks.subtrees():\n",
    "        if subtree.label() == 'ANS':\n",
    "            possAnswers.append((' '.join(word for word, pos in subtree.leaves()),'O'))\n",
    "    possAnswers.append((\"Nope\", \"CRAP\")) # To ensure nothing has 0 tags\n",
    "    return possAnswers    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_non_chunked_words_as_single_tags(words):\n",
    "    chunked_output = chunk(words)\n",
    "    token_words = nltk.pos_tag(nltk.word_tokenize(words))\n",
    "    if len(chunked_output) == 0:\n",
    "        chunked_words = [\"DEREKWANG\"]\n",
    "    else:\n",
    "        chunked_words = [nltk.word_tokenize(word_tag_pair[0]) for word_tag_pair in chunked_output ]    \n",
    "    all_word_tags = []\n",
    "    \n",
    "    current_chunk_index = 0\n",
    "    current_chunk_word = 0\n",
    "    current_chunk_list = chunked_words[0]\n",
    "    \n",
    "    for word_tag_pair in token_words:\n",
    "        word = word_tag_pair[0]\n",
    "        if word == current_chunk_list[current_chunk_word]:\n",
    "            # Need to move onto next word\n",
    "            if current_chunk_word == len(current_chunk_list) - 1:\n",
    "                # last word in this current chunk\n",
    "                all_word_tags.append(chunked_output[current_chunk_index])\n",
    "                current_chunk_index += 1\n",
    "                current_chunk_word = 0\n",
    "                if current_chunk_index == len(chunked_words):\n",
    "                    current_chunk_list = [\"NOPE\"]\n",
    "                else:\n",
    "                    current_chunk_list = chunked_words[current_chunk_index]\n",
    "            else :\n",
    "                current_chunk_word += 1\n",
    "        else :\n",
    "            # Need to add word, as it's not in a chunk :(\n",
    "            all_word_tags.append((word,'O'))\n",
    "    return all_word_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shim function for later clean\n",
    "\n",
    "def refine_word_tags(taggedWordList):\n",
    "    newWordTags = []\n",
    "    for (word, tag) in taggedWordList:\n",
    "        if (tag == 'ORGANIZATION'):\n",
    "            tag = 'O'\n",
    "        if (tag == 'O'):\n",
    "            #Might be a number\n",
    "            if isNumber(word):\n",
    "                tag = 'NUMBER'\n",
    "            elif word in preUnits:\n",
    "                tag = 'PRENUM'\n",
    "            elif isPunctuation(word):\n",
    "                tag = 'PUNC'\n",
    "            elif word in postUnits:\n",
    "                tag = 'POSTNUM'\n",
    "            elif isCapitalised(word):\n",
    "                tag = \"OTHERCAP\"\n",
    "        newWordTags.append((word, tag))\n",
    "    \n",
    "    newWordTags = combineTags (newWordTags)\n",
    "    other_processed_tags = process_others(newWordTags)\n",
    "    return other_processed_tags\n",
    "        \n",
    "def combineTags(wordTags):\n",
    "    \n",
    "    newTags = []\n",
    "    prevWord = wordTags[0][0]\n",
    "    prevTag = wordTags[0][1]\n",
    "    \n",
    "    for (word, tag) in wordTags[1:]:\n",
    "        if tag == 'NUMBER' and prevTag == 'PRENUM':\n",
    "            prevTag = 'NUMBER'\n",
    "        elif prevTag == 'PRENUM':\n",
    "            prevTag = 'O'\n",
    "        if tag == 'POSTNUM' and prevTag == \"NUMBER\":\n",
    "            tag = \"NUMBER\"\n",
    "        elif tag == \"POSTNUM\":\n",
    "            tag = \"O\"\n",
    "        newTags.append((prevWord, prevTag))\n",
    "        prevWord = word\n",
    "        prevTag = tag\n",
    "    newTags.append((prevWord, prevTag))\n",
    "        \n",
    "    newNewTags = []\n",
    "    prevWord = newTags[0][0]\n",
    "    prevTag = newTags[0][1]\n",
    "    if (prevTag == \"OTHERCAP\" and newTags[1][1] != \"OTHERCAP\"):\n",
    "        prevTag = \"O\"\n",
    "        \n",
    "    for (word, tag) in newTags[1:]:\n",
    "#         print tag, prevTag\n",
    "        if tag == prevTag :\n",
    "            if word == '%':\n",
    "                prevWord += word\n",
    "            else :\n",
    "                if prevWord == '$':\n",
    "                    prevWord += word\n",
    "                else :\n",
    "                    prevWord += ' ' + word\n",
    "        else :\n",
    "            newNewTags.append((prevWord, prevTag))\n",
    "            prevWord = word\n",
    "            prevTag = tag\n",
    "            \n",
    "    newNewTags.append((prevWord, prevTag))\n",
    "    \n",
    "    return newNewTags\n",
    "\n",
    "def process_others(words_with_tags):\n",
    "    new_taggings = []\n",
    "    for (words, tag) in words_with_tags:\n",
    "        if tag == 'O':\n",
    "            chunk_results = add_non_chunked_words_as_single_tags(words)\n",
    "            for (word,tag) in chunk_results:\n",
    "                new_taggings.append((word, tag))\n",
    "            #new_taggings.append((words,tag))\n",
    "        else :\n",
    "            new_taggings.append((words, tag))\n",
    "    return new_taggings\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tags1 = [   (u'Because', 'O'),\n",
    "#     (u'of', 'STOPWORD'),\n",
    "#     (u'financial hardships', u'O'),\n",
    "#     (u'that', 'STOPWORD'),\n",
    "#     (u'plagued', u'O'),\n",
    "#     (u'the', 'STOPWORD'),\n",
    "#     (u'recording industry', u'O'),\n",
    "#     (u'during that', 'STOPWORD'),\n",
    "#     (u'period (', u'O'),\n",
    "#     (u'and', 'STOPWORD'),\n",
    "#     (u'RCA', 'OTHERCAP'),\n",
    "#     (u\"'s\", u'O'),\n",
    "#     (u'own', 'STOPWORD'),\n",
    "#     (u'parched revenues )', u'O'),\n",
    "#     (u',', 'PUNC'),\n",
    "#     (u'Victor', u'PERSON'),\n",
    "#     (u\"'s long-playing records\", u'O'),\n",
    "#     (u'were', 'STOPWORD'),\n",
    "#     (u'discontinued', u'O'),\n",
    "#     (u'by', 'STOPWORD'),\n",
    "#     (u'early', 'PRENUM'),\n",
    "#     (u'1933', 'NUMBER'),\n",
    "#     (u'.', 'PUNC')]\n",
    "\n",
    "# tags2 = [   (u'At', 'O'),\n",
    "#     (u'the', 'STOPWORD'),\n",
    "#     (u'beginning', u'O'),\n",
    "#     (u'of the', 'STOPWORD'),\n",
    "#     (u'20th', 'NUMBER'),\n",
    "#     (u'century', 'POSTNUM'),\n",
    "#     (u',', 'PUNC'),\n",
    "#     (u'the', 'STOPWORD'),\n",
    "#     (u'early', 'PRENUM'),\n",
    "#     (u'discs played', u'O'),\n",
    "#     (u'for', 'STOPWORD'),\n",
    "#     (u'two', 'NUMBER'),\n",
    "#     (u'minutes', 'POSTNUM'),\n",
    "#     (u',', 'PUNC'),\n",
    "#     (u'the same as', 'STOPWORD'),\n",
    "#     (u'early', 'PRENUM'),\n",
    "#     (u'cylinder records', u'O'),\n",
    "#     (u'.', 'PUNC')]\n",
    "\n",
    "# tags3 = [       (u'early', 'PRENUM'),\n",
    "#     (u'1933', 'NUMBER'), (u'for', 'STOPWORD'),\n",
    "#     (u'two', 'NUMBER'),\n",
    "#     (u'minutes', 'POSTNUM'), ]\n",
    "\n",
    "# pp.pprint(combineTags(tags3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_part_b_output(name, data, args):\n",
    "    \n",
    "    question_set = data[name][\"question_set\"]\n",
    "    a_output_answer_set = data[name][\"a_output_answer_set\"]\n",
    "    tagged_set = data[name][\"tagged_set\"]\n",
    "    \n",
    "    part_b_output = []\n",
    "    \n",
    "    for result_a in a_output_answer_set:\n",
    "        \n",
    "        stanford_tags = tagged_set[result_a[\"set_index\"]][result_a[\"sentence_index\"]]\n",
    "        \n",
    "        filtered_tags = refine_word_tags(stanford_tags)\n",
    "        \n",
    "        question = question_set[result_a[\"set_index\"]][result_a[\"question_index\"]][\"question\"]\n",
    "        \n",
    "        result_b = {\n",
    "            \"set_index\"  : result_a[\"set_index\"],\n",
    "            \"question_index\" : result_a[\"question_index\"],\n",
    "            \"sentence_index\" : result_a[\"sentence_index\"],\n",
    "            \"candidates\" : filtered_tags\n",
    "        }\n",
    "        \n",
    "        part_b_output.append(result_b)\n",
    "        \n",
    "    return part_b_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_part_b(name, data, args):\n",
    "    \n",
    "    data[name][\"b_output_answer_set\"] = generate_part_b_output(name, data, args)\n",
    "    \n",
    "    print\n",
    "    print \"Part B Output: \"\n",
    "    pp.pprint(data[name][\"b_output_answer_set\"][:rapid_size])\n",
    "    print    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Shim function for later clean\n",
    "\n",
    "def evaluate_ner(name, data, args):\n",
    "    \n",
    "    question_set = data[name][\"question_set\"]\n",
    "    b_output_answer_set = data[name][\"b_output_answer_set\"]\n",
    "    \n",
    "    correct = []\n",
    "    wrong = []\n",
    "    \n",
    "    for result_b in b_output_answer_set:\n",
    "        \n",
    "        answer = question_set[result_b[\"set_index\"]][result_b[\"question_index\"]][\"answer\"]\n",
    "        \n",
    "        possible_candidates = result_b[\"candidates\"]\n",
    "        \n",
    "        answer_exists_in_candidates = False\n",
    "        \n",
    "        for candidate in possible_candidates:\n",
    "            \n",
    "            candidate_string = candidate[0]\n",
    "            \n",
    "            if candidate_string == answer:\n",
    "                \n",
    "                answer_exists_in_candidates = True\n",
    "                \n",
    "                break\n",
    "        \n",
    "        if answer_exists_in_candidates:\n",
    "            correct.append(result_b)\n",
    "        else :\n",
    "            wrong.append(result_b)\n",
    "            \n",
    "    return (correct, wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_ner(name, data, stats=False, args={}):\n",
    "    print \"Processing ner: \", name\n",
    "    process_part_b(name, data, args)\n",
    "    if stats:\n",
    "        process_generic(name, data, \"ner\", evaluate_ner, args)\n",
    "        \n",
    "        correct_ner = len(data[name][\"ner_correct\"])\n",
    "        correct_ret = len(data[name][\"retrieval_correct\"])\n",
    "        \n",
    "        avg = correct_ner * 1.0 / correct_ret\n",
    "        \n",
    "        print \"ner\".capitalize() + \" Correct Average of Previous %: \", avg\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ner:  rapid\n",
      "\n",
      "Part B Output: \n",
      "[   {   'candidates': [   (u'They', 'O'),\n",
      "                          (u'had', 'O'),\n",
      "                          (u'a', 'O'),\n",
      "                          (u'playing time', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'eight minutes', 'NUMBER'),\n",
      "                          (u'.', 'PUNC')],\n",
      "        'question_index': 0,\n",
      "        'sentence_index': 149,\n",
      "        'set_index': 0}]\n",
      "\n",
      "Ner Correct:  75\n",
      "Ner Wrong:  329\n",
      "Ner Total:  404\n",
      "Ner Overall Average %:  0.185643564356\n",
      "Ner Correct Average of Previous %:  0.480769230769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_ner(\"rapid\", DATA, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ner:  dev\n",
      "Warning: parsing empty text\n",
      "\n",
      "Part B Output: \n",
      "[   {   'candidates': [   (u'Infrared', 'O'),\n",
      "                          (u'is', 'O'),\n",
      "                          (u'used', 'O'),\n",
      "                          (u'in', 'O'),\n",
      "                          (u'night vision equipment', 'O'),\n",
      "                          (u'when', 'O'),\n",
      "                          (u'there', 'O'),\n",
      "                          (u'is', 'O'),\n",
      "                          (u'insufficient', 'O'),\n",
      "                          (u'visible light', 'O'),\n",
      "                          (u'to', 'O'),\n",
      "                          (u'see', 'O'),\n",
      "                          (u'.', 'PUNC')],\n",
      "        'question_index': 0,\n",
      "        'sentence_index': 71,\n",
      "        'set_index': 0}]\n",
      "\n",
      "Ner Correct:  2846\n",
      "Ner Wrong:  5617\n",
      "Ner Total:  8463\n",
      "Ner Overall Average %:  0.336287368545\n",
      "Ner Correct Average of Previous %:  0.542508577964\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_ner(\"dev\", DATA, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# process_ner(\"train\", DATA, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ner:  test\n",
      "Warning: parsing empty text\n",
      "\n",
      "Part B Output: \n",
      "[   {   'candidates': [   (u'The Crimean War', 'OTHERCAP'),\n",
      "                          (u'marked', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'ascendancy', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'France', u'LOCATION'),\n",
      "                          (u'to', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'position', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'pre-eminent power', 'O'),\n",
      "                          (u'on', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'Continent', 'OTHERCAP'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u':411', 'NUMBER'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'continued decline', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'Ottoman Empire', 'OTHERCAP'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'and', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'beginning', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'a', 'O'),\n",
      "                          (u'decline', 'O'),\n",
      "                          (u'for', 'O'),\n",
      "                          (u'Tsarist', 'OTHERCAP'),\n",
      "                          (u'Russia', u'LOCATION'),\n",
      "                          (u'.', 'PUNC')],\n",
      "        'question_index': 0,\n",
      "        'sentence_index': 353,\n",
      "        'set_index': 0}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_ner(\"test\", DATA, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, answers whose content words all appear in the question should be ranked lowest.\n",
    "\n",
    "def first_filter(question, answer_entities):\n",
    "   \n",
    "    ranked_list = []\n",
    "    \n",
    "    question = set(pre_process_tf_idf(question))\n",
    "    \n",
    "#     print question\n",
    "#     print\n",
    "    \n",
    "    for entity in answer_entities:\n",
    "\n",
    "        raw_span = entity[0]\n",
    "        span_tag = entity[1]\n",
    "        \n",
    "        set_span = set(pre_process_tf_idf(raw_span))\n",
    "        \n",
    "        if span_tag != \"O\" and span_tag != \"STOPWORD\" and span_tag !=\"PUNC\":\n",
    "            \n",
    "            if set_span.issubset(question):\n",
    "                \n",
    "                ranked_list.append([entity, 1])\n",
    "#                 print \"IN\", raw_span, span_tag, set_span, question\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                ranked_list.append([entity, 2])\n",
    "#                 print \"OUT\", raw_span, span_tag, set_span, question\n",
    "    \n",
    "    return sorted(ranked_list, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, answers whose content words all appear in the question should be ranked lowest.\n",
    "\n",
    "def first_filter_object(question, answer_entities):\n",
    "   \n",
    "    ranked_list = []\n",
    "    \n",
    "    question = set(pre_process_tf_idf(question))\n",
    "    \n",
    "#     print question\n",
    "#     print\n",
    "    \n",
    "    for entity in answer_entities:\n",
    "\n",
    "        raw_span = entity[0]\n",
    "        span_tag = entity[1]\n",
    "        \n",
    "        set_span = set(pre_process_tf_idf(raw_span))\n",
    "        \n",
    "        if span_tag != \"STOPWORD\" and span_tag !=\"PUNC\": #span_tag != \"O\" and\n",
    "            \n",
    "            if span_tag == \"O\":\n",
    "                \n",
    "                if len(set_span) > 1:\n",
    "                    ranked_list.append([entity, 0])\n",
    "            \n",
    "            elif set_span.issubset(question):\n",
    "                \n",
    "                ranked_list.append([entity, 1])\n",
    "#                 print \"IN\", raw_span, span_tag, set_span, question\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                ranked_list.append([entity, 2])\n",
    "#                 print \"OUT\", raw_span, span_tag, set_span, question\n",
    "    \n",
    "    return sorted(ranked_list, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, answers whose content words all appear in the question should be ranked lowest.\n",
    "\n",
    "def first_filter_object_stop(question, answer_entities):\n",
    "   \n",
    "    ranked_list = []\n",
    "    \n",
    "    question = set(pre_process_tf_idf(question))\n",
    "    \n",
    "#     print question\n",
    "#     print\n",
    "    \n",
    "    for entity in answer_entities:\n",
    "\n",
    "        raw_span = entity[0]\n",
    "        span_tag = entity[1]\n",
    "        \n",
    "        set_span = set(pre_process_tf_idf(raw_span))\n",
    "        \n",
    "        if span_tag !=\"PUNC\": #span_tag != \"O\" and\n",
    "            \n",
    "            if span_tag == \"O\" or span_tag == \"STOPWORD\":\n",
    "                \n",
    "                if len(set_span) > 1:\n",
    "                    \n",
    "                    ranked_list.append([entity, 0])\n",
    "            \n",
    "            elif set_span.issubset(question):\n",
    "                \n",
    "                ranked_list.append([entity, 1])\n",
    "#                 print \"IN\", raw_span, span_tag, set_span, question\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                ranked_list.append([entity, 2])\n",
    "#                 print \"OUT\", raw_span, span_tag, set_span, question\n",
    "    \n",
    "    return sorted(ranked_list, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Second, answers which match the question type should be ranked higher than those that don't; for this, you\n",
    "# should build a simple rule-based question type classifier based on key words (e.g. questions which contain \"who\" are\n",
    "# people).\n",
    "\n",
    "# First, answers whose content words all appear in the question should be ranked lowest.\n",
    "\n",
    "def second_filter(question, ranked_list):\n",
    "   \n",
    "    question_type = getQuestionType(question)\n",
    "#     print question_type\n",
    "    \n",
    "    for index, answer in enumerate(ranked_list):\n",
    "        \n",
    "        entity_tag = answer[0][1]\n",
    "        \n",
    "        if entity_tag == question_type:\n",
    "#             print \"MATCH\", answer[0], question_type, question\n",
    "            ranked_list[index].append(2)\n",
    "#             ranked_list[index][1] += 1\n",
    "        else:\n",
    "            ranked_list[index].append(1)\n",
    "#             ranked_list[index][1] -= 1\n",
    "            \n",
    "    return ranked_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pre_process_open_class(line):\n",
    "    tokenized_sentence = word_tokenizer.tokenize(line.lower())\n",
    "    lemmatized_sentence = [lemmatize(token) for token in tokenized_sentence]\n",
    "    filtered_sentence = [token for token in lemmatized_sentence if token not in filter_tokens]\n",
    "    tagged_sent = nltk.pos_tag(lemmatized_sentence)\n",
    "    final = []\n",
    "       \n",
    "    for word, tag in tagged_sent:\n",
    "        #expand the open-class word to noun,verb,adj and adv\n",
    "        if \"V\" in tag or \"NN\" in tag or 'JJ' in tag or 'RB' in tag:\n",
    "#             final.append((word,tag))\n",
    "            final.append(word)\n",
    "            \n",
    "#     print \"RESULT: \", final\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Third, among entities of the same type, the prefered entity should be the one which is closer in the sentence to a\n",
    "# closed-class word from the question.\n",
    "\n",
    "def third_filter(question, possAnswers, ranked_list):\n",
    "    \n",
    "    question = pre_process_open_class(question)\n",
    "\n",
    "    answer_sent = \" \".join([x[0] for x in possAnswers])\n",
    "    answer_sent = pre_process_tf_idf(answer_sent)\n",
    "    raw_answer_sent = \" \".join(answer_sent)\n",
    "    \n",
    "#     print \"QUESTION: \"\n",
    "#     pp.pprint(question)\n",
    "#     print \"ANSWER: \"\n",
    "#     pp.pprint(answer_sent)\n",
    "#     pp.pprint(raw_answer_sent)\n",
    "    \n",
    "    for index, answer in enumerate(ranked_list):\n",
    "\n",
    "        span_tag = answer[0][1]\n",
    "        raw_span = answer[0][0]\n",
    "\n",
    "        proc_span = pre_process_tf_idf(raw_span)\n",
    "\n",
    "        raw_proc_span = \" \".join(proc_span)\n",
    "        new_raw_proc_span = \"-\".join(proc_span)\n",
    "\n",
    "        raw_answer_sent = raw_answer_sent.replace(raw_proc_span, new_raw_proc_span)\n",
    "    \n",
    "    answer_sent = raw_answer_sent.split(\" \")\n",
    "    \n",
    "    avg_dict = defaultdict(float)\n",
    "    \n",
    "    for open_class in question:\n",
    "        \n",
    "        if open_class in answer_sent:\n",
    "            \n",
    "            open_class_locations = [i for i, x in enumerate(answer_sent) if x == open_class]\n",
    "            \n",
    "#             print \"OPEN CLASS: \", repr(open_class)\n",
    "\n",
    "            for index, answer in enumerate(ranked_list):\n",
    "\n",
    "                span_tag = answer[0][1]\n",
    "                raw_span = answer[0][0]\n",
    "\n",
    "                proc_span = pre_process_tf_idf(raw_span)\n",
    "                \n",
    "                raw_proc_span = \" \".join(proc_span)\n",
    "                new_raw_proc_span = \"-\".join(proc_span)\n",
    "                \n",
    "                proc_span_locations = [i for i, x in enumerate(answer_sent) if x == new_raw_proc_span]\n",
    "                \n",
    "                min_dist = len(answer_sent)\n",
    "                min_dist_ind = (None, None)\n",
    "                \n",
    "                for loc1 in proc_span_locations:\n",
    "                    \n",
    "                    for loc2 in open_class_locations:\n",
    "                        \n",
    "                        dist = abs(loc1 - loc2)\n",
    "                        \n",
    "                        if dist < min_dist:\n",
    "                            \n",
    "                            min_dist = dist\n",
    "                            min_dist_ind = (loc1, loc2)\n",
    "                \n",
    "#                 print \"PROC: \", proc_span_locations\n",
    "#                 print \"OPEN CLASS: \", open_class_locations                \n",
    "                scale = (len(answer_sent) - min_dist) * 1.0 / len(answer_sent)\n",
    "#                 print \"JOINT: \", min_dist_ind, scale\n",
    "                avg_dict[index] += scale\n",
    "#                 ranked_list[index][1] *= scale\n",
    "    \n",
    "    for key, value in avg_dict.iteritems():\n",
    "        ranked_list[key].append(value / len(question))\n",
    "\n",
    "    return ranked_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduce_rank(ranking_list):\n",
    "    \n",
    "    new_ranking = []\n",
    "    \n",
    "    for rank in ranking_list:\n",
    "        \n",
    "        new_rank = ( rank[1] + rank[2] )\n",
    "        \n",
    "        if len(rank) == 4:\n",
    "             new_rank *= rank[3]\n",
    "        \n",
    "        new_ranking.append([rank[0], new_rank])\n",
    "        \n",
    "    return sorted(new_ranking, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_result(fourth_pass):\n",
    "    top_answer = fourth_pass[0]\n",
    "    predicted_answer = top_answer[0][0]    \n",
    "    \n",
    "    return predicted_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def multi_pass(first_filter_funcs, question, candidates, mem=None):\n",
    "    \n",
    "    if len(first_filter_funcs) > 0:\n",
    "    \n",
    "        first_pass = first_filter_funcs.pop(0)(question, candidates)\n",
    "\n",
    "        second_pass = second_filter(question, first_pass)\n",
    "\n",
    "        third_pass = third_filter(question, candidates, second_pass)\n",
    "\n",
    "        fourth_pass = reduce_rank(third_pass)\n",
    "\n",
    "        if len(fourth_pass) > 0:\n",
    "            \n",
    "            predicted_answer = get_result(fourth_pass)\n",
    "            \n",
    "            return [fourth_pass, third_pass, predicted_answer]\n",
    "        else:\n",
    "            return multi_pass(first_filter_funcs, question, candidates, [fourth_pass, third_pass])\n",
    "    else:\n",
    "        \n",
    "        hits = [x for x in candidates if x[1] != \"PUNC\" or x[1] == \"STOPWORDS\"]                        \n",
    "        predicted_answer = random.choice(hits)[0]\n",
    "        \n",
    "        return mem + [predicted_answer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_part_c_output(name, data, args):\n",
    "        \n",
    "    question_set = data[name][\"question_set\"]\n",
    "    document_set = data[name][\"document_set\"]\n",
    "    \n",
    "    part_c_output = []\n",
    "    \n",
    "    cached = args.get(\"cached\")\n",
    "    \n",
    "    cache_dict = None\n",
    "    \n",
    "    if cached:\n",
    "        \n",
    "        cache_dict = data[name][\"part_c_cache_dict\"]\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        cache_dict = {}\n",
    "        \n",
    "        cache_dict[\"pass_cache\"] = []\n",
    "        \n",
    "#         if use_enhancement:\n",
    "            \n",
    "#             cache_dict[\"enhancement_cache\"] = []    \n",
    "        \n",
    "    b_output_answer_set = data[name][\"b_output_answer_set\"]\n",
    "    \n",
    "    for i, result_b in enumerate(b_output_answer_set):\n",
    "        \n",
    "        predicted_answer = None        \n",
    "        question = question_set[result_b[\"set_index\"]][result_b[\"question_index\"]][\"question\"]\n",
    "        \n",
    "        if cached:\n",
    "            \n",
    "            (fourth_pass, third_pass, predicted_answer) = cache_dict[\"pass_cache\"][i]\n",
    "            \n",
    "        else:\n",
    "            (fourth_pass, third_pass, predicted_answer) = multi_pass([first_filter, first_filter_object, first_filter_object_stop], question, result_b[\"candidates\"])\n",
    "            \n",
    "            cache_dict[\"pass_cache\"].append((fourth_pass, third_pass, predicted_answer))\n",
    "        \n",
    "        predicted_answer = predicted_answer.replace(\" %\", \"%\").replace(\"$ \", \"$\")\n",
    "\n",
    "        result_c = {\n",
    "            \"set_index\"  : result_b[\"set_index\"],\n",
    "            \"question_index\" : result_b[\"question_index\"],\n",
    "            \"sentence_index\" : result_b[\"sentence_index\"],\n",
    "            \"candidates\": result_b[\"candidates\"],\n",
    "            \"ranked_answers\": fourth_pass,\n",
    "            \"vector_ranked_answers\": third_pass,\n",
    "            \"predicted_answer\" : predicted_answer\n",
    "        }\n",
    "        \n",
    "        part_c_output.append(result_c)        \n",
    "\n",
    "           \n",
    "    if not cached:\n",
    "        \n",
    "        data[name][\"part_c_cache_dict\"] = cache_dict        \n",
    "        \n",
    "    return part_c_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_part_c(name, data, args):\n",
    "    \n",
    "    data[name][\"c_output_answer_set\"] = generate_part_c_output(name, data, args)\n",
    "    \n",
    "    print\n",
    "    print \"Part C Output: \"\n",
    "    pp.pprint(data[name][\"c_output_answer_set\"][:rapid_size])\n",
    "    print    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For each question, evaluate if the answer is present as an entity\n",
    "\n",
    "def evaluate_rank(name, data, args):\n",
    "    \n",
    "    question_set = data[name][\"question_set\"]\n",
    "    document_set = data[name][\"document_set\"]\n",
    "    \n",
    "    correct = []\n",
    "    wrong = []\n",
    "    \n",
    "    c_output_answer_set = data[name][\"c_output_answer_set\"]\n",
    "    \n",
    "    for result_c in c_output_answer_set:\n",
    "        \n",
    "        question = question_set[result_c[\"set_index\"]][result_c[\"question_index\"]][\"question\"]\n",
    "        answer =  question_set[result_c[\"set_index\"]][result_c[\"question_index\"]][\"answer\"]\n",
    "        \n",
    "        predicted_answer = result_c[\"predicted_answer\"]\n",
    "        vector_ranked_answers = result_c[\"vector_ranked_answers\"]                \n",
    "\n",
    "        if (predicted_answer == answer):\n",
    "            correct.append(result_c)\n",
    "        else :\n",
    "            wrong.append(result_c)\n",
    "#         break\n",
    "        #print correct\n",
    "    return (correct, wrong)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_rank(name, data, stats=False, args={}):\n",
    "    print \"Processing rank: \", name\n",
    "    process_part_c(name, data, args)\n",
    "    if stats:\n",
    "        process_generic(name, data, \"rank\", evaluate_rank, args)\n",
    "        \n",
    "        \n",
    "        correct_rank = len(data[name][\"rank_correct\"])\n",
    "        correct_ner = len(data[name][\"ner_correct\"])\n",
    "        \n",
    "        avg = correct_rank * 1.0 / correct_ner\n",
    "        \n",
    "        print \"rank\".capitalize() + \" Correct Average of Previous %: \", avg        \n",
    "        \n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rank:  rapid\n",
      "\n",
      "Part C Output: \n",
      "[   {   'candidates': [   (u'They', 'O'),\n",
      "                          (u'had', 'O'),\n",
      "                          (u'a', 'O'),\n",
      "                          (u'playing time', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'eight minutes', 'NUMBER'),\n",
      "                          (u'.', 'PUNC')],\n",
      "        'predicted_answer': u'eight minutes',\n",
      "        'question_index': 0,\n",
      "        'ranked_answers': [   [   (u'eight minutes', 'NUMBER'),\n",
      "                                  0.2857142857142857]],\n",
      "        'sentence_index': 149,\n",
      "        'set_index': 0,\n",
      "        'vector_ranked_answers': [   [   (u'eight minutes', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.09523809523809523]]}]\n",
      "\n",
      "Rank Correct:  34\n",
      "Rank Wrong:  370\n",
      "Rank Total:  404\n",
      "Rank Overall Average %:  0.0841584158416\n",
      "Rank Correct Average of Previous %:  0.453333333333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_rank(\"rapid\", DATA, True, {\"cached\" : True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rank:  dev\n",
      "\n",
      "Part C Output: \n",
      "[   {   'candidates': [   (u'Infrared', 'O'),\n",
      "                          (u'is', 'O'),\n",
      "                          (u'used', 'O'),\n",
      "                          (u'in', 'O'),\n",
      "                          (u'night vision equipment', 'O'),\n",
      "                          (u'when', 'O'),\n",
      "                          (u'there', 'O'),\n",
      "                          (u'is', 'O'),\n",
      "                          (u'insufficient', 'O'),\n",
      "                          (u'visible light', 'O'),\n",
      "                          (u'to', 'O'),\n",
      "                          (u'see', 'O'),\n",
      "                          (u'.', 'PUNC')],\n",
      "        'predicted_answer': u'night vision equipment',\n",
      "        'question_index': 0,\n",
      "        'ranked_answers': [   [   (u'night vision equipment', 'O'),\n",
      "                                  0.2777777777777778],\n",
      "                              [(u'visible light', 'O'), 0.16666666666666666]],\n",
      "        'sentence_index': 71,\n",
      "        'set_index': 0,\n",
      "        'vector_ranked_answers': [   [   (u'night vision equipment', 'O'),\n",
      "                                         0,\n",
      "                                         2,\n",
      "                                         0.1388888888888889],\n",
      "                                     [   (u'visible light', 'O'),\n",
      "                                         0,\n",
      "                                         2,\n",
      "                                         0.08333333333333333]]}]\n",
      "\n",
      "Rank Correct:  1275\n",
      "Rank Wrong:  7188\n",
      "Rank Total:  8463\n",
      "Rank Overall Average %:  0.150655795817\n",
      "Rank Correct Average of Previous %:  0.447997189037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_rank(\"dev\", DATA, True, {\"cached\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# process_rank(\"train\", DATA, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def log_wrong_debug(name, data):\n",
    "    \n",
    "    question_set = data[name][\"question_set\"]\n",
    "    document_set = data[name][\"document_set\"]\n",
    "    rank_wrong = data[name][\"rank_wrong\"]\n",
    "    rank_correct = data[name][\"rank_correct\"]\n",
    "    \n",
    "    for i, result_wrong in enumerate(rank_correct):\n",
    "        \n",
    "        question = question_set[result_wrong[\"set_index\"]][result_wrong[\"question_index\"]]\n",
    "        candidate_sentence = document_set[result_wrong[\"set_index\"]][result_wrong[\"sentence_index\"]]\n",
    "        correct_sentence = document_set[result_wrong[\"set_index\"]][question[\"answer_sentence\"]]\n",
    "        \n",
    "        candidates = result_wrong[\"candidates\"]\n",
    "        ranked_answers = result_wrong[\"ranked_answers\"]\n",
    "        vector_ranked_answers = result_wrong[\"vector_ranked_answers\"]\n",
    "        predicted_answer = result_wrong[\"predicted_answer\"]\n",
    "        \n",
    "#         if i == 299:\n",
    "#         if question[\"answer_sentence\"] == result_wrong[\"sentence_index\"] and i % 100 == 0:\n",
    "        if question[\"answer\"].replace(\" \", \"\") in predicted_answer.replace(\" \", \"\"): # and i % 10 == 0:\n",
    "#             if len(set(question[\"answer\"].replace(\" \", \"\")).intersection(punct_tokens)) > 0:\n",
    "\n",
    "                print \"=\" * 20\n",
    "                print \"=\" * 20\n",
    "\n",
    "                print \"Question: \"\n",
    "                print\n",
    "                pp.pprint(question[\"question\"])\n",
    "\n",
    "                print\n",
    "                print \"Correct Sentence: (Part A)\"\n",
    "                print\n",
    "                pp.pprint(correct_sentence)\n",
    "                print\n",
    "                print \"Chosen Sentence: (Part A)\"\n",
    "                print\n",
    "                pp.pprint(candidate_sentence)\n",
    "                print\n",
    "\n",
    "                print \"Candidate Answers: (Part B)\"\n",
    "                print\n",
    "                pp.pprint(candidates)\n",
    "                print\n",
    "                print \"Ranked Answers: (Part C)\"\n",
    "                print\n",
    "                pp.pprint(ranked_answers)\n",
    "                print\n",
    "                print\n",
    "                print \"Vector Ranked Answers: (Part C)\"\n",
    "                print\n",
    "                pp.pprint(vector_ranked_answers)\n",
    "                print            \n",
    "                print \"Predicted Answer: (Part C)\"\n",
    "                print\n",
    "                pp.pprint(predicted_answer)\n",
    "                print\n",
    "                print \"Correct Answer: (Part C)\"\n",
    "                print\n",
    "                pp.pprint(question[\"answer\"])     \n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# log_wrong_debug(\"rapid\", DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rank:  test\n",
      "\n",
      "Part C Output: \n",
      "[   {   'candidates': [   (u'The Crimean War', 'OTHERCAP'),\n",
      "                          (u'marked', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'ascendancy', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'France', u'LOCATION'),\n",
      "                          (u'to', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'position', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'pre-eminent power', 'O'),\n",
      "                          (u'on', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'Continent', 'OTHERCAP'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u':411', 'NUMBER'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'continued decline', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'Ottoman Empire', 'OTHERCAP'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'and', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'beginning', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'a', 'O'),\n",
      "                          (u'decline', 'O'),\n",
      "                          (u'for', 'O'),\n",
      "                          (u'Tsarist', 'OTHERCAP'),\n",
      "                          (u'Russia', u'LOCATION'),\n",
      "                          (u'.', 'PUNC')],\n",
      "        'predicted_answer': u'Ottoman Empire',\n",
      "        'question_index': 0,\n",
      "        'ranked_answers': [   [   (u'Ottoman Empire', 'OTHERCAP'),\n",
      "                                  0.5647058823529412],\n",
      "                              [(u'Tsarist', 'OTHERCAP'), 0.5294117647058822],\n",
      "                              [   (u'Russia', u'LOCATION'),\n",
      "                                  0.49411764705882355],\n",
      "                              [(u':411', 'NUMBER'), 0.45882352941176463],\n",
      "                              [   (u'Continent', 'OTHERCAP'),\n",
      "                                  0.4235294117647059],\n",
      "                              [   (u'France', u'LOCATION'),\n",
      "                                  0.24705882352941178],\n",
      "                              [   (u'The Crimean War', 'OTHERCAP'),\n",
      "                                  0.09411764705882353]],\n",
      "        'sentence_index': 353,\n",
      "        'set_index': 0,\n",
      "        'vector_ranked_answers': [   [   (u'France', u'LOCATION'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.08235294117647059],\n",
      "                                     [   (u'Continent', 'OTHERCAP'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.1411764705882353],\n",
      "                                     [   (u':411', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.15294117647058822],\n",
      "                                     [   (u'Ottoman Empire', 'OTHERCAP'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.18823529411764706],\n",
      "                                     [   (u'Tsarist', 'OTHERCAP'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.1764705882352941],\n",
      "                                     [   (u'Russia', u'LOCATION'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.16470588235294117],\n",
      "                                     [   (u'The Crimean War', 'OTHERCAP'),\n",
      "                                         1,\n",
      "                                         1,\n",
      "                                         0.047058823529411764]]}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_rank(\"test\", DATA, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_submit(name, data):\n",
    "    \n",
    "    headers = ['id', 'answer']\n",
    "    \n",
    "    c_output_answer_set = data[name][\"c_output_answer_set\"]       \n",
    "\n",
    "    with open(name + '.submit.csv', 'w') as f:\n",
    "\n",
    "        f_csv = csv.DictWriter(f, headers)\n",
    "        f_csv.writeheader()\n",
    "\n",
    "        for index, result_c in enumerate(c_output_answer_set):\n",
    "            \n",
    "            predicted_answer = result_c[\"predicted_answer\"]\n",
    "            \n",
    "            if predicted_answer is not None:\n",
    "                f_csv.writerows([{'id':index+1,'answer':predicted_answer.encode(\"utf-8\")}])\n",
    "            else:\n",
    "                f_csv.writerows([{'id':index+1,'answer':\"NONE\"}])\n",
    "            \n",
    "#             if isinstance( answer_list[index]['answer'], int):\n",
    "                \n",
    "#                 f_csv.writerows([{'id':index+1,'answer':answer_list[index]['answer'][0][0]}])\n",
    "                \n",
    "#             else:\n",
    "                \n",
    "#                 f_csv.writerows([{'id':index+1,'answer':answer_list[index]['answer'][0][0].encode(\"utf-8\")}])        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "process_submit(\"rapid\", DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_submit(\"test\", DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
