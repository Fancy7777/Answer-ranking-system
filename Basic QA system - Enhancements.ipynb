{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in the python script containing the same code as the load the data notebook\n",
    "%run loadData.py\n",
    "# now we can access train, dev, and test\n",
    "# along with trainSents, devSents testSents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shim names for later clean\n",
    "\n",
    "train_question_set = train\n",
    "train_document_set = trainSents\n",
    "\n",
    "dev_question_set = dev\n",
    "dev_document_set = devSents\n",
    "\n",
    "test_question_set = test\n",
    "test_document_set = testSents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rapid_size = 1\n",
    "\n",
    "rapid_question_set = train_question_set[:rapid_size]\n",
    "rapid_document_set = train_document_set[:rapid_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shim for easier name spacing\n",
    "\n",
    "DATA = {\n",
    "    \"rapid\" : {\n",
    "            \"question_set\": rapid_question_set,\n",
    "            \"document_set\": rapid_document_set,\n",
    "    },\n",
    "    \"train\" : {\n",
    "            \"question_set\": train_question_set,\n",
    "            \"document_set\": train_document_set,\n",
    "    },\n",
    "    \"dev\" : {\n",
    "            \"question_set\": dev_question_set,\n",
    "            \"document_set\": dev_document_set,\n",
    "    },\n",
    "    \"test\" : {\n",
    "            \"question_set\": test_question_set,\n",
    "            \"document_set\": test_document_set,\n",
    "    }    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from string import punctuation  \n",
    "\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import csv\n",
    "\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Core functions\n",
    "\n",
    "classifier = './stanford/classifiers/english.all.3class.distsim.crf.ser.gz'\n",
    "jar = './stanford/stanford-ner.jar'\n",
    "\n",
    "sTagger = StanfordNERTagger(classifier,jar)\n",
    "\n",
    "punct_tokens = set(punctuation)\n",
    "extra_tokens = set([\"what\", \"where\", \"how\", \"when\", \"who\"])\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filter_tokens = extra_tokens.union(punct_tokens).union(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location = ['where','what place',u'where is', u'what country',u'along with', u'where are',u'on what', u'what city', u'in the', u'where did','where']\n",
    "number = [u'how many',u'how much','when','what year',u'when did', u'what year', u'when was',u'how long',u'when were', 'when']\n",
    "person = [u'who was', u'who is', u'which contestant',u'who wrote', u'who said', u'who did', u'who has', u'who played','who','whom','who',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getQuestionType(question):\n",
    "    \n",
    "    # fix: speed up\n",
    "    \n",
    "    question = question.lower()\n",
    "    \n",
    "    for ele in person:\n",
    "        if ele in question:\n",
    "            return 'PERSON'\n",
    "    for ele in  location:                       \n",
    "        if ele in question:\n",
    "            return 'LOCATION'\n",
    "    for ele in  number:  \n",
    "        if ele in question:\n",
    "            return 'NUMBER'\n",
    "    return 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Shim function for later clean\n",
    "\n",
    "def getStanfordTagging(datasetName):\n",
    "    fnameTrain = './preCompTags/stanfordTaggedTrain.txt'\n",
    "    fnameDev = './preCompTags/stanfordTaggedDev.txt'\n",
    "    fnameTest = './preCompTags/stanfordTaggedTest.txt'\n",
    "    \n",
    "    theFilePath = ''\n",
    "    theSents = []\n",
    "    if (datasetName == 'train'):\n",
    "        theFilePath = fnameTrain\n",
    "        theSents = trainSents\n",
    "    elif (datasetName == 'dev'):\n",
    "        theFilePath = fnameDev\n",
    "        theSents = devSents\n",
    "    elif (datasetName == 'test'):\n",
    "        theFilePath = fnameTest\n",
    "        theSents = testSents\n",
    "    else :\n",
    "        raise ValueError('Incorrect datasetName: ' + datasetName + ', choose from - \"train\", \"dev\", \"test\" ') \n",
    "    if (os.path.exists(theFilePath)):\n",
    "        with open(theFilePath, \"rb\") as fp:\n",
    "            stanfordTags = pickle.load(fp)\n",
    "            return stanfordTags\n",
    "    \n",
    "    else :\n",
    "        #Need to create taggings!\n",
    "        taggedSentsList = []\n",
    "        for sents in theSents:\n",
    "            tokenisedSents = [word_tokenize(sent) for sent in sents]\n",
    "            classifiedSents = sTagger.tag_sents(tokenisedSents)\n",
    "            taggedSentsList.append(classifiedSents)\n",
    "        #And save them\n",
    "        with open(theFilePath, \"wb\") as fp: \n",
    "            pickle.dump(taggedSentsList, fp)\n",
    "        return taggedSentsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_train_set = getStanfordTagging('train')\n",
    "tagged_dev_set = getStanfordTagging('dev')\n",
    "tagged_test_set = getStanfordTagging('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_rapid_set = tagged_train_set[:rapid_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shim for easier name spacing\n",
    "\n",
    "DATA[\"rapid\"][\"tagged_set\"] = tagged_rapid_set\n",
    "DATA[\"train\"][\"tagged_set\"] = tagged_train_set\n",
    "DATA[\"dev\"][\"tagged_set\"] = tagged_dev_set\n",
    "DATA[\"test\"][\"tagged_set\"] = tagged_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From: WSTA_N10_word_vectors\n",
    "\n",
    "import gensim\n",
    "from nltk.data import find\n",
    "\n",
    "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))\n",
    "word2vec_model = gensim.models.Word2Vec.load_word2vec_format(word2vec_sample, binary=False) # Use this if newer gensim: gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing tuning functions\n",
    "\n",
    "# Follow lemmatize function from guide notebook: WSTA_N1B_preprocessing.ipynb\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "word_tokenizer = nltk.tokenize.WordPunctTokenizer() #word_tokenize #tokenize.regexp.WordPunctTokenizer()\n",
    "\n",
    "def lemmatize(word):\n",
    "    lemma = lemmatizer.lemmatize(word,'v')\n",
    "    if lemma == word:\n",
    "        lemma = lemmatizer.lemmatize(word,'n')\n",
    "    return lemma\n",
    "\n",
    "def pre_process_tf_idf(line):\n",
    "    tokenized_sentence = word_tokenizer.tokenize(line.lower())\n",
    "    lemmatized_sentence = [lemmatize(token) for token in tokenized_sentence]\n",
    "    filtered_sentence = [token for token in lemmatized_sentence if token not in filter_tokens]\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Core functions\n",
    "\n",
    "def vectorize_documents(text_documents):\n",
    "\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', tokenizer=pre_process_tf_idf)\n",
    "    vector_documents = vectorizer.fit_transform(text_documents)\n",
    "    \n",
    "    return [vector_documents, vectorizer]\n",
    "\n",
    "def vectorize_query(vectorizer, text_query):\n",
    "    return vectorizer.transform([text_query])\n",
    "\n",
    "def process_neighbours(vector_documents):\n",
    "    \n",
    "    neighbours = NearestNeighbors(1, algorithm=\"brute\", metric=\"cosine\")\n",
    "    neighbours.fit(vector_documents)\n",
    "    \n",
    "    return neighbours\n",
    "\n",
    "def closest_document(neighbours, vector_query):\n",
    "\n",
    "    result = neighbours.kneighbors(vector_query, 1, return_distance=True)\n",
    "\n",
    "    result_index = result[1][0][0]\n",
    "    result_distance = result[0][0][0]\n",
    "    \n",
    "    return [result_distance, result_index]\n",
    "\n",
    "# def closest_documents(neighbours, vector_query, n):\n",
    "\n",
    "#     result = neighbours.kneighbors(vector_query, n, return_distance=True)\n",
    "\n",
    "#     result_indices = result[1][0]\n",
    "#     result_distances = result[0][0]\n",
    "    \n",
    "#     return sorted(zip(result_indices, result_distances), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def closest_documents_bm25(question, bm25, dictionary, n):\n",
    "\n",
    "    text_query = question[\"question\"]\n",
    "    \n",
    "    new_vec = dictionary.doc2bow(pre_process_tf_idf(text_query))\n",
    "    \n",
    "    average_idf = sum(map(lambda k: float(bm25.idf[k]), bm25.idf.keys())) / len(bm25.idf.keys())\n",
    "    scores = bm25.get_scores(new_vec, average_idf)\n",
    "        \n",
    "    return sorted(zip([i for i in range(0, len(scores))], scores), key=lambda x: x[1], reverse=True)[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model, datasets    \n",
    "from sklearn import cross_validation \n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_results(predictions, classifications):\n",
    "    print \"Accuracy: \", accuracy_score(classifications, predictions)\n",
    "    print classification_report(classifications, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(name, data) :\n",
    "\n",
    "    vec = DATA[name][\"X_vec\"]\n",
    "    X = DATA[name][\"X\"]\n",
    "    Y = DATA[name][\"Y\"]\n",
    "\n",
    "    clf = linear_model.LogisticRegression(C=1e5)\n",
    "    \n",
    "    print \"Model: \", clf\n",
    "    \n",
    "    print\n",
    "    print \"Data Slice: \"\n",
    "    print\n",
    "    print \"Shape X/Y: \", X.shape, Y.shape\n",
    "#     print \"Types X: \", vec.get_feature_names() \n",
    "    print \"Example X: \", X[0]\n",
    "    print \"Example Y: \", Y[0]\n",
    "    print\n",
    "    print \"Training model...\"\n",
    "    \n",
    "    clf.fit(X,Y)\n",
    "    \n",
    "    print \"Cross validating...\"\n",
    "\n",
    "    predictions = cross_validation.cross_val_predict(clf, X, Y, cv=10)\n",
    "    \n",
    "    print\n",
    "    print \"Model results: \"\n",
    "    print\n",
    "\n",
    "    check_results(predictions, Y)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_w2v(x):\n",
    "    return word2vec_model.vocab.get(x) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from gensim.summarization.bm25 import BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)],\n",
       " [(4, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)],\n",
       " [(6, 1), (7, 1), (9, 1), (13, 1), (14, 1)],\n",
       " [(5, 1), (7, 2), (14, 1), (15, 1), (16, 1)],\n",
       " [(9, 1), (10, 1), (12, 1), (17, 1), (18, 1), (19, 1), (20, 1)],\n",
       " [(21, 1), (22, 1), (23, 1), (24, 1), (25, 1)],\n",
       " [(24, 1), (26, 1), (27, 1), (28, 1)],\n",
       " [(24, 1), (26, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1)],\n",
       " [(8, 1), (26, 1), (34, 1)],\n",
       " []]"
      ]
     },
     "execution_count": 1307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_docs = '''\n",
    "Human machine interface for lab abc computer applications\n",
    "A survey of user opinion of computer system response time\n",
    "The EPS user interface management system\n",
    "System and human system engineering testing of EPS\n",
    "Relation of user perceived response time to error measurement\n",
    "The generation of random binary unordered trees\n",
    "The intersection graph of paths in trees\n",
    "Graph IV Widths of trees and well quasi ordering\n",
    "Graph minors A survey\n",
    "'''.split(\"\\n\")\n",
    "fn_docs_proc = map(pre_process_tf_idf, fn_docs)\n",
    "fn_docs_proc\n",
    "\n",
    "dictionary = corpora.Dictionary(fn_docs_proc)\n",
    "dictionary\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in fn_docs_proc]\n",
    "\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bm_ex = BM25(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Query = 'The intersection graph of paths in trees survey Graph'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, 1), (24, 1), (26, 2), (27, 1), (28, 1)]"
      ]
     },
     "execution_count": 1310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_idf = sum(map(lambda k: float(bm_ex.idf[k]), bm_ex.idf.keys())) / len(bm_ex.idf.keys())\n",
    "new_vec = dictionary.doc2bow(pre_process_tf_idf(Query))\n",
    "new_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 2.91587766511 The intersection graph of paths in trees\n",
      "2 0.814521700264 A survey of user opinion of computer system response time\n",
      "9 0.814521700264 Graph minors A survey\n",
      "6 0.541368636364 The generation of random binary unordered trees\n",
      "8 0.541368636364 Graph IV Widths of trees and well quasi ordering\n",
      "0 0 \n",
      "1 0 Human machine interface for lab abc computer applications\n",
      "3 0 The EPS user interface management system\n",
      "4 0 System and human system engineering testing of EPS\n",
      "5 0 Relation of user perceived response time to error measurement\n",
      "10 0 \n"
     ]
    }
   ],
   "source": [
    "scores = bm_ex.get_scores(new_vec, average_idf)\n",
    "\n",
    "best_result = fn_docs[scores.index(max(scores))]\n",
    "\n",
    "l = sorted(zip([i for i in range(0, len(scores))], scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for x in l:\n",
    "    print x[0], x[1], fn_docs[x[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def process_sentences(sentences):\n",
    "    \n",
    "#     vector_sentences, vectorizer = vectorize_documents(sentences)\n",
    "#     analyze = vectorizer.build_analyzer()\n",
    "#     neighbours = process_neighbours(vector_sentences)\n",
    "       \n",
    "#     return {\n",
    "#             \"vector_sentences\": vector_sentences,\n",
    "#             \"vectorizer\": vectorizer,\n",
    "#             \"analyze\": analyze,\n",
    "#             \"neighbours\": neighbours\n",
    "#            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_sentences_bm25(sentences):\n",
    "    \n",
    "    sentences_proc = map(pre_process_tf_idf, sentences)\n",
    "    \n",
    "    dictionary = corpora.Dictionary(sentences_proc)\n",
    "\n",
    "    corpus = [dictionary.doc2bow(text) for text in sentences_proc]\n",
    "    \n",
    "    bm25 = BM25(corpus)\n",
    "\n",
    "    return {\"bm25\" : bm25, \"dictionary\": dictionary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1445,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def process_feature(candidate_result, question, question_text_vector, analyze, sentences, y_sup=False):\n",
    "    \n",
    "#     text_query = question[\"question\"]\n",
    "        \n",
    "#     result_index = candidate_result[0]\n",
    "#     result_distance = candidate_result[1]    \n",
    "    \n",
    "#     result_text_vector = set(filter(f_w2v, analyze(sentences[result_index])))\n",
    "\n",
    "#     if len(question_text_vector) > 0 and len(result_text_vector) > 0:\n",
    "\n",
    "#         current_w2v_simil = word2vec_model.n_similarity(question_text_vector, result_text_vector)\n",
    "#         question_type = getQuestionType(text_query)\n",
    "\n",
    "#         new_x = {\n",
    "#                 \"tf-idf\": result_distance, \n",
    "#                 \"w2v\": current_w2v_simil,\n",
    "#                 \"qtype\": question_type,\n",
    "#                 \"len_sent\": len(sentences[result_index])\n",
    "#         }\n",
    "\n",
    "#         new_y = None\n",
    "        \n",
    "#         if not y_sup:\n",
    "#             new_y = int(result_index == question[\"answer_sentence\"])\n",
    "\n",
    "#         return [new_x, new_y]\n",
    "    \n",
    "#     else:\n",
    "        \n",
    "#         return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1446,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_feature_bm25(candidate_result, question, question_text_vector, bm25, dictionary, sentences, y_sup=False):\n",
    "\n",
    "    text_query = question[\"question\"]\n",
    "        \n",
    "    result_index = candidate_result[0]\n",
    "    result_distance = candidate_result[1]    \n",
    "    \n",
    "    result_text_vector = set(filter(f_w2v, pre_process_tf_idf(sentences[result_index])))\n",
    "\n",
    "    if len(question_text_vector) > 0 and len(result_text_vector) > 0:\n",
    "\n",
    "        current_w2v_simil = word2vec_model.n_similarity(question_text_vector, result_text_vector)\n",
    "        question_type = getQuestionType(text_query)\n",
    "\n",
    "        new_x = {\n",
    "                \"bm25\": result_distance, \n",
    "                \"w2v\": current_w2v_simil,\n",
    "                \"qtype\": question_type,\n",
    "                \"len_sent\": len(sentences[result_index])\n",
    "        }\n",
    "\n",
    "        new_y = None\n",
    "        \n",
    "        if not y_sup:\n",
    "            new_y = int(result_index == question[\"answer_sentence\"])\n",
    "\n",
    "        return [new_x, new_y]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1447,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def process_enhancement(question, neighbours, vector_query, analyze, sentences, y_sup=False):\n",
    "    \n",
    "#     text_query = question[\"question\"]\n",
    "#     question_text_vector = set(filter(f_w2v, analyze(text_query)))\n",
    "    \n",
    "#     candidate_results = closest_documents(neighbours, vector_query, 5)\n",
    "#     features = filter(None, [process_feature(x, question, question_text_vector, analyze, sentences, y_sup) for x in candidate_results])\n",
    "    \n",
    "#     return {\n",
    "#         \"candidate_results\": candidate_results,\n",
    "#         \"features\": features\n",
    "#     }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1448,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_enhancement_bm25(question, bm25, dictionary, sentences, y_sup=False):\n",
    "    \n",
    "    text_query = question[\"question\"]\n",
    "    question_text_vector = set(filter(f_w2v, pre_process_tf_idf(text_query)))\n",
    "    \n",
    "#     pp.pprint(question_text_vector)\n",
    "    \n",
    "    candidate_results = closest_documents_bm25(question, bm25, dictionary, 5)\n",
    "    features = filter(None, [process_feature_bm25(x, question, question_text_vector, bm25, dictionary, sentences, y_sup) for x in candidate_results])\n",
    "    \n",
    "    return {\n",
    "        \"candidate_results\": candidate_results,\n",
    "        \"features\": features\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1449,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def process_query(question, vectorizer, neighbours, analyze):\n",
    "    \n",
    "#     text_query = question[\"question\"]\n",
    "\n",
    "#     vector_query = vectorize_query(vectorizer, text_query)\n",
    "\n",
    "#     result_distance, result_index = closest_document(neighbours, vector_query)\n",
    "    \n",
    "#     return {\n",
    "#             \"vector_query\": vector_query,\n",
    "#             \"result_distance\": result_distance,\n",
    "#             \"result_index\": result_index\n",
    "#            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1450,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_query_bm25(question, bm25, dictionary):\n",
    "    \n",
    "    text_query = question[\"question\"]\n",
    "    \n",
    "    new_vec = dictionary.doc2bow(pre_process_tf_idf(text_query))\n",
    "    \n",
    "    average_idf = sum(map(lambda k: float(bm25.idf[k]), bm25.idf.keys())) / len(bm25.idf.keys())\n",
    "    scores = bm25.get_scores(new_vec, average_idf)\n",
    "    \n",
    "    result_distance = max(scores)\n",
    "    result_index = scores.index(result_distance)\n",
    "    \n",
    "    return {\n",
    "            \"vector_query\": Query,\n",
    "            \"result_distance\": result_distance,\n",
    "            \"result_index\": result_index\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1451,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recursive_default_dict():\n",
    "    return defaultdict(recursive_default_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1452,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def generate_part_a_output(name, data, args):\n",
    "    \n",
    "#     cached = args.get(\"cached\")\n",
    "    \n",
    "#     use_enhancement = args.get(\"use_enhancement\")\n",
    "#     train_enhancement = args.get(\"train_enhancement\")\n",
    "    \n",
    "#     enhancement_dataset = args.get(\"enhancement_dataset\")\n",
    "    \n",
    "#     y_sup = args.get(\"y_sup\")\n",
    "    \n",
    "#     question_set = data[name][\"question_set\"]\n",
    "#     document_set = data[name][\"document_set\"]\n",
    "    \n",
    "#     part_a_output = []\n",
    "#     X = []\n",
    "#     Y = []\n",
    "    \n",
    "#     index_to_x = {}\n",
    "    \n",
    "#     cache_dict = None\n",
    "    \n",
    "#     if cached:\n",
    "        \n",
    "#         cache_dict = data[name][\"part_a_cache_dict\"]\n",
    "        \n",
    "#         x_best = cache_dict.get(\"X_best\")\n",
    "        \n",
    "#         if x_best == None:\n",
    "#             cache_dict[\"X_best\"] = recursive_default_dict()\n",
    "        \n",
    "# #         X = data[name][\"X\"]\n",
    "# #         Y = data[name][\"Y\"]        \n",
    "        \n",
    "#     else:\n",
    "        \n",
    "#         cache_dict = {}\n",
    "        \n",
    "#         cache_dict[\"sen_cache\"] = []\n",
    "        \n",
    "#         cache_dict[\"query_cache\"] = []\n",
    "        \n",
    "#         cache_dict[\"X_best\"] = recursive_default_dict()\n",
    "        \n",
    "#         if use_enhancement:\n",
    "            \n",
    "#             cache_dict[\"enhancement_cache\"] = []\n",
    "                \n",
    "        \n",
    "#     for i, questions in enumerate(question_set):\n",
    "        \n",
    "#         sentences = document_set[i]\n",
    "        \n",
    "#         sen_cache = None\n",
    "\n",
    "#         if cached:\n",
    "            \n",
    "#             sen_cache_item = cache_dict[\"sen_cache\"][i]\n",
    "        \n",
    "#         else:\n",
    "            \n",
    "#             sen_cache_item = process_sentences(sentences)\n",
    "#             cache_dict[\"sen_cache\"].append(sen_cache_item)\n",
    "            \n",
    "#             cache_dict[\"query_cache\"].append([])\n",
    "            \n",
    "#             if use_enhancement:\n",
    "                \n",
    "#                 cache_dict[\"enhancement_cache\"].append([])\n",
    "\n",
    "#         for j, question in enumerate(questions):\n",
    "            \n",
    "#             query_cache_item = None\n",
    "#             result_index = None\n",
    "            \n",
    "#             if cached:\n",
    "                \n",
    "#                 query_cache_item = cache_dict[\"query_cache\"][i][j]\n",
    "#                 result_index = query_cache_item[\"result_index\"]\n",
    "                \n",
    "#                 if use_enhancement:\n",
    "                    \n",
    "#                     enhancement_cache_item = cache_dict[\"enhancement_cache\"][i][j]\n",
    "\n",
    "#                     model = data[enhancement_dataset][\"model\"]\n",
    "#                     vec = data[enhancement_dataset][\"X_vec\"]\n",
    "\n",
    "#                     candidate_results = enhancement_cache_item[\"candidate_results\"]\n",
    "#                     new_xs = [feature[0] for feature in enhancement_cache_item[\"features\"]]\n",
    "\n",
    "#                     if len(new_xs) > 0:\n",
    "\n",
    "#                         new_features = vec.transform(new_xs) #.toarray()\n",
    "\n",
    "#                         prob_ys = model.predict_proba(new_features)\n",
    "#                         best_y_index = np.argmax(prob_ys[:, 1])\n",
    "                        \n",
    "#                         cache_dict[\"X_best\"][i][j] = new_xs[best_y_index]\n",
    "\n",
    "#                         result_index = candidate_results[best_y_index][0]\n",
    "                \n",
    "#             else:\n",
    "                \n",
    "#                 query_cache_item = process_query(question, sen_cache_item[\"vectorizer\"], sen_cache_item[\"neighbours\"], sen_cache_item[\"analyze\"])\n",
    "#                 cache_dict[\"query_cache\"][i].append(query_cache_item)\n",
    "                \n",
    "#                 result_index = query_cache_item[\"result_index\"]\n",
    "                \n",
    "#                 if use_enhancement:\n",
    "                    \n",
    "#                     enhancement_cache_item = process_enhancement(question, sen_cache_item[\"neighbours\"], query_cache_item[\"vector_query\"], sen_cache_item[\"analyze\"], sentences, y_sup)\n",
    "#                     cache_dict[\"enhancement_cache\"][i].append(enhancement_cache_item)                    \n",
    "                \n",
    "#                 if train_enhancement:\n",
    "\n",
    "#                     new_xs = [feature[0] for feature in enhancement_cache_item[\"features\"]]\n",
    "#                     new_ys = [feature[1] for feature in enhancement_cache_item[\"features\"]]\n",
    "\n",
    "#                     X += new_xs\n",
    "#                     Y += new_ys\n",
    "            \n",
    "#             result = {\n",
    "#                 \"set_index\" : i,\n",
    "#                 \"question_index\" : j,\n",
    "#                 \"sentence_index\" : result_index\n",
    "#             }\n",
    "\n",
    "#             part_a_output.append(result)\n",
    "            \n",
    "# #             if j > 1:\n",
    "# #                 break\n",
    "                \n",
    "# #         if i > 1:\n",
    "# #             break\n",
    "    \n",
    "#     data[name][\"part_a_cache_dict\"] = cache_dict\n",
    "    \n",
    "#     if not cached:\n",
    "        \n",
    "#         if train_enhancement:\n",
    "        \n",
    "#             vec = DictVectorizer()                \n",
    "#             X = vec.fit_transform(X) #.toarray()\n",
    "#             Y = np.array(Y)\n",
    "\n",
    "#             data[name][\"X_vec\"] = vec\n",
    "#             data[name][\"X\"] = X\n",
    "#             data[name][\"Y\"] = Y\n",
    "\n",
    "#             print \"Shape X/Y: \", data[name][\"X\"].shape, data[name][\"Y\"].shape\n",
    "# #             print \"Types X: \", vec.get_feature_names()        \n",
    "#             print \"Example X: \", X[0]\n",
    "#             print \"Example Y: \", Y[0]        \n",
    "        \n",
    "#     return part_a_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1453,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_part_a_output(name, data, args):\n",
    "    \n",
    "    cached = args.get(\"cached\")\n",
    "    \n",
    "    use_enhancement = args.get(\"use_enhancement\")\n",
    "    train_enhancement = args.get(\"train_enhancement\")\n",
    "    \n",
    "    enhancement_dataset = args.get(\"enhancement_dataset\")\n",
    "    \n",
    "    y_sup = args.get(\"y_sup\")\n",
    "    \n",
    "    question_set = data[name][\"question_set\"]\n",
    "    document_set = data[name][\"document_set\"]\n",
    "    \n",
    "    part_a_output = []\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    index_to_x = {}\n",
    "    \n",
    "    cache_dict = None\n",
    "    \n",
    "    if cached:\n",
    "        \n",
    "        cache_dict = data[name][\"part_a_cache_dict\"]\n",
    "        \n",
    "        x_best = cache_dict.get(\"X_best\")\n",
    "        \n",
    "        if x_best == None:\n",
    "            cache_dict[\"X_best\"] = recursive_default_dict()\n",
    "        \n",
    "#         X = data[name][\"X\"]\n",
    "#         Y = data[name][\"Y\"]        \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        cache_dict = {}\n",
    "        \n",
    "        cache_dict[\"sen_cache\"] = []\n",
    "        \n",
    "        cache_dict[\"query_cache\"] = []\n",
    "        \n",
    "        cache_dict[\"X_best\"] = recursive_default_dict()\n",
    "        \n",
    "        if use_enhancement:\n",
    "            \n",
    "            cache_dict[\"enhancement_cache\"] = []\n",
    "                \n",
    "        \n",
    "    for i, questions in enumerate(question_set):\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print \"Processed: {0}, {1}\".format(i, len(question_set))\n",
    "        \n",
    "        sentences = document_set[i]\n",
    "        \n",
    "        sen_cache = None\n",
    "\n",
    "        if cached:\n",
    "            \n",
    "            sen_cache_item = cache_dict[\"sen_cache\"][i]\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            sen_cache_item = process_sentences_bm25(sentences)\n",
    "            cache_dict[\"sen_cache\"].append(sen_cache_item)\n",
    "            \n",
    "            cache_dict[\"query_cache\"].append([])\n",
    "            \n",
    "            if use_enhancement:\n",
    "                \n",
    "                cache_dict[\"enhancement_cache\"].append([])\n",
    "\n",
    "        for j, question in enumerate(questions):\n",
    "            \n",
    "            query_cache_item = None\n",
    "            result_index = None\n",
    "            \n",
    "            if cached:\n",
    "                \n",
    "                query_cache_item = cache_dict[\"query_cache\"][i][j]\n",
    "                result_index = query_cache_item[\"result_index\"]\n",
    "                \n",
    "                if use_enhancement:\n",
    "                    \n",
    "                    enhancement_cache_item = cache_dict[\"enhancement_cache\"][i][j]\n",
    "\n",
    "                    model = data[enhancement_dataset][\"model\"]\n",
    "                    vec = data[enhancement_dataset][\"X_vec\"]\n",
    "\n",
    "                    candidate_results = enhancement_cache_item[\"candidate_results\"]\n",
    "                    new_xs = [feature[0] for feature in enhancement_cache_item[\"features\"]]\n",
    "\n",
    "                    if len(new_xs) > 0:\n",
    "\n",
    "                        new_features = vec.transform(new_xs) #.toarray()\n",
    "\n",
    "                        prob_ys = model.predict_proba(new_features)\n",
    "                        best_y_index = np.argmax(prob_ys[:, 1])\n",
    "                        \n",
    "                        cache_dict[\"X_best\"][i][j] = new_xs[best_y_index]\n",
    "\n",
    "                        result_index = candidate_results[best_y_index][0]\n",
    "                \n",
    "            else:\n",
    "                \n",
    "#                 query_cache_item = process_query(question, sen_cache_item[\"vectorizer\"], sen_cache_item[\"neighbours\"], sen_cache_item[\"analyze\"])\n",
    "                query_cache_item = process_query_bm25(question, sen_cache_item[\"bm25\"], sen_cache_item[\"dictionary\"])\n",
    "\n",
    "                cache_dict[\"query_cache\"][i].append(query_cache_item)\n",
    "                \n",
    "                result_index = query_cache_item[\"result_index\"]\n",
    "                \n",
    "#                 print(question[\"question\"])\n",
    "#                 print(sentences[result_index])\n",
    "                \n",
    "                if use_enhancement:\n",
    "                    \n",
    "#                     enhancement_cache_item = process_enhancement(question, sen_cache_item[\"neighbours\"], query_cache_item[\"vector_query\"], sen_cache_item[\"analyze\"], sentences, y_sup)\n",
    "                    enhancement_cache_item = process_enhancement_bm25(question, sen_cache_item[\"bm25\"], sen_cache_item[\"dictionary\"], sentences, y_sup)\n",
    "                    cache_dict[\"enhancement_cache\"][i].append(enhancement_cache_item)                    \n",
    "        \n",
    "#                     pp.pprint(enhancement_cache_item)\n",
    "                \n",
    "                if train_enhancement:\n",
    "\n",
    "                    new_xs = [feature[0] for feature in enhancement_cache_item[\"features\"]]\n",
    "                    new_ys = [feature[1] for feature in enhancement_cache_item[\"features\"]]\n",
    "\n",
    "                    X += new_xs\n",
    "                    Y += new_ys\n",
    "            \n",
    "            result = {\n",
    "                \"set_index\" : i,\n",
    "                \"question_index\" : j,\n",
    "                \"sentence_index\" : result_index\n",
    "            }\n",
    "\n",
    "            part_a_output.append(result)\n",
    "            \n",
    "#             if j > 1:\n",
    "#                 break\n",
    "                \n",
    "#         if i > 1:\n",
    "#             break\n",
    "    \n",
    "    data[name][\"part_a_cache_dict\"] = cache_dict\n",
    "    \n",
    "    if not cached:\n",
    "        \n",
    "        if train_enhancement:\n",
    "        \n",
    "            vec = DictVectorizer()                \n",
    "            X = vec.fit_transform(X) #.toarray()\n",
    "            Y = np.array(Y)\n",
    "\n",
    "            data[name][\"X_vec\"] = vec\n",
    "            data[name][\"X\"] = X\n",
    "            data[name][\"Y\"] = Y\n",
    "\n",
    "            print \"Shape X/Y: \", data[name][\"X\"].shape, data[name][\"Y\"].shape\n",
    "#             print \"Types X: \", vec.get_feature_names()        \n",
    "            print \"Example X: \", X[0]\n",
    "            print \"Example Y: \", Y[0]        \n",
    "        \n",
    "    return part_a_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1454,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_part_a(name, data, args):\n",
    "    \n",
    "    data[name][\"a_output_answer_set\"] = generate_part_a_output(name, data, args)\n",
    "    \n",
    "    gen_model = args.get(\"gen_model\")\n",
    "    \n",
    "    if gen_model:\n",
    "        data[name][\"model\"] = train_model(name, data)\n",
    "    \n",
    "    print\n",
    "    print \"Part A Output: \"\n",
    "    print\n",
    "    pp.pprint(data[name][\"a_output_answer_set\"][:rapid_size])\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1455,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shim function for later clean\n",
    "\n",
    "def evaluate_retrieval(name, data, args):\n",
    "    \n",
    "    question_set = data[name][\"question_set\"]\n",
    "    a_output_answer_set = data[name][\"a_output_answer_set\"]\n",
    "    \n",
    "    correct = []\n",
    "    wrong = []\n",
    "    \n",
    "    for result_a in a_output_answer_set:\n",
    "        \n",
    "        question = question_set[result_a[\"set_index\"]][result_a[\"question_index\"]]\n",
    "        \n",
    "        answer_sentence = question[\"answer_sentence\"]\n",
    "        predicted_answer_sentence = result_a[\"sentence_index\"]\n",
    "        \n",
    "        if answer_sentence == predicted_answer_sentence:\n",
    "            correct.append(result_a)\n",
    "        else:\n",
    "            wrong.append(result_a)\n",
    "        \n",
    "#         break\n",
    "            \n",
    "    return (correct, wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1456,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_generic(name, data, process_type, process_func, args):\n",
    "\n",
    "    (correct, wrong) = process_func(name, data, args)\n",
    "    \n",
    "    data[name][process_type + \"_correct\"] = correct\n",
    "    data[name][process_type + \"_wrong\"] = wrong\n",
    "#     data[name][process_type + \"_full\"] = full\n",
    "    \n",
    "    total = len(correct) + len(wrong)\n",
    "    avg = len(correct) * 1.0 / total\n",
    "    \n",
    "    print process_type.capitalize() + \" Correct: \", len(correct)\n",
    "    print process_type.capitalize() + \" Wrong: \", len(wrong)\n",
    "    print process_type.capitalize() + \" Total: \", total\n",
    "    print process_type.capitalize() + \" Overall Average %: \", avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1457,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_retrieval(name, data, stats=False, args={}):\n",
    "    print \"Processing retrieval: \", name\n",
    "    process_part_a(name, data, args)\n",
    "    if stats:\n",
    "        process_generic(name, data, \"retrieval\", evaluate_retrieval, args)\n",
    "        \n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1458,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# process_retrieval(\"rapid\", DATA, True, {\"cached\" : False, \n",
    "#                                         \"train_enhancement\": True,\n",
    "#                                         \"use_enhancement\": True,\n",
    "#                                         \"enhancement_dataset\": \"rapid\",\n",
    "#                                         \"y_sup\": False,\n",
    "#                                         \"gen_model\": False})   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1459,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# process_retrieval(\"dev\", DATA, True, {\"cached\" : False, \n",
    "#                                         \"train_enhancement\": False,\n",
    "#                                         \"use_enhancement\": False,\n",
    "#                                         \"enhancement_dataset\": \"dev\",\n",
    "#                                         \"y_sup\": False,\n",
    "#                                         \"gen_model\": False})   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# process_retrieval(\"train\", DATA, True, {\"cached\" : False, \n",
    "#                                         \"train_enhancement\": False,\n",
    "#                                         \"use_enhancement\": False,\n",
    "#                                         \"enhancement_dataset\": \"train\",\n",
    "#                                         \"y_sup\": False,\n",
    "#                                         \"gen_model\": False})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1461,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing retrieval:  rapid\n",
      "Processed: 0, 1\n",
      "Shape X/Y:  (2010, 7) (2010,)\n",
      "Example X:    (0, 0)\t0.783141260629\n",
      "  (0, 1)\t508.0\n",
      "  (0, 3)\t1.0\n",
      "  (0, 6)\t0.509172394044\n",
      "Example Y:  1\n",
      "Model:  LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "\n",
      "Data Slice: \n",
      "\n",
      "Shape X/Y:  (2010, 7) (2010,)\n",
      "Example X:    (0, 0)\t0.783141260629\n",
      "  (0, 1)\t508.0\n",
      "  (0, 3)\t1.0\n",
      "  (0, 6)\t0.509172394044\n",
      "Example Y:  1\n",
      "\n",
      "Training model...\n",
      "Cross validating...\n",
      "\n",
      "Model results: \n",
      "\n",
      "Accuracy:  0.888059701493\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94      1750\n",
      "          1       0.66      0.28      0.39       260\n",
      "\n",
      "avg / total       0.87      0.89      0.87      2010\n",
      "\n",
      "\n",
      "Part A Output: \n",
      "\n",
      "[{   'question_index': 0, 'sentence_index': 2, 'set_index': 0}]\n",
      "\n",
      "Retrieval Correct:  176\n",
      "Retrieval Wrong:  228\n",
      "Retrieval Total:  404\n",
      "Retrieval Overall Average %:  0.435643564356\n",
      "\n",
      "Processing retrieval:  rapid\n",
      "Processed: 0, 1\n",
      "\n",
      "Part A Output: \n",
      "\n",
      "[{   'question_index': 0, 'sentence_index': 2, 'set_index': 0}]\n",
      "\n",
      "Retrieval Correct:  176\n",
      "Retrieval Wrong:  228\n",
      "Retrieval Total:  404\n",
      "Retrieval Overall Average %:  0.435643564356\n",
      "\n",
      "Processing retrieval:  rapid\n",
      "Processed: 0, 1\n",
      "\n",
      "Part A Output: \n",
      "\n",
      "[{   'question_index': 0, 'sentence_index': 2, 'set_index': 0}]\n",
      "\n",
      "Retrieval Correct:  175\n",
      "Retrieval Wrong:  229\n",
      "Retrieval Total:  404\n",
      "Retrieval Overall Average %:  0.433168316832\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_retrieval(\"rapid\", DATA, True, {\"cached\" : False, \n",
    "                                        \"train_enhancement\": True,\n",
    "                                        \"use_enhancement\": True,\n",
    "                                        \"enhancement_dataset\": \"rapid\",\n",
    "                                        \"y_sup\": False,\n",
    "                                        \"gen_model\": True})                                        \n",
    "\n",
    "process_retrieval(\"rapid\", DATA, True, {\"cached\" : True, \n",
    "                                        \"train_enhancement\": False,\n",
    "                                        \"use_enhancement\": False,\n",
    "                                        \"enhancement_dataset\": \"rapid\",\n",
    "                                        \"y_sup\": False,\n",
    "                                        \"gen_model\": False})\n",
    "\n",
    "process_retrieval(\"rapid\", DATA, True, {\"cached\" : True, \n",
    "                                        \"train_enhancement\": False,\n",
    "                                        \"use_enhancement\": True,\n",
    "                                        \"enhancement_dataset\": \"rapid\",\n",
    "                                        \"y_sup\": False,\n",
    "                                        \"gen_model\": False})\n",
    "\n",
    "# process_retrieval(\"rapid\", DATA, True, {\"cached\" : True, \n",
    "#                                         \"train_enhancement\": False,\n",
    "#                                         \"use_enhancement\": True,\n",
    "#                                         \"enhancement_dataset\": \"train\",\n",
    "#                                         \"y_sup\": False,\n",
    "#                                         \"gen_model\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1464,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing retrieval:  dev\n",
      "Processed: 0, 40\n",
      "Processed: 10, 40\n",
      "Processed: 20, 40\n",
      "Processed: 30, 40\n",
      "\n",
      "Part A Output: \n",
      "\n",
      "[{   'question_index': 0, 'sentence_index': 1, 'set_index': 0}]\n",
      "\n",
      "Retrieval Correct:  5101\n",
      "Retrieval Wrong:  3362\n",
      "Retrieval Total:  8463\n",
      "Retrieval Overall Average %:  0.602741344677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# process_retrieval(\"dev\", DATA, True, {\"cached\" : False, \n",
    "#                                         \"train_enhancement\": True,\n",
    "#                                         \"use_enhancement\": True,\n",
    "#                                         \"enhancement_dataset\": \"dev\",\n",
    "#                                         \"y_sup\": False,\n",
    "#                                         \"gen_model\": True})                                        \n",
    "\n",
    "# process_retrieval(\"dev\", DATA, True, {\"cached\" : True, \n",
    "#                                         \"train_enhancement\": False,\n",
    "#                                         \"use_enhancement\": False,\n",
    "#                                         \"enhancement_dataset\": \"dev\",\n",
    "#                                         \"y_sup\": False,\n",
    "#                                         \"gen_model\": False})\n",
    "\n",
    "# process_retrieval(\"dev\", DATA, True, {\"cached\" : True, \n",
    "#                                         \"train_enhancement\": False,\n",
    "#                                         \"use_enhancement\": True,\n",
    "#                                         \"enhancement_dataset\": \"dev\",\n",
    "#                                         \"y_sup\": False,\n",
    "#                                         \"gen_model\": False})\n",
    "\n",
    "process_retrieval(\"dev\", DATA, True, {\"cached\" : True, \n",
    "                                        \"train_enhancement\": False,\n",
    "                                        \"use_enhancement\": True,\n",
    "                                        \"enhancement_dataset\": \"train\",\n",
    "                                        \"y_sup\": False,\n",
    "                                        \"gen_model\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1463,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing retrieval:  train\n",
      "Processed: 0, 360\n",
      "Processed: 10, 360\n",
      "Processed: 20, 360\n",
      "Processed: 30, 360\n",
      "Processed: 40, 360\n",
      "Processed: 50, 360\n",
      "Processed: 60, 360\n",
      "Processed: 70, 360\n",
      "Processed: 80, 360\n",
      "Processed: 90, 360\n",
      "Processed: 100, 360\n",
      "Processed: 110, 360\n",
      "Processed: 120, 360\n",
      "Processed: 130, 360\n",
      "Processed: 140, 360\n",
      "Processed: 150, 360\n",
      "Processed: 160, 360\n",
      "Processed: 170, 360\n",
      "Processed: 180, 360\n",
      "Processed: 190, 360\n",
      "Processed: 200, 360\n",
      "Processed: 210, 360\n",
      "Processed: 220, 360\n",
      "Processed: 230, 360\n",
      "Processed: 240, 360\n",
      "Processed: 250, 360\n",
      "Processed: 260, 360\n",
      "Processed: 270, 360\n",
      "Processed: 280, 360\n",
      "Processed: 290, 360\n",
      "Processed: 300, 360\n",
      "Processed: 310, 360\n",
      "Processed: 320, 360\n",
      "Processed: 330, 360\n",
      "Processed: 340, 360\n",
      "Processed: 350, 360\n",
      "Shape X/Y:  (348337, 7) (348337,)\n",
      "Example X:    (0, 0)\t0.783141260629\n",
      "  (0, 1)\t508.0\n",
      "  (0, 3)\t1.0\n",
      "  (0, 6)\t0.509172394044\n",
      "Example Y:  1\n",
      "Model:  LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "\n",
      "Data Slice: \n",
      "\n",
      "Shape X/Y:  (348337, 7) (348337,)\n",
      "Example X:    (0, 0)\t0.783141260629\n",
      "  (0, 1)\t508.0\n",
      "  (0, 3)\t1.0\n",
      "  (0, 6)\t0.509172394044\n",
      "Example Y:  1\n",
      "\n",
      "Training model...\n",
      "Cross validating...\n",
      "\n",
      "Model results: \n",
      "\n",
      "Accuracy:  0.869738213282\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93    291486\n",
      "          1       0.74      0.32      0.44     56851\n",
      "\n",
      "avg / total       0.86      0.87      0.85    348337\n",
      "\n",
      "\n",
      "Part A Output: \n",
      "\n",
      "[{   'question_index': 0, 'sentence_index': 2, 'set_index': 0}]\n",
      "\n",
      "Retrieval Correct:  44269\n",
      "Retrieval Wrong:  25890\n",
      "Retrieval Total:  70159\n",
      "Retrieval Overall Average %:  0.630981057313\n",
      "\n",
      "Processing retrieval:  train\n",
      "Processed: 0, 360\n",
      "Processed: 10, 360\n",
      "Processed: 20, 360\n",
      "Processed: 30, 360\n",
      "Processed: 40, 360\n",
      "Processed: 50, 360\n",
      "Processed: 60, 360\n",
      "Processed: 70, 360\n",
      "Processed: 80, 360\n",
      "Processed: 90, 360\n",
      "Processed: 100, 360\n",
      "Processed: 110, 360\n",
      "Processed: 120, 360\n",
      "Processed: 130, 360\n",
      "Processed: 140, 360\n",
      "Processed: 150, 360\n",
      "Processed: 160, 360\n",
      "Processed: 170, 360\n",
      "Processed: 180, 360\n",
      "Processed: 190, 360\n",
      "Processed: 200, 360\n",
      "Processed: 210, 360\n",
      "Processed: 220, 360\n",
      "Processed: 230, 360\n",
      "Processed: 240, 360\n",
      "Processed: 250, 360\n",
      "Processed: 260, 360\n",
      "Processed: 270, 360\n",
      "Processed: 280, 360\n",
      "Processed: 290, 360\n",
      "Processed: 300, 360\n",
      "Processed: 310, 360\n",
      "Processed: 320, 360\n",
      "Processed: 330, 360\n",
      "Processed: 340, 360\n",
      "Processed: 350, 360\n",
      "\n",
      "Part A Output: \n",
      "\n",
      "[{   'question_index': 0, 'sentence_index': 2, 'set_index': 0}]\n",
      "\n",
      "Retrieval Correct:  44269\n",
      "Retrieval Wrong:  25890\n",
      "Retrieval Total:  70159\n",
      "Retrieval Overall Average %:  0.630981057313\n",
      "\n",
      "Processing retrieval:  train\n",
      "Processed: 0, 360\n",
      "Processed: 10, 360\n",
      "Processed: 20, 360\n",
      "Processed: 30, 360\n",
      "Processed: 40, 360\n",
      "Processed: 50, 360\n",
      "Processed: 60, 360\n",
      "Processed: 70, 360\n",
      "Processed: 80, 360\n",
      "Processed: 90, 360\n",
      "Processed: 100, 360\n",
      "Processed: 110, 360\n",
      "Processed: 120, 360\n",
      "Processed: 130, 360\n",
      "Processed: 140, 360\n",
      "Processed: 150, 360\n",
      "Processed: 160, 360\n",
      "Processed: 170, 360\n",
      "Processed: 180, 360\n",
      "Processed: 190, 360\n",
      "Processed: 200, 360\n",
      "Processed: 210, 360\n",
      "Processed: 220, 360\n",
      "Processed: 230, 360\n",
      "Processed: 240, 360\n",
      "Processed: 250, 360\n",
      "Processed: 260, 360\n",
      "Processed: 270, 360\n",
      "Processed: 280, 360\n",
      "Processed: 290, 360\n",
      "Processed: 300, 360\n",
      "Processed: 310, 360\n",
      "Processed: 320, 360\n",
      "Processed: 330, 360\n",
      "Processed: 340, 360\n",
      "Processed: 350, 360\n",
      "\n",
      "Part A Output: \n",
      "\n",
      "[{   'question_index': 0, 'sentence_index': 2, 'set_index': 0}]\n",
      "\n",
      "Retrieval Correct:  44325\n",
      "Retrieval Wrong:  25834\n",
      "Retrieval Total:  70159\n",
      "Retrieval Overall Average %:  0.631779244288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_retrieval(\"train\", DATA, True, {\"cached\" : False, \n",
    "                                        \"train_enhancement\": True,\n",
    "                                        \"use_enhancement\": True,\n",
    "                                        \"enhancement_dataset\": \"train\",\n",
    "                                        \"gen_model\": True})                                     \n",
    "\n",
    "process_retrieval(\"train\", DATA, True, {\"cached\" : True, \n",
    "                                        \"train_enhancement\": False,\n",
    "                                        \"use_enhancement\": False,\n",
    "                                        \"enhancement_dataset\": \"train\",\n",
    "                                        \"y_sup\": False,\n",
    "                                        \"gen_model\": False})                                        \n",
    "\n",
    "\n",
    "process_retrieval(\"train\", DATA, True, {\"cached\" : True, \n",
    "                                        \"train_enhancement\": False,\n",
    "                                        \"use_enhancement\": True,\n",
    "                                        \"enhancement_dataset\": \"train\",\n",
    "                                        \"y_sup\": False,\n",
    "                                        \"gen_model\": False})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# process_retrieval(\"test\", DATA, False, {\"cached\" : False, \n",
    "#                                         \"train_enhancement\": False,\n",
    "#                                         \"use_enhancement\": True,\n",
    "#                                         \"enhancement_dataset\": \"dev\",\n",
    "#                                         \"y_sup\": True})                                       \n",
    "\n",
    "# process_retrieval(\"test\", DATA, False, {\"cached\" : True, \n",
    "#                                         \"train_enhancement\": False,\n",
    "#                                         \"use_enhancement\": False,\n",
    "#                                         \"enhancement_dataset\": \"dev\",\n",
    "#                                         \"y_sup\": True})                                       \n",
    "\n",
    "process_retrieval(\"test\", DATA, False, {\"cached\" : True, \n",
    "                                        \"train_enhancement\": False,\n",
    "                                        \"use_enhancement\": True,\n",
    "                                        \"enhancement_dataset\": \"dev\",\n",
    "                                        \"y_sup\": True})                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1465,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing retrieval:  test\n",
      "Processed: 0, 42\n",
      "Processed: 10, 42\n",
      "Processed: 20, 42\n",
      "Processed: 30, 42\n",
      "Processed: 40, 42\n",
      "\n",
      "Part A Output: \n",
      "\n",
      "[{   'question_index': 0, 'sentence_index': 353, 'set_index': 0}]\n",
      "\n",
      "\n",
      "Processing retrieval:  test\n",
      "Processed: 0, 42\n",
      "Processed: 10, 42\n",
      "Processed: 20, 42\n",
      "Processed: 30, 42\n",
      "Processed: 40, 42\n",
      "\n",
      "Part A Output: \n",
      "\n",
      "[{   'question_index': 0, 'sentence_index': 25, 'set_index': 0}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_retrieval(\"test\", DATA, False, {\"cached\" : False, \n",
    "                                        \"train_enhancement\": False,\n",
    "                                        \"use_enhancement\": True,\n",
    "                                        \"enhancement_dataset\": \"train\",\n",
    "                                        \"y_sup\": True})                                       \n",
    "\n",
    "# process_retrieval(\"test\", DATA, False, {\"cached\" : True, \n",
    "#                                         \"train_enhancement\": False,\n",
    "#                                         \"use_enhancement\": False,\n",
    "#                                         \"enhancement_dataset\": \"train\",\n",
    "#                                         \"y_sup\": True})                                       \n",
    "\n",
    "process_retrieval(\"test\", DATA, False, {\"cached\" : True, \n",
    "                                        \"train_enhancement\": False,\n",
    "                                        \"use_enhancement\": True,\n",
    "                                        \"enhancement_dataset\": \"train\",\n",
    "                                        \"y_sup\": True})                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1466,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shim function for later clean\n",
    "\n",
    "# Thanks for this list to save me typing it : http://stackoverflow.com/questions/493174/is-there-a-way-to-convert-number-words-to-integers\\n\",\n",
    "numInWords = [\"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\",\n",
    "        \"nine\", \"ten\", \"eleven\", \"twelve\", \"thirteen\", \"fourteen\", \"fifteen\",\n",
    "        \"sixteen\", \"seventeen\", \"eighteen\", \"nineteen\", \"twenty\", \"thirty\", \"forty\", \"fifty\", \"sixty\", \"seventy\", \"eighty\", \"ninety\"\n",
    "       , \"hundred\", \"thousand\", \"million\", \"billion\", \"trillion\"]\n",
    "\n",
    "punctuation = [\"''\",'``','(','.',':', ',',')']\n",
    "\n",
    "\n",
    "months = [\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"]\n",
    "\n",
    "def isPunctuation(word):\n",
    "    return word in punctuation\n",
    "\n",
    "def isCapitalised (word):\n",
    "    if len(word) == 0:\n",
    "        return False\n",
    "    return word[0].isupper()\n",
    "\n",
    "# Obtained from training data\n",
    "postUnits = [u'%', u'century', u'years', u'percent', u'years ago', u'days', u'months', u'km', u'hours', u'times', u'inches', u'\\xb0C', u'minutes', u'acres', u'\\xb0F', u'weeks', u'people', u'sq mi', u'mi', u'ft', u'feet', u'metres', u'mm', u'square miles', u'miles', u'pm', u'per cent', u'year', u'copies', u'yuan', u'men', u'square feet', u'third', u'kilometres', u'nm', u'tonnes', u'species', u'decades', u'barrels', u'tons', u'largest', u'centuries', u'km2']\n",
    "preUnits = [u'$',u'around', u'late', u'early', u'nearly', u'since', u'approximately', u'number']\n",
    "\n",
    "# Returns true if the word represents a number\\n\",\n",
    "def isNumber(word):\n",
    "    pattern = \".?(\\\\d)+((,|.)(\\\\d)+)*\"\n",
    "    if re.match(pattern,word) :\n",
    "        return True\n",
    "    if word.lower() in numInWords:\n",
    "        return True\n",
    "    if word in months:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def isStopWord(word):\n",
    "    return word.lower() in stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1467,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grammar = \"\"\" ANS: {<JJ>?<N.*>*}\n",
    "                   {<DT>?<N.*>*}\n",
    "                   }<UH|POS|VB|VBG|RP|DT|MD|PRP$|TO|RB|JJS|PDT|IN|PRP|VBP|VBN|RBS|WRB|WP|EX|VBZ|WDT|VBD>{\n",
    "                    \"\"\"\n",
    "cp = nltk.RegexpParser(grammar) \n",
    "\n",
    "def chunk(words):\n",
    "    tokenWS = nltk.pos_tag(nltk.word_tokenize(words))\n",
    "    chunks =  cp.parse(tokenWS)\n",
    "    possAnswers = []\n",
    "    for subtree in chunks.subtrees():\n",
    "        if subtree.label() == 'ANS':\n",
    "            possAnswers.append((' '.join(word for word, pos in subtree.leaves()),'O'))\n",
    "    possAnswers.append((\"Nope\", \"CRAP\")) # To ensure nothing has 0 tags\n",
    "    return possAnswers    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1468,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_non_chunked_words_as_single_tags(words):\n",
    "    chunked_output = chunk(words)\n",
    "    token_words = nltk.pos_tag(nltk.word_tokenize(words))\n",
    "    if len(chunked_output) == 0:\n",
    "        chunked_words = [\"DEREKWANG\"]\n",
    "    else:\n",
    "        chunked_words = [nltk.word_tokenize(word_tag_pair[0]) for word_tag_pair in chunked_output ]    \n",
    "    all_word_tags = []\n",
    "    \n",
    "    current_chunk_index = 0\n",
    "    current_chunk_word = 0\n",
    "    current_chunk_list = chunked_words[0]\n",
    "    \n",
    "    for word_tag_pair in token_words:\n",
    "        word = word_tag_pair[0]\n",
    "        if word == current_chunk_list[current_chunk_word]:\n",
    "            # Need to move onto next word\n",
    "            if current_chunk_word == len(current_chunk_list) - 1:\n",
    "                # last word in this current chunk\n",
    "                all_word_tags.append(chunked_output[current_chunk_index])\n",
    "                current_chunk_index += 1\n",
    "                current_chunk_word = 0\n",
    "                if current_chunk_index == len(chunked_words):\n",
    "                    current_chunk_list = [\"NOPE\"]\n",
    "                else:\n",
    "                    current_chunk_list = chunked_words[current_chunk_index]\n",
    "            else :\n",
    "                current_chunk_word += 1\n",
    "        else :\n",
    "            # Need to add word, as it's not in a chunk :(\n",
    "            all_word_tags.append((word,'O'))\n",
    "    return all_word_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1469,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shim function for later clean\n",
    "\n",
    "def slow_refine_word_tags(taggedWordList):\n",
    "    newWordTags = []\n",
    "    for (word, tag) in taggedWordList:\n",
    "        if (tag == 'ORGANIZATION'):\n",
    "            tag = 'O'\n",
    "        if (tag == 'O'):\n",
    "            #Might be a number\n",
    "            if isNumber(word):\n",
    "                tag = 'NUMBER'\n",
    "            elif word in preUnits:\n",
    "                tag = 'PRENUM'\n",
    "            elif isPunctuation(word):\n",
    "                tag = 'PUNC'\n",
    "            elif word in postUnits:\n",
    "                tag = 'POSTNUM'\n",
    "            elif isCapitalised(word):\n",
    "                tag = \"OTHERCAP\"\n",
    "        newWordTags.append((word, tag))\n",
    "    \n",
    "    newWordTags = combineTags (newWordTags)\n",
    "    other_processed_tags = process_others(newWordTags)\n",
    "    return other_processed_tags\n",
    "        \n",
    "def combineTags(wordTags):\n",
    "    \n",
    "    newTags = []\n",
    "    prevWord = wordTags[0][0]\n",
    "    prevTag = wordTags[0][1]\n",
    "    \n",
    "    for (word, tag) in wordTags[1:]:\n",
    "        if tag == 'NUMBER' and prevTag == 'PRENUM':\n",
    "            prevTag = 'NUMBER'\n",
    "        elif prevTag == 'PRENUM':\n",
    "            prevTag = 'O'\n",
    "        if tag == 'POSTNUM' and prevTag == \"NUMBER\":\n",
    "            tag = \"NUMBER\"\n",
    "        elif tag == \"POSTNUM\":\n",
    "            tag = \"O\"\n",
    "        newTags.append((prevWord, prevTag))\n",
    "        prevWord = word\n",
    "        prevTag = tag\n",
    "    newTags.append((prevWord, prevTag))\n",
    "        \n",
    "    newNewTags = []\n",
    "    prevWord = newTags[0][0]\n",
    "    prevTag = newTags[0][1]\n",
    "    if (prevTag == \"OTHERCAP\" and newTags[1][1] != \"OTHERCAP\"):\n",
    "        prevTag = \"O\"\n",
    "        \n",
    "    for (word, tag) in newTags[1:]:\n",
    "#         print tag, prevTag\n",
    "        if tag == prevTag :\n",
    "            if word == '%':\n",
    "                prevWord += word\n",
    "            else :\n",
    "                if prevWord == '$':\n",
    "                    prevWord += word\n",
    "                else :\n",
    "                    prevWord += ' ' + word\n",
    "        else :\n",
    "            newNewTags.append((prevWord, prevTag))\n",
    "            prevWord = word\n",
    "            prevTag = tag\n",
    "            \n",
    "    newNewTags.append((prevWord, prevTag))\n",
    "    \n",
    "    return newNewTags\n",
    "\n",
    "def process_others(words_with_tags):\n",
    "    new_taggings = []\n",
    "    for (words, tag) in words_with_tags:\n",
    "        if tag == 'O':\n",
    "            chunk_results = add_non_chunked_words_as_single_tags(words)\n",
    "            for (word,tag) in chunk_results:\n",
    "                new_taggings.append((word, tag))\n",
    "            #new_taggings.append((words,tag))\n",
    "        else :\n",
    "            new_taggings.append((words, tag))\n",
    "    return new_taggings\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1470,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Shim function for later clean\n",
    "\n",
    "def fast_refine_word_tags(taggedWordList):\n",
    "    newWordTags = []\n",
    "    for (word, tag) in taggedWordList:\n",
    "        if (tag == 'ORGANIZATION'):\n",
    "            tag = 'O'\n",
    "        if (tag == 'O'):\n",
    "            #Might be a number\n",
    "            if isNumber(word):\n",
    "                tag = 'NUMBER'\n",
    "            elif isCapitalised(word):\n",
    "                tag = 'OTHERCAP'\n",
    "            elif word in preUnits:\n",
    "                tag = 'PRENUM'\n",
    "            elif word in postUnits:\n",
    "                tag = 'POSTNUM'\n",
    "            elif isStopWord(word):\n",
    "                tag = 'STOPWORD'\n",
    "            elif isPunctuation(word):\n",
    "                tag = 'PUNC'\n",
    "\n",
    "        newWordTags.append((word, tag))\n",
    "    \n",
    "    newWordTags = combineTags (newWordTags)\n",
    "    return newWordTags\n",
    "        \n",
    "def combineTags(wordTags):\n",
    "    \n",
    "    newTags = []\n",
    "    prevWord = wordTags[0][0]\n",
    "    prevTag = wordTags[0][1]\n",
    "    \n",
    "    for (word, tag) in wordTags[1:]:\n",
    "        if tag == 'NUMBER' and prevTag == 'PRENUM':\n",
    "            prevTag = 'NUMBER'\n",
    "        elif prevTag == 'PRENUM':\n",
    "            prevTag = 'O'\n",
    "        if tag == 'POSTNUM' and prevTag == \"NUMBER\":\n",
    "            tag = \"NUMBER\"\n",
    "        elif tag == \"POSTNUM\":\n",
    "            tag = \"O\"\n",
    "        newTags.append((prevWord, prevTag))\n",
    "        prevWord = word\n",
    "        prevTag = tag\n",
    "    newTags.append((prevWord, prevTag))\n",
    "    \n",
    "#     print newTags\n",
    "    \n",
    "    newNewTags = []\n",
    "    prevWord = newTags[0][0]\n",
    "    prevTag = newTags[0][1]\n",
    "    if (prevTag == \"OTHERCAP\"):\n",
    "        prevTag = \"O\"\n",
    "        \n",
    "    for (word, tag) in newTags[1:]:\n",
    "#         print tag, prevTag\n",
    "        if tag == prevTag :\n",
    "            prevWord += ' ' + word\n",
    "        else :\n",
    "            newNewTags.append((prevWord, prevTag))\n",
    "            prevWord = word\n",
    "            prevTag = tag\n",
    "            \n",
    "    newNewTags.append((prevWord, prevTag))\n",
    "    \n",
    "    return newNewTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1471,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_part_b_output(name, data, args):\n",
    "    \n",
    "    question_set = data[name][\"question_set\"]\n",
    "    a_output_answer_set = data[name][\"a_output_answer_set\"]\n",
    "    tagged_set = data[name][\"tagged_set\"]\n",
    "    \n",
    "    refine_func = args.get(\"refine_func\")\n",
    "    \n",
    "    part_b_output = []\n",
    "    \n",
    "    for i, result_a in enumerate(a_output_answer_set):\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print \"Processed: {0}\".format(i)\n",
    "        \n",
    "        stanford_tags = tagged_set[result_a[\"set_index\"]][result_a[\"sentence_index\"]]\n",
    "        \n",
    "        filtered_tags = refine_func(stanford_tags)\n",
    "        \n",
    "        question = question_set[result_a[\"set_index\"]][result_a[\"question_index\"]][\"question\"]\n",
    "        \n",
    "        result_b = {\n",
    "            \"set_index\"  : result_a[\"set_index\"],\n",
    "            \"question_index\" : result_a[\"question_index\"],\n",
    "            \"sentence_index\" : result_a[\"sentence_index\"],\n",
    "            \"candidates\" : filtered_tags\n",
    "        }\n",
    "        \n",
    "        part_b_output.append(result_b)\n",
    "        \n",
    "    return part_b_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1472,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_part_b(name, data, args):\n",
    "    \n",
    "    data[name][\"b_output_answer_set\"] = generate_part_b_output(name, data, args)\n",
    "    \n",
    "    print\n",
    "    print \"Part B Output: \"\n",
    "    pp.pprint(data[name][\"b_output_answer_set\"][:rapid_size])\n",
    "    print    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1473,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Shim function for later clean\n",
    "\n",
    "def evaluate_ner(name, data, args):\n",
    "    \n",
    "    question_set = data[name][\"question_set\"]\n",
    "    b_output_answer_set = data[name][\"b_output_answer_set\"]\n",
    "    \n",
    "    correct = []\n",
    "    wrong = []\n",
    "    \n",
    "    for result_b in b_output_answer_set:\n",
    "        \n",
    "        answer = question_set[result_b[\"set_index\"]][result_b[\"question_index\"]][\"answer\"]\n",
    "        \n",
    "        possible_candidates = result_b[\"candidates\"]\n",
    "        \n",
    "        answer_exists_in_candidates = False\n",
    "        \n",
    "        for candidate in possible_candidates:\n",
    "            \n",
    "            candidate_string = candidate[0]\n",
    "            \n",
    "            if candidate_string == answer:\n",
    "                \n",
    "                answer_exists_in_candidates = True\n",
    "                \n",
    "                break\n",
    "        \n",
    "        if answer_exists_in_candidates:\n",
    "            correct.append(result_b)\n",
    "        else :\n",
    "            wrong.append(result_b)\n",
    "            \n",
    "    return (correct, wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1474,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_ner(name, data, stats=False, args={}):\n",
    "    print \"Processing ner: \", name\n",
    "    process_part_b(name, data, args)\n",
    "    if stats:\n",
    "        process_generic(name, data, \"ner\", evaluate_ner, args)\n",
    "        \n",
    "        correct_ner = len(data[name][\"ner_correct\"])\n",
    "        correct_ret = len(data[name][\"retrieval_correct\"])\n",
    "        \n",
    "        avg = correct_ner * 1.0 / correct_ret\n",
    "        \n",
    "        print \"ner\".capitalize() + \" Correct Average of Previous %: \", avg\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1475,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ner:  rapid\n",
      "Processed: 0\n",
      "\n",
      "Part B Output: \n",
      "[   {   'candidates': [   (u'Phonograph records', 'O'),\n",
      "                          (u'are', 'O'),\n",
      "                          (u'generally', 'O'),\n",
      "                          (u'described', 'O'),\n",
      "                          (u'by', 'O'),\n",
      "                          (u'their', 'O'),\n",
      "                          (u'diameter', 'O'),\n",
      "                          (u'in', 'O'),\n",
      "                          (u'inches', 'O'),\n",
      "                          (u'(', 'PUNC'),\n",
      "                          (u'12', 'NUMBER'),\n",
      "                          (u\"'' ,\", 'PUNC'),\n",
      "                          (u'10', 'NUMBER'),\n",
      "                          (u\"'' ,\", 'PUNC'),\n",
      "                          (u'7', 'NUMBER'),\n",
      "                          (u\"'' ) ,\", 'PUNC'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'rotational speed', 'O'),\n",
      "                          (u'in', 'O'),\n",
      "                          (u'rpm', 'O'),\n",
      "                          (u'at', 'O'),\n",
      "                          (u'which', 'O'),\n",
      "                          (u'they', 'O'),\n",
      "                          (u'are', 'O'),\n",
      "                          (u'played', 'O'),\n",
      "                          (u'(', 'PUNC'),\n",
      "                          (u'16 2\\u20443', 'NUMBER'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'33 1\\u20443', 'NUMBER'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'45', 'NUMBER'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'78', 'NUMBER'),\n",
      "                          (u') ,', 'PUNC'),\n",
      "                          (u'and', 'O'),\n",
      "                          (u'their', 'O'),\n",
      "                          (u'time capacity', 'O'),\n",
      "                          (u'resulting', 'O'),\n",
      "                          (u'from', 'O'),\n",
      "                          (u'a', 'O'),\n",
      "                          (u'combination', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'those', 'O'),\n",
      "                          (u'parameters', 'O'),\n",
      "                          (u'(', 'PUNC'),\n",
      "                          (u'LP', 'OTHERCAP'),\n",
      "                          (u'\\u2013', 'O'),\n",
      "                          (u'long', 'O'),\n",
      "                          (u'playing', 'O'),\n",
      "                          (u'33 1\\u20443', 'NUMBER'),\n",
      "                          (u'rpm', 'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'SP', 'OTHERCAP'),\n",
      "                          (u'\\u2013', 'O'),\n",
      "                          (u'78', 'NUMBER'),\n",
      "                          (u'rpm', 'O'),\n",
      "                          (u'single', 'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'EP', 'OTHERCAP'),\n",
      "                          (u'\\u2013', 'O'),\n",
      "                          (u'12-inch', 'NUMBER'),\n",
      "                          (u'single', 'O'),\n",
      "                          (u'or', 'O'),\n",
      "                          (u'extended', 'O'),\n",
      "                          (u'play', 'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'33', 'NUMBER'),\n",
      "                          (u'or', 'O'),\n",
      "                          (u'45', 'NUMBER'),\n",
      "                          (u'rpm', 'O'),\n",
      "                          (u')', 'PUNC'),\n",
      "                          (u';', 'O'),\n",
      "                          (u'their', 'O'),\n",
      "                          (u'reproductive quality', 'O'),\n",
      "                          (u'or', 'O'),\n",
      "                          (u'level', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'fidelity', 'O'),\n",
      "                          (u'(', 'PUNC'),\n",
      "                          (u'high-fidelity', 'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'orthophonic', 'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'full-range', 'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'etc', 'O'),\n",
      "                          (u'. ) ,', 'PUNC'),\n",
      "                          (u'and', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'number', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'audio channels', 'O'),\n",
      "                          (u'provided', 'O'),\n",
      "                          (u'(', 'PUNC'),\n",
      "                          (u'mono', 'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'stereo', 'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'quad', 'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'etc', 'O'),\n",
      "                          (u'. ) .', 'PUNC')],\n",
      "        'question_index': 0,\n",
      "        'sentence_index': 2,\n",
      "        'set_index': 0}]\n",
      "\n",
      "Ner Correct:  76\n",
      "Ner Wrong:  328\n",
      "Ner Total:  404\n",
      "Ner Overall Average %:  0.188118811881\n",
      "Ner Correct Average of Previous %:  0.434285714286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_ner(\"rapid\", DATA, True, {\"refine_func\": slow_refine_word_tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1476,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ner:  dev\n",
      "Processed: 0\n",
      "Processed: 1000\n",
      "Processed: 2000\n",
      "Processed: 3000\n",
      "Processed: 4000\n",
      "Processed: 5000\n",
      "Processed: 6000\n",
      "Warning: parsing empty text\n",
      "Processed: 7000\n",
      "Processed: 8000\n",
      "\n",
      "Part B Output: \n",
      "[   {   'candidates': [   (u'Night-vision devices', 'O'),\n",
      "                          (u'using', 'O'),\n",
      "                          (u'active', 'O'),\n",
      "                          (u'near-infrared illumination', 'O'),\n",
      "                          (u'allow', 'O'),\n",
      "                          (u'people', 'O'),\n",
      "                          (u'or', 'O'),\n",
      "                          (u'animals', 'O'),\n",
      "                          (u'to', 'O'),\n",
      "                          (u'be', 'O'),\n",
      "                          (u'observed', 'O'),\n",
      "                          (u'without', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'observer', 'O'),\n",
      "                          (u'being', 'O'),\n",
      "                          (u'detected', 'O'),\n",
      "                          (u'.', 'PUNC')],\n",
      "        'question_index': 0,\n",
      "        'sentence_index': 1,\n",
      "        'set_index': 0}]\n",
      "\n",
      "Ner Correct:  2669\n",
      "Ner Wrong:  5794\n",
      "Ner Total:  8463\n",
      "Ner Overall Average %:  0.315372799244\n",
      "Ner Correct Average of Previous %:  0.523230739071\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_ner(\"dev\", DATA, True, {\"refine_func\": slow_refine_word_tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1477,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ner:  train\n",
      "Processed: 0\n",
      "Processed: 1000\n",
      "Processed: 2000\n",
      "Processed: 3000\n",
      "Processed: 4000\n",
      "Processed: 5000\n",
      "Processed: 6000\n",
      "Processed: 7000\n",
      "Processed: 8000\n",
      "Processed: 9000\n",
      "Processed: 10000\n",
      "Processed: 11000\n",
      "Processed: 12000\n",
      "Processed: 13000\n",
      "Processed: 14000\n",
      "Processed: 15000\n",
      "Processed: 16000\n",
      "Processed: 17000\n",
      "Processed: 18000\n",
      "Processed: 19000\n",
      "Processed: 20000\n",
      "Processed: 21000\n",
      "Processed: 22000\n",
      "Processed: 23000\n",
      "Processed: 24000\n",
      "Processed: 25000\n",
      "Processed: 26000\n",
      "Processed: 27000\n",
      "Processed: 28000\n",
      "Processed: 29000\n",
      "Processed: 30000\n",
      "Processed: 31000\n",
      "Processed: 32000\n",
      "Processed: 33000\n",
      "Processed: 34000\n",
      "Processed: 35000\n",
      "Processed: 36000\n",
      "Processed: 37000\n",
      "Processed: 38000\n",
      "Processed: 39000\n",
      "Processed: 40000\n",
      "Processed: 41000\n",
      "Processed: 42000\n",
      "Processed: 43000\n",
      "Processed: 44000\n",
      "Processed: 45000\n",
      "Processed: 46000\n",
      "Processed: 47000\n",
      "Processed: 48000\n",
      "Processed: 49000\n",
      "Processed: 50000\n",
      "Processed: 51000\n",
      "Processed: 52000\n",
      "Processed: 53000\n",
      "Processed: 54000\n",
      "Processed: 55000\n",
      "Processed: 56000\n",
      "Processed: 57000\n",
      "Processed: 58000\n",
      "Processed: 59000\n",
      "Processed: 60000\n",
      "Processed: 61000\n",
      "Processed: 62000\n",
      "Processed: 63000\n",
      "Processed: 64000\n",
      "Processed: 65000\n",
      "Processed: 66000\n",
      "Processed: 67000\n",
      "Processed: 68000\n",
      "Processed: 69000\n",
      "Processed: 70000\n",
      "\n",
      "Part B Output: \n",
      "[   {   'candidates': [   (u'Phonograph records', 'O'),\n",
      "                          (u'are', 'STOPWORD'),\n",
      "                          (u'generally described', u'O'),\n",
      "                          (u'by their', 'STOPWORD'),\n",
      "                          (u'diameter', u'O'),\n",
      "                          (u'in', 'STOPWORD'),\n",
      "                          (u'inches', 'O'),\n",
      "                          (u'(', 'PUNC'),\n",
      "                          (u'12', 'NUMBER'),\n",
      "                          (u\"'' ,\", 'PUNC'),\n",
      "                          (u'10', 'NUMBER'),\n",
      "                          (u\"'' ,\", 'PUNC'),\n",
      "                          (u'7', 'NUMBER'),\n",
      "                          (u\"'' ) ,\", 'PUNC'),\n",
      "                          (u'the', 'STOPWORD'),\n",
      "                          (u'rotational speed', u'O'),\n",
      "                          (u'in', 'STOPWORD'),\n",
      "                          (u'rpm', u'O'),\n",
      "                          (u'at which they are', 'STOPWORD'),\n",
      "                          (u'played', u'O'),\n",
      "                          (u'(', 'PUNC'),\n",
      "                          (u'16 2\\u20443', 'NUMBER'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'33 1\\u20443', 'NUMBER'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'45', 'NUMBER'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'78', 'NUMBER'),\n",
      "                          (u') ,', 'PUNC'),\n",
      "                          (u'and their', 'STOPWORD'),\n",
      "                          (u'time capacity resulting', u'O'),\n",
      "                          (u'from a', 'STOPWORD'),\n",
      "                          (u'combination', u'O'),\n",
      "                          (u'of those', 'STOPWORD'),\n",
      "                          (u'parameters', u'O'),\n",
      "                          (u'(', 'PUNC'),\n",
      "                          (u'LP', 'OTHERCAP'),\n",
      "                          (u'\\u2013 long playing', u'O'),\n",
      "                          (u'33 1\\u20443', 'NUMBER'),\n",
      "                          (u'rpm', u'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'SP', 'OTHERCAP'),\n",
      "                          (u'\\u2013', u'O'),\n",
      "                          (u'78', 'NUMBER'),\n",
      "                          (u'rpm single', u'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'EP', 'OTHERCAP'),\n",
      "                          (u'\\u2013', u'O'),\n",
      "                          (u'12-inch', 'NUMBER'),\n",
      "                          (u'single', u'O'),\n",
      "                          (u'or', 'STOPWORD'),\n",
      "                          (u'extended play', u'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'33', 'NUMBER'),\n",
      "                          (u'or', 'STOPWORD'),\n",
      "                          (u'45', 'NUMBER'),\n",
      "                          (u'rpm', u'O'),\n",
      "                          (u')', 'PUNC'),\n",
      "                          (u';', u'O'),\n",
      "                          (u'their', 'STOPWORD'),\n",
      "                          (u'reproductive quality', u'O'),\n",
      "                          (u'or', 'STOPWORD'),\n",
      "                          (u'level', u'O'),\n",
      "                          (u'of', 'STOPWORD'),\n",
      "                          (u'fidelity', u'O'),\n",
      "                          (u'(', 'PUNC'),\n",
      "                          (u'high-fidelity', u'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'orthophonic', u'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'full-range', u'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'etc', u'O'),\n",
      "                          (u'. ) ,', 'PUNC'),\n",
      "                          (u'and the', 'STOPWORD'),\n",
      "                          (u'number', 'O'),\n",
      "                          (u'of', 'STOPWORD'),\n",
      "                          (u'audio channels provided', u'O'),\n",
      "                          (u'(', 'PUNC'),\n",
      "                          (u'mono', u'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'stereo', u'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'quad', u'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'etc', u'O'),\n",
      "                          (u'. ) .', 'PUNC')],\n",
      "        'question_index': 0,\n",
      "        'sentence_index': 2,\n",
      "        'set_index': 0}]\n",
      "\n",
      "Ner Correct:  21309\n",
      "Ner Wrong:  48850\n",
      "Ner Total:  70159\n",
      "Ner Overall Average %:  0.30372439744\n",
      "Ner Correct Average of Previous %:  0.480744500846\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_ner(\"train\", DATA, True, {\"refine_func\": fast_refine_word_tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1478,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ner:  test\n",
      "Processed: 0\n",
      "Processed: 1000\n",
      "Warning: parsing empty text\n",
      "Processed: 2000\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Processed: 3000\n",
      "Processed: 4000\n",
      "Processed: 5000\n",
      "Processed: 6000\n",
      "Processed: 7000\n",
      "Processed: 8000\n",
      "\n",
      "Part B Output: \n",
      "[   {   'candidates': [   (u'This', 'O'),\n",
      "                          (u'was', 'O'),\n",
      "                          (u'welcomed', 'O'),\n",
      "                          (u'by', 'O'),\n",
      "                          (u'France', u'LOCATION'),\n",
      "                          (u'and', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'UK', u'LOCATION'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'where', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'citizens', 'O'),\n",
      "                          (u'began', 'O'),\n",
      "                          (u'to', 'O'),\n",
      "                          (u'turn', 'O'),\n",
      "                          (u'against', 'O'),\n",
      "                          (u'their', 'O'),\n",
      "                          (u'governments', 'O'),\n",
      "                          (u'as', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'war', 'O'),\n",
      "                          (u'dragged', 'O'),\n",
      "                          (u'on', 'O'),\n",
      "                          (u'.', 'PUNC')],\n",
      "        'question_index': 0,\n",
      "        'sentence_index': 25,\n",
      "        'set_index': 0}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_ner(\"test\", DATA, False, {\"refine_func\": slow_refine_word_tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1479,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.parse.stanford import StanfordDependencyParser\n",
    "\n",
    "import os\n",
    "os.environ['CLASSPATH'] = 'stanford-parser-full-2016-10-31'\n",
    "\n",
    "dep_parser = StanfordDependencyParser(model_path=\"./englishPCFG.ser.gz\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1480,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove the non-word entities from answer-entities\n",
    "def process_answer_entities(anwser_entities):\n",
    "    new_anwser_entities =[]\n",
    "    for (entity,entity_type) in anwser_entities:\n",
    "        tokenized_entity = word_tokenize(entity)\n",
    "        #print tokenized_entity\n",
    "        temp = []\n",
    "        for ele in tokenized_entity:\n",
    "            temp.append(ele.encode('utf-8'))\n",
    "        temp = ' '.join(temp)\n",
    "        new_anwser_entities.append(temp)\n",
    "    result = ' '.join(new_anwser_entities)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1481,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, answers whose content words all appear in the question should be ranked lowest.\n",
    "\n",
    "def first_filter(question, answer_entities):\n",
    "   \n",
    "    ranked_list = []\n",
    "    \n",
    "    question = set(pre_process_tf_idf(question))\n",
    "    \n",
    "#     print question\n",
    "#     print\n",
    "    \n",
    "    for entity in answer_entities:\n",
    "\n",
    "        raw_span = entity[0]\n",
    "        span_tag = entity[1]\n",
    "        \n",
    "        set_span = set(pre_process_tf_idf(raw_span))\n",
    "        \n",
    "        if span_tag != \"O\" and span_tag != \"STOPWORD\" and span_tag !=\"PUNC\":\n",
    "            \n",
    "            if set_span.issubset(question):\n",
    "                \n",
    "                ranked_list.append([entity, 1])\n",
    "#                 print \"IN\", raw_span, span_tag, set_span, question\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                ranked_list.append([entity, 2])\n",
    "#                 print \"OUT\", raw_span, span_tag, set_span, question\n",
    "    \n",
    "    return sorted(ranked_list, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1482,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, answers whose content words all appear in the question should be ranked lowest.\n",
    "\n",
    "def first_filter_object(question, answer_entities):\n",
    "   \n",
    "    ranked_list = []\n",
    "    \n",
    "    question = set(pre_process_tf_idf(question))\n",
    "    \n",
    "#     print question\n",
    "#     print\n",
    "    \n",
    "    for entity in answer_entities:\n",
    "\n",
    "        raw_span = entity[0]\n",
    "        span_tag = entity[1]\n",
    "        \n",
    "        set_span = set(pre_process_tf_idf(raw_span))\n",
    "        \n",
    "        if span_tag != \"STOPWORD\" and span_tag !=\"PUNC\": #span_tag != \"O\" and\n",
    "            \n",
    "            if span_tag == \"O\":\n",
    "                \n",
    "                if len(set_span) > 1:\n",
    "                    ranked_list.append([entity, 0])\n",
    "            \n",
    "            elif set_span.issubset(question):\n",
    "                \n",
    "                ranked_list.append([entity, 1])\n",
    "#                 print \"IN\", raw_span, span_tag, set_span, question\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                ranked_list.append([entity, 2])\n",
    "#                 print \"OUT\", raw_span, span_tag, set_span, question\n",
    "    \n",
    "    return sorted(ranked_list, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1483,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, answers whose content words all appear in the question should be ranked lowest.\n",
    "\n",
    "def first_filter_object_stop(question, answer_entities):\n",
    "   \n",
    "    ranked_list = []\n",
    "    \n",
    "    question = set(pre_process_tf_idf(question))\n",
    "    \n",
    "#     print question\n",
    "#     print\n",
    "    \n",
    "    for entity in answer_entities:\n",
    "\n",
    "        raw_span = entity[0]\n",
    "        span_tag = entity[1]\n",
    "        \n",
    "        set_span = set(pre_process_tf_idf(raw_span))\n",
    "        \n",
    "        if span_tag !=\"PUNC\": #span_tag != \"O\" and\n",
    "            \n",
    "            if span_tag == \"O\" or span_tag == \"STOPWORD\":\n",
    "                \n",
    "                if len(set_span) > 1:\n",
    "                    \n",
    "                    ranked_list.append([entity, 0])\n",
    "            \n",
    "            elif set_span.issubset(question):\n",
    "                \n",
    "                ranked_list.append([entity, 1])\n",
    "#                 print \"IN\", raw_span, span_tag, set_span, question\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                ranked_list.append([entity, 2])\n",
    "#                 print \"OUT\", raw_span, span_tag, set_span, question\n",
    "    \n",
    "    return sorted(ranked_list, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1484,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Second, answers which match the question type should be ranked higher than those that don't; for this, you\n",
    "# should build a simple rule-based question type classifier based on key words (e.g. questions which contain \"who\" are\n",
    "# people).\n",
    "\n",
    "# First, answers whose content words all appear in the question should be ranked lowest.\n",
    "\n",
    "def second_filter(question, ranked_list):\n",
    "   \n",
    "    question_type = getQuestionType(question)\n",
    "#     print question_type\n",
    "    \n",
    "    for index, answer in enumerate(ranked_list):\n",
    "        \n",
    "        entity_tag = answer[0][1]\n",
    "        \n",
    "        if entity_tag == question_type:\n",
    "#             print \"MATCH\", answer[0], question_type, question\n",
    "            ranked_list[index].append(2)\n",
    "#             ranked_list[index][1] += 1\n",
    "        else:\n",
    "            ranked_list[index].append(1)\n",
    "#             ranked_list[index][1] -= 1\n",
    "            \n",
    "    return ranked_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1485,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pre_process_open_class(line):\n",
    "    tokenized_sentence = word_tokenizer.tokenize(line.lower())\n",
    "    lemmatized_sentence = [lemmatize(token) for token in tokenized_sentence]\n",
    "    filtered_sentence = [token for token in lemmatized_sentence if token not in filter_tokens]\n",
    "    tagged_sent = nltk.pos_tag(lemmatized_sentence)\n",
    "    final = []\n",
    "       \n",
    "    for word, tag in tagged_sent:\n",
    "        #expand the open-class word to noun,verb,adj and adv\n",
    "        if \"V\" in tag or \"NN\" in tag or 'JJ' in tag or 'RB' in tag:\n",
    "#             final.append((word,tag))\n",
    "            final.append(word)\n",
    "            \n",
    "#     print \"RESULT: \", final\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1486,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Third, among entities of the same type, the prefered entity should be the one which is closer in the sentence to a\n",
    "# closed-class word from the question.\n",
    "\n",
    "def third_filter(question, possAnswers, ranked_list):\n",
    "    \n",
    "    question = pre_process_open_class(question)\n",
    "\n",
    "    answer_sent = \" \".join([x[0] for x in possAnswers])\n",
    "    answer_sent = pre_process_tf_idf(answer_sent)\n",
    "    raw_answer_sent = \" \".join(answer_sent)\n",
    "    \n",
    "#     print \"QUESTION: \"\n",
    "#     pp.pprint(question)\n",
    "#     print \"ANSWER: \"\n",
    "#     pp.pprint(answer_sent)\n",
    "#     pp.pprint(raw_answer_sent)\n",
    "    \n",
    "    for index, answer in enumerate(ranked_list):\n",
    "\n",
    "        span_tag = answer[0][1]\n",
    "        raw_span = answer[0][0]\n",
    "\n",
    "        proc_span = pre_process_tf_idf(raw_span)\n",
    "\n",
    "        raw_proc_span = \" \".join(proc_span)\n",
    "        new_raw_proc_span = \"-\".join(proc_span)\n",
    "\n",
    "        raw_answer_sent = raw_answer_sent.replace(raw_proc_span, new_raw_proc_span)\n",
    "    \n",
    "    answer_sent = raw_answer_sent.split(\" \")\n",
    "    \n",
    "    avg_dict = defaultdict(float)\n",
    "    \n",
    "    for open_class in question:\n",
    "        \n",
    "        if open_class in answer_sent:\n",
    "            \n",
    "            open_class_locations = [i for i, x in enumerate(answer_sent) if x == open_class]\n",
    "            \n",
    "#             print \"OPEN CLASS: \", repr(open_class)\n",
    "\n",
    "            for index, answer in enumerate(ranked_list):\n",
    "\n",
    "                span_tag = answer[0][1]\n",
    "                raw_span = answer[0][0]\n",
    "\n",
    "                proc_span = pre_process_tf_idf(raw_span)\n",
    "                \n",
    "                raw_proc_span = \" \".join(proc_span)\n",
    "                new_raw_proc_span = \"-\".join(proc_span)\n",
    "                \n",
    "                proc_span_locations = [i for i, x in enumerate(answer_sent) if x == new_raw_proc_span]\n",
    "                \n",
    "                min_dist = len(answer_sent)\n",
    "                min_dist_ind = (None, None)\n",
    "                \n",
    "                for loc1 in proc_span_locations:\n",
    "                    \n",
    "                    for loc2 in open_class_locations:\n",
    "                        \n",
    "                        dist = abs(loc1 - loc2)\n",
    "                        \n",
    "                        if dist < min_dist:\n",
    "                            \n",
    "                            min_dist = dist\n",
    "                            min_dist_ind = (loc1, loc2)\n",
    "                \n",
    "#                 print \"PROC: \", proc_span_locations\n",
    "#                 print \"OPEN CLASS: \", open_class_locations                \n",
    "                scale = (len(answer_sent) - min_dist) * 1.0 / len(answer_sent)\n",
    "#                 print \"JOINT: \", min_dist_ind, scale\n",
    "                avg_dict[index] += scale\n",
    "#                 ranked_list[index][1] *= scale\n",
    "    \n",
    "    for key, value in avg_dict.iteritems():\n",
    "        ranked_list[key].append(value / len(question))\n",
    "\n",
    "    return ranked_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1487,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduce_rank(ranking_list):\n",
    "    \n",
    "    new_ranking = []\n",
    "    \n",
    "    for rank in ranking_list:\n",
    "        \n",
    "        new_rank = ( rank[1] + rank[2] )\n",
    "        \n",
    "        if len(rank) == 4:\n",
    "             new_rank *= rank[3]\n",
    "        \n",
    "        new_ranking.append([rank[0], new_rank])\n",
    "        \n",
    "    return sorted(new_ranking, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1488,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1489,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_result(fourth_pass):\n",
    "    top_answer = fourth_pass[0]\n",
    "    predicted_answer = top_answer[0][0]    \n",
    "    \n",
    "    return predicted_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1490,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def multi_pass(first_filter_funcs, question, candidates, mem=None):\n",
    "    \n",
    "    if len(first_filter_funcs) > 0:\n",
    "    \n",
    "        first_pass = first_filter_funcs.pop(0)(question, candidates)\n",
    "        \n",
    "        second_pass = second_filter(question, first_pass)\n",
    "\n",
    "        third_pass = third_filter(question, candidates, second_pass)\n",
    "\n",
    "        fourth_pass = reduce_rank(third_pass)\n",
    "\n",
    "        if len(fourth_pass) > 0:\n",
    "            \n",
    "            predicted_answer = get_result(fourth_pass)\n",
    "            \n",
    "            return [fourth_pass, third_pass, predicted_answer]\n",
    "        else:\n",
    "            return multi_pass(first_filter_funcs, question, candidates, [fourth_pass, third_pass])\n",
    "    else:\n",
    "        \n",
    "        hits = [x for x in candidates if x[1] != \"PUNC\" or x[1] == \"STOPWORDS\"]                        \n",
    "        predicted_answer = random.choice(hits)[0]\n",
    "        \n",
    "        return mem + [predicted_answer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1491,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tagger(words):\n",
    "    return nltk.pos_tag(words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1492,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_feature(feature, sen_proc, sen_proc_set, sen_proc_tag, question_proc_set, question_type, a_new_x):\n",
    "    \n",
    "#     pp.pprint(feature)    \n",
    "    \n",
    "    open_dist = 0.5\n",
    "    \n",
    "    if len(feature) > 3:\n",
    "        open_dist = feature[3]\n",
    "    \n",
    "                \n",
    "        \n",
    "    c_feature =  {\n",
    "            \"answer_type\": feature[0][1],\n",
    "            \"first\" : feature[1],\n",
    "            \"second\": feature[2],\n",
    "            \"question_type\": question_type,\n",
    "            \"open_dist\": open_dist,            \n",
    "    }\n",
    "    \n",
    "    answer_proc = pre_process_tf_idf(feature[0][0].encode('ascii', 'ignore'))\n",
    "       \n",
    "    answer_proc_set = set(answer_proc)\n",
    "    \n",
    "    delt_proc_set = sen_proc_set.symmetric_difference(answer_proc_set)\n",
    "           \n",
    "    for x in delt_proc_set:   \n",
    "        for y in question_proc_set:               \n",
    "            feature_name = \"DSQ {0} {1}\".format(y, x)\n",
    "            c_feature[feature_name] = 1.0\n",
    "    \n",
    "    for x in answer_proc_set:\n",
    "        for y in question_proc_set:\n",
    "            feature_name = \"DAQ {0} {1}\".format(y, x)\n",
    "            c_feature[feature_name] = 1.0\n",
    "   \n",
    "    if len(answer_proc) > 0:\n",
    "    \n",
    "        first_answer_proc = answer_proc[0]\n",
    "        second_answer_proc = answer_proc[-1]\n",
    "        \n",
    "        first_answer_proc_index = None\n",
    "        second_answer_proc_index = None\n",
    "        \n",
    "        if first_answer_proc in sen_proc:       \n",
    "            first_answer_proc_index = sen_proc.index(first_answer_proc)\n",
    "            \n",
    "        if second_answer_proc in sen_proc:\n",
    "            second_answer_proc_index = sen_proc.index(second_answer_proc)\n",
    "\n",
    "        inter_proc_set = sen_proc_set.intersection(question_proc_set)\n",
    "  \n",
    "        #pp.pprint(sen_proc_tag)\n",
    "#         print \"Answer: \"\n",
    "#         pp.pprint(answer_proc)\n",
    "#         print \"Answer Bounds: \"\n",
    "#         print first_answer_proc, first_answer_proc_index\n",
    "#         print second_answer_proc, second_answer_proc_index\n",
    "        \n",
    "#         print \"Sen/Q Sets: \"\n",
    "#         pp.pprint(sen_proc_set)\n",
    "#         pp.pprint(question_proc_set)\n",
    "#         pp.pprint(inter_proc_set)\n",
    "        \n",
    "#         pp.pprint(\"Sen/I Sets: \")\n",
    "#         pp.pprint(zip([i for i, v in enumerate(sen_proc)], sen_proc))        \n",
    "#         pp.pprint(zip([i for i, v in enumerate(sen_proc)], sen_proc_tag))        \n",
    "\n",
    "        for x in inter_proc_set:\n",
    "        \n",
    "            x_index = sen_proc.index(x)\n",
    "            \n",
    "#             print x, x_index, first_answer_proc_index, second_answer_proc_index\n",
    "            \n",
    "            feature_name = None\n",
    "        \n",
    "            if first_answer_proc_index != None:\n",
    "            \n",
    "                left_bool = (x_index < first_answer_proc_index and x_index >= first_answer_proc_index - 2)\n",
    "\n",
    "                if left_bool:\n",
    "\n",
    "                    entries = [sen_proc_tag[x_index][1]]\n",
    "\n",
    "                    for y in sen_proc_tag[x_index+1:first_answer_proc_index]:\n",
    "                        entries.append(y[1])\n",
    "\n",
    "                    entries.append(sen_proc_tag[first_answer_proc_index][1])\n",
    "\n",
    "                    entries_str = \" -> \".join(entries)\n",
    "\n",
    "                    feature_name = \"PSA {0}\".format(entries_str)\n",
    "            \n",
    "            if second_answer_proc_index != None:\n",
    "                \n",
    "                right_bool = (x_index > second_answer_proc_index and x_index <= second_answer_proc_index + 2)\n",
    "\n",
    "                if right_bool:\n",
    "\n",
    "                    entries = []\n",
    "\n",
    "                    for y in sen_proc_tag[second_answer_proc_index:x_index]:\n",
    "                        entries.append(y[1])\n",
    "\n",
    "                    entries.append(sen_proc_tag[x_index][1])\n",
    "\n",
    "                    entries_str = \" <- \".join(entries)\n",
    "\n",
    "                    feature_name = \"PSA {0}\".format(entries_str)\n",
    "\n",
    "            if feature_name != None:\n",
    "                c_feature[feature_name] = 1.0\n",
    "#                 print feature_name\n",
    "    \n",
    "#     c_feature.update(a_new_x)\n",
    "    \n",
    "#     pp.pprint(c_feature)\n",
    "    \n",
    "    return c_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1493,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dep_tree(string):\n",
    "    \n",
    "    parses = [parse for parse in dep_parser.raw_parse(string.encode('ascii', 'ignore'))]\n",
    "    \n",
    "    if len(parses) > 0:\n",
    "        return parses[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1494,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def processed_relations(string):\n",
    "    \n",
    "    dep = get_dep_tree(string)\n",
    "    \n",
    "    l = list(dep.triples())\n",
    "\n",
    "    rela_struct = defaultdict(list)\n",
    "\n",
    "    prune = { \"CC\": True, \".\": True, \": True,\": True, \":\": True, \"-LRB-\": True, \"-RRB-\": True, \"POS\": True, \"DT\": True, \"IN\": True, \"TO\": True }\n",
    "\n",
    "    for a in l:\n",
    "\n",
    "        source_tuple = a[0]\n",
    "\n",
    "        relation = a[1]\n",
    "\n",
    "        sink_tuple = a[2]\n",
    "\n",
    "        source_word = source_tuple[0]\n",
    "        source_word_tag = source_tuple[1]\n",
    "\n",
    "        sink_word = sink_tuple[0]\n",
    "        sink_word_tag = sink_tuple[1]\n",
    "        \n",
    "#         print source_tuple, relation, sink_tuple\n",
    "\n",
    "        if source_word not in prune and sink_word_tag not in prune:   \n",
    "            rela_struct[source_word].append((relation, \"->\", sink_word))   \n",
    "            rela_struct[sink_word].append((relation, \"<-\", source_word))                        \n",
    "\n",
    "    return rela_struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1495,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_part_c_output(name, data, args):\n",
    "        \n",
    "    question_set = data[name][\"question_set\"]\n",
    "    document_set = data[name][\"document_set\"]\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    part_c_output = []\n",
    "    \n",
    "    cached = args.get(\"cached\")\n",
    "    enhancement_dataset = args.get(\"enhancement_dataset\")\n",
    "    \n",
    "    train_enhancement = args.get(\"train_enhancement\")\n",
    "    use_enhancement = args.get(\"use_enhancement\")\n",
    "    \n",
    "    cache_dict = None\n",
    "    data_a_cache_dict = data[name][\"part_a_cache_dict\"]\n",
    "    \n",
    "    if cached:\n",
    "        \n",
    "        cache_dict = data[name][\"part_c_cache_dict\"]\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        cache_dict = {}\n",
    "        \n",
    "        cache_dict[\"pass_cache\"] = []\n",
    "        \n",
    "        if use_enhancement:\n",
    "            \n",
    "            cache_dict[\"enhancement_cache\"] = []    \n",
    "        \n",
    "    b_output_answer_set = data[name][\"b_output_answer_set\"]\n",
    "    \n",
    "    if use_enhancement:\n",
    "\n",
    "        model = data[enhancement_dataset][\"part_c_cache_dict\"][\"model\"]\n",
    "        vec = data[enhancement_dataset][\"part_c_cache_dict\"][\"X_vec\"]\n",
    "    \n",
    "    for i, result_b in enumerate(b_output_answer_set):\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print \"Processed: {0}\".format(i)\n",
    "        \n",
    "        predicted_answer = None        \n",
    "        \n",
    "        question = question_set[result_b[\"set_index\"]][result_b[\"question_index\"]][\"question\"]\n",
    "        candidate_sentence = document_set[result_b[\"set_index\"]][result_b[\"sentence_index\"]]\n",
    "        \n",
    "        if train_enhancement:\n",
    "            actual_answer = question_set[result_b[\"set_index\"]][result_b[\"question_index\"]][\"answer\"]\n",
    "        \n",
    "        question_type = getQuestionType(question)\n",
    "        question_proc_set = set(pre_process_tf_idf(question.encode('ascii', 'ignore')))\n",
    "#         rela_proc = processed_relations(candidate_sentence)\n",
    "        sen_proc = pre_process_tf_idf(candidate_sentence.encode('ascii', 'ignore'))\n",
    "        sen_proc_set = set(sen_proc)\n",
    "        sen_proc_tag = tagger(sen_proc)\n",
    "        \n",
    "        rela_proc = None\n",
    "        \n",
    "        if cached:\n",
    "            \n",
    "            (fourth_pass, third_pass, predicted_answer) = cache_dict[\"pass_cache\"][i]\n",
    "            \n",
    "            if use_enhancement:\n",
    "                \n",
    "#                 a_new_x = data_a_cache_dict[\"X_best\"][result_b[\"set_index\"]][result_b[\"question_index\"]]\n",
    "                a_new_x = {}\n",
    "                new_xs = [build_feature(x, sen_proc, sen_proc_set, sen_proc_tag, question_proc_set, question_type, a_new_x) for x in third_pass]\n",
    "                \n",
    "#                 pp.pprint(new_xs)\n",
    "\n",
    "                if len(new_xs) > 0:\n",
    "\n",
    "                    new_features = vec.transform(new_xs) #.toarray()\n",
    "\n",
    "                    prob_ys = model.predict_proba(new_features)\n",
    "                    best_y_index = np.argmax(prob_ys[:, 1])\n",
    "\n",
    "                    predicted_answer = third_pass[best_y_index][0][0]\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            (fourth_pass, third_pass, predicted_answer) = multi_pass([first_filter, first_filter_object, first_filter_object_stop], question, result_b[\"candidates\"])\n",
    "            \n",
    "            cache_dict[\"pass_cache\"].append((fourth_pass, third_pass, predicted_answer))\n",
    "                        \n",
    "            if train_enhancement:\n",
    "\n",
    "#                 a_new_x = data_a_cache_dict[\"X_best\"][result_b[\"set_index\"]][result_b[\"question_index\"]]\n",
    "                \n",
    "#                 pp.pprint(a_new_x)\n",
    "                a_new_x = {}\n",
    "                \n",
    "                new_xs = [build_feature(x, sen_proc, sen_proc_set, sen_proc_tag, question_proc_set, question_type, a_new_x) for x in third_pass]\n",
    "                new_ys = [int(feature[0][0] == actual_answer) for feature in third_pass]\n",
    "                \n",
    "#                 pp.pprint(new_xs)\n",
    "#                 pp.pprint(new_ys)\n",
    "\n",
    "                X += new_xs\n",
    "                Y += new_ys\n",
    "        \n",
    "        predicted_answer = predicted_answer.replace(\" %\", \"%\").replace(\"$ \", \"$\")\n",
    "\n",
    "        result_c = {\n",
    "            \"set_index\"  : result_b[\"set_index\"],\n",
    "            \"question_index\" : result_b[\"question_index\"],\n",
    "            \"sentence_index\" : result_b[\"sentence_index\"],\n",
    "            \"candidates\": result_b[\"candidates\"],\n",
    "            \"ranked_answers\": fourth_pass,\n",
    "            \"vector_ranked_answers\": third_pass,\n",
    "            \"predicted_answer\" : predicted_answer\n",
    "        }\n",
    "        \n",
    "        part_c_output.append(result_c)\n",
    "        \n",
    "#         if i > 10:\n",
    "#             break\n",
    "           \n",
    "    if not cached:\n",
    "        \n",
    "        if train_enhancement:\n",
    "        \n",
    "            vec = DictVectorizer()                \n",
    "            X = vec.fit_transform(X) #.toarray()\n",
    "            Y = np.array(Y)\n",
    "\n",
    "            cache_dict[\"X_vec\"] = vec\n",
    "            cache_dict[\"X\"] = X\n",
    "            cache_dict[\"Y\"] = Y\n",
    "\n",
    "            print \"Shape X/Y: \", cache_dict[\"X\"].shape, cache_dict[\"Y\"].shape\n",
    "#             print \"Types X: \", vec.get_feature_names()        \n",
    "            print \"Example X: \", X[0]\n",
    "            print \"Example Y: \", Y[0]            \n",
    "        \n",
    "        data[name][\"part_c_cache_dict\"] = cache_dict            \n",
    "        \n",
    "    return part_c_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1496,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Adapted generator from guide notebook: WSTA_N2_text_classification.ipynb\n",
    "# from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# def check_results(predictions, classifications, name, model):\n",
    "    \n",
    "#     print \"==== \", name, \" ====\\n\"\n",
    "#     print \"Parameters: \\n\"\n",
    "#     pp.pprint(model.get_params())\n",
    "    \n",
    "#     accuracy = accuracy_score(classifications, predictions)\n",
    "#     f_score = f1_score(classifications, predictions, average=\"macro\", pos_label=\"positive\")    \n",
    "#     report = classification_report(classifications, predictions)\n",
    "    \n",
    "#     print \"\\nAccuracy:\", accuracy\n",
    "#     print \"F-score (macro):\", f_score, \"\\n\"    \n",
    "#     print \"Classification Report:\"\n",
    "#     print report\n",
    "    \n",
    "#     return {\"accuracy\": accuracy, \"f_score\": f_score}\n",
    "\n",
    "# def run_model(model_name, model, train_x, train_y, test_x, test_y):\n",
    "    \n",
    "#     train_vectorizer, train_feature_matrix = prepare_bow_features(train_x, get_bow)\n",
    "#     test_vectorizer, test_feature_matrix = prepare_bow_features(test_x, get_bow)\n",
    "    \n",
    "#     train_features = train_vectorizer.fit_transform(train_feature_matrix)   \n",
    "    \n",
    "#     model.fit(train_features, train_y)\n",
    "    \n",
    "#     test_features = train_vectorizer.transform(test_feature_matrix)\n",
    "#     test_predictions = model.predict(test_features)\n",
    "    \n",
    "#     return check_results(test_predictions, test_y, model_name, model)\n",
    "\n",
    "# def optimizer(proper_name, models):\n",
    "#     print \"{0} model hyper parameter run: \".format(proper_name)\n",
    "#     print \"=\" * 100\n",
    "\n",
    "#     results = []\n",
    "\n",
    "#     for model in models:\n",
    "#         result = run_model(proper_name, model, train_x, train_y, dev_x, dev_y)\n",
    "\n",
    "#         result[\"model\"] = model\n",
    "\n",
    "#         results.append(result)\n",
    "\n",
    "#     print \"{0} best models: \".format(proper_name)\n",
    "#     print \"=\" * 100\n",
    "#     print \"Best accuracy: \"\n",
    "#     pp.pprint(sorted(results, reverse=True, key=lambda k: k['accuracy']) )\n",
    "#     print \"Best f score: \"\n",
    "#     pp.pprint(sorted(results, reverse=True, key=lambda k: k['f_score']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1497,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model_c(name, data, cache) :\n",
    "\n",
    "    vec = DATA[name][cache][\"X_vec\"]\n",
    "    X = DATA[name][cache][\"X\"]\n",
    "    Y = DATA[name][cache][\"Y\"]\n",
    "\n",
    "    clf = linear_model.LogisticRegression(C=1e5)\n",
    "#     clf = AdaBoostClassifier(n_estimators=100)\n",
    "#     clf = RandomForestClassifier(n_estimators=10)\n",
    "    #clf = svm.SVC()\n",
    "#     clf = GaussianNB()\n",
    "    \n",
    "    print \"Model: \", clf\n",
    "    \n",
    "    print\n",
    "    print \"Data Slice: \"\n",
    "    print\n",
    "    print \"Shape X/Y: \", X.shape, Y.shape\n",
    "#     print \"Types X: \", vec.get_feature_names() \n",
    "    print \"Example X: \", X[0]\n",
    "    print \"Example Y: \", Y[0]\n",
    "    print\n",
    "    print \"Training model...\"\n",
    "    \n",
    "    clf.fit(X,Y)\n",
    "    \n",
    "    print \"Cross validating...\"\n",
    "\n",
    "#     predictions = cross_validation.cross_val_predict(clf, X, Y, cv=10)\n",
    "    \n",
    "    print\n",
    "    print \"Model results: \"\n",
    "    print\n",
    "\n",
    "#     check_results(predictions, Y)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1498,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def train_model_c(name, data, cache) :\n",
    "\n",
    "#     vec = DATA[name][cache][\"X_vec\"]\n",
    "#     X = DATA[name][cache][\"X\"]\n",
    "#     Y = DATA[name][cache][\"Y\"]\n",
    "    \n",
    "#     # Parameter testing adapted from guide notebook: WSTA_N2_text_classification.ipynb\n",
    "#     penalty_range = [\"l1\", \"l2\"]\n",
    "#     C_range = numpy.linspace(0.1, 10.0, 10)\n",
    "\n",
    "#     logistic_regression_models = [LogisticRegression(penalty=p, C=c) for p in penalty_range for c in C_range ]\n",
    "#     optimizer(\"Logistic Regression\", logistic_regression_models)\n",
    "    \n",
    "#     for model in logistic_regression_models:\n",
    "\n",
    "#         clf = model\n",
    "\n",
    "#         print \"Model: \", clf\n",
    "\n",
    "#         print\n",
    "#         print \"Data Slice: \"\n",
    "#         print\n",
    "#         print \"Shape X/Y: \", X.shape, Y.shape\n",
    "#     #     print \"Types X: \", vec.get_feature_names() \n",
    "#         print \"Example X: \", X[0]\n",
    "#         print \"Example Y: \", Y[0]\n",
    "#         print\n",
    "#         print \"Training model...\"\n",
    "\n",
    "#         clf.fit(X,Y)\n",
    "\n",
    "#         print \"Cross validating...\"\n",
    "\n",
    "#         predictions = cross_validation.cross_val_predict(clf, X, Y, cv=10)\n",
    "\n",
    "#         print\n",
    "#         print \"Model results: \"\n",
    "#         print\n",
    "        \n",
    "#         check_results(predictions, Y, \"Logistic Regression\", clf)\n",
    "    \n",
    "# #     return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1499,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_part_c(name, data, args):\n",
    "    \n",
    "    data[name][\"c_output_answer_set\"] = generate_part_c_output(name, data, args)\n",
    "    \n",
    "    gen_model = args.get(\"gen_model\")    \n",
    "    \n",
    "    if gen_model:\n",
    "        data[name][\"part_c_cache_dict\"][\"model\"] = train_model_c(name, data, \"part_c_cache_dict\")    \n",
    "    \n",
    "    print\n",
    "    print \"Part C Output: \"\n",
    "    pp.pprint(data[name][\"c_output_answer_set\"][:rapid_size])\n",
    "    print    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1500,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For each question, evaluate if the answer is present as an entity\n",
    "\n",
    "def evaluate_rank(name, data, args):\n",
    "    \n",
    "    question_set = data[name][\"question_set\"]\n",
    "    document_set = data[name][\"document_set\"]\n",
    "    \n",
    "    correct = []\n",
    "    wrong = []\n",
    "    \n",
    "#     partial = []\n",
    "    \n",
    "    c_output_answer_set = data[name][\"c_output_answer_set\"]\n",
    "    \n",
    "    for result_c in c_output_answer_set:\n",
    "        \n",
    "        question = question_set[result_c[\"set_index\"]][result_c[\"question_index\"]][\"question\"]\n",
    "        answer =  question_set[result_c[\"set_index\"]][result_c[\"question_index\"]][\"answer\"]\n",
    "        \n",
    "        predicted_answer = result_c[\"predicted_answer\"]\n",
    "        vector_ranked_answers = result_c[\"vector_ranked_answers\"]                \n",
    "\n",
    "        if (predicted_answer == answer):\n",
    "            correct.append(result_c)\n",
    "        else :\n",
    "            wrong.append(result_c)\n",
    "            \n",
    "#             print(answer, predicted_answer)\n",
    "#             print vector_ranked_answers\n",
    "#             break\n",
    "        #print correct\n",
    "    return (correct, wrong)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1501,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_rank(name, data, stats=False, args={}):\n",
    "    print \"Processing rank: \", name\n",
    "    process_part_c(name, data, args)\n",
    "    if stats:\n",
    "        process_generic(name, data, \"rank\", evaluate_rank, args)\n",
    "        \n",
    "        \n",
    "        correct_rank = len(data[name][\"rank_correct\"])\n",
    "        correct_ner = len(data[name][\"ner_correct\"])\n",
    "        \n",
    "        avg = correct_rank * 1.0 / correct_ner\n",
    "        \n",
    "        print \"rank\".capitalize() + \" Correct Average of Previous %: \", avg        \n",
    "        \n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1502,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rank:  rapid\n",
      "Processed: 0\n",
      "Shape X/Y:  (1358, 34448) (1358,)\n",
      "Example X:    (0, 1154)\t1.0\n",
      "  (0, 1358)\t1.0\n",
      "  (0, 4125)\t1.0\n",
      "  (0, 7043)\t1.0\n",
      "  (0, 7406)\t1.0\n",
      "  (0, 12003)\t1.0\n",
      "  (0, 12004)\t1.0\n",
      "  (0, 12005)\t1.0\n",
      "  (0, 12006)\t1.0\n",
      "  (0, 12007)\t1.0\n",
      "  (0, 12008)\t1.0\n",
      "  (0, 12009)\t1.0\n",
      "  (0, 12011)\t1.0\n",
      "  (0, 12012)\t1.0\n",
      "  (0, 12013)\t1.0\n",
      "  (0, 12014)\t1.0\n",
      "  (0, 12015)\t1.0\n",
      "  (0, 12016)\t1.0\n",
      "  (0, 12017)\t1.0\n",
      "  (0, 12018)\t1.0\n",
      "  (0, 12019)\t1.0\n",
      "  (0, 12020)\t1.0\n",
      "  (0, 12021)\t1.0\n",
      "  (0, 12022)\t1.0\n",
      "  (0, 12023)\t1.0\n",
      "  :\t:\n",
      "  (0, 31230)\t1.0\n",
      "  (0, 31236)\t1.0\n",
      "  (0, 31240)\t1.0\n",
      "  (0, 31241)\t1.0\n",
      "  (0, 31244)\t1.0\n",
      "  (0, 31247)\t1.0\n",
      "  (0, 31254)\t1.0\n",
      "  (0, 31255)\t1.0\n",
      "  (0, 31256)\t1.0\n",
      "  (0, 31258)\t1.0\n",
      "  (0, 31261)\t1.0\n",
      "  (0, 31267)\t1.0\n",
      "  (0, 31268)\t1.0\n",
      "  (0, 31269)\t1.0\n",
      "  (0, 31270)\t1.0\n",
      "  (0, 31277)\t1.0\n",
      "  (0, 31280)\t1.0\n",
      "  (0, 31281)\t1.0\n",
      "  (0, 31284)\t1.0\n",
      "  (0, 31292)\t1.0\n",
      "  (0, 34437)\t1.0\n",
      "  (0, 34441)\t2.0\n",
      "  (0, 34442)\t0.319727891156\n",
      "  (0, 34444)\t1.0\n",
      "  (0, 34447)\t2.0\n",
      "Example Y:  0\n",
      "Model:  LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "\n",
      "Data Slice: \n",
      "\n",
      "Shape X/Y:  (1358, 34448) (1358,)\n",
      "Example X:    (0, 1154)\t1.0\n",
      "  (0, 1358)\t1.0\n",
      "  (0, 4125)\t1.0\n",
      "  (0, 7043)\t1.0\n",
      "  (0, 7406)\t1.0\n",
      "  (0, 12003)\t1.0\n",
      "  (0, 12004)\t1.0\n",
      "  (0, 12005)\t1.0\n",
      "  (0, 12006)\t1.0\n",
      "  (0, 12007)\t1.0\n",
      "  (0, 12008)\t1.0\n",
      "  (0, 12009)\t1.0\n",
      "  (0, 12011)\t1.0\n",
      "  (0, 12012)\t1.0\n",
      "  (0, 12013)\t1.0\n",
      "  (0, 12014)\t1.0\n",
      "  (0, 12015)\t1.0\n",
      "  (0, 12016)\t1.0\n",
      "  (0, 12017)\t1.0\n",
      "  (0, 12018)\t1.0\n",
      "  (0, 12019)\t1.0\n",
      "  (0, 12020)\t1.0\n",
      "  (0, 12021)\t1.0\n",
      "  (0, 12022)\t1.0\n",
      "  (0, 12023)\t1.0\n",
      "  :\t:\n",
      "  (0, 31230)\t1.0\n",
      "  (0, 31236)\t1.0\n",
      "  (0, 31240)\t1.0\n",
      "  (0, 31241)\t1.0\n",
      "  (0, 31244)\t1.0\n",
      "  (0, 31247)\t1.0\n",
      "  (0, 31254)\t1.0\n",
      "  (0, 31255)\t1.0\n",
      "  (0, 31256)\t1.0\n",
      "  (0, 31258)\t1.0\n",
      "  (0, 31261)\t1.0\n",
      "  (0, 31267)\t1.0\n",
      "  (0, 31268)\t1.0\n",
      "  (0, 31269)\t1.0\n",
      "  (0, 31270)\t1.0\n",
      "  (0, 31277)\t1.0\n",
      "  (0, 31280)\t1.0\n",
      "  (0, 31281)\t1.0\n",
      "  (0, 31284)\t1.0\n",
      "  (0, 31292)\t1.0\n",
      "  (0, 34437)\t1.0\n",
      "  (0, 34441)\t2.0\n",
      "  (0, 34442)\t0.319727891156\n",
      "  (0, 34444)\t1.0\n",
      "  (0, 34447)\t2.0\n",
      "Example Y:  0\n",
      "\n",
      "Training model...\n",
      "Cross validating...\n",
      "\n",
      "Model results: \n",
      "\n",
      "\n",
      "Part C Output: \n",
      "[   {   'candidates': [   (u'Phonograph records', 'O'),\n",
      "                          (u'are', 'O'),\n",
      "                          (u'generally', 'O'),\n",
      "                          (u'described', 'O'),\n",
      "                          (u'by', 'O'),\n",
      "                          (u'their', 'O'),\n",
      "                          (u'diameter', 'O'),\n",
      "                          (u'in', 'O'),\n",
      "                          (u'inches', 'O'),\n",
      "                          (u'(', 'PUNC'),\n",
      "                          (u'12', 'NUMBER'),\n",
      "                          (u\"'' ,\", 'PUNC'),\n",
      "                          (u'10', 'NUMBER'),\n",
      "                          (u\"'' ,\", 'PUNC'),\n",
      "                          (u'7', 'NUMBER'),\n",
      "                          (u\"'' ) ,\", 'PUNC'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'rotational speed', 'O'),\n",
      "                          (u'in', 'O'),\n",
      "                          (u'rpm', 'O'),\n",
      "                          (u'at', 'O'),\n",
      "                          (u'which', 'O'),\n",
      "                          (u'they', 'O'),\n",
      "                          (u'are', 'O'),\n",
      "                          (u'played', 'O'),\n",
      "                          (u'(', 'PUNC'),\n",
      "                          (u'16 2\\u20443', 'NUMBER'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'33 1\\u20443', 'NUMBER'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'45', 'NUMBER'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'78', 'NUMBER'),\n",
      "                          (u') ,', 'PUNC'),\n",
      "                          (u'and', 'O'),\n",
      "                          (u'their', 'O'),\n",
      "                          (u'time capacity', 'O'),\n",
      "                          (u'resulting', 'O'),\n",
      "                          (u'from', 'O'),\n",
      "                          (u'a', 'O'),\n",
      "                          (u'combination', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'those', 'O'),\n",
      "                          (u'parameters', 'O'),\n",
      "                          (u'(', 'PUNC'),\n",
      "                          (u'LP', 'OTHERCAP'),\n",
      "                          (u'\\u2013', 'O'),\n",
      "                          (u'long', 'O'),\n",
      "                          (u'playing', 'O'),\n",
      "                          (u'33 1\\u20443', 'NUMBER'),\n",
      "                          (u'rpm', 'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'SP', 'OTHERCAP'),\n",
      "                          (u'\\u2013', 'O'),\n",
      "                          (u'78', 'NUMBER'),\n",
      "                          (u'rpm', 'O'),\n",
      "                          (u'single', 'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'EP', 'OTHERCAP'),\n",
      "                          (u'\\u2013', 'O'),\n",
      "                          (u'12-inch', 'NUMBER'),\n",
      "                          (u'single', 'O'),\n",
      "                          (u'or', 'O'),\n",
      "                          (u'extended', 'O'),\n",
      "                          (u'play', 'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'33', 'NUMBER'),\n",
      "                          (u'or', 'O'),\n",
      "                          (u'45', 'NUMBER'),\n",
      "                          (u'rpm', 'O'),\n",
      "                          (u')', 'PUNC'),\n",
      "                          (u';', 'O'),\n",
      "                          (u'their', 'O'),\n",
      "                          (u'reproductive quality', 'O'),\n",
      "                          (u'or', 'O'),\n",
      "                          (u'level', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'fidelity', 'O'),\n",
      "                          (u'(', 'PUNC'),\n",
      "                          (u'high-fidelity', 'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'orthophonic', 'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'full-range', 'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'etc', 'O'),\n",
      "                          (u'. ) ,', 'PUNC'),\n",
      "                          (u'and', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'number', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'audio channels', 'O'),\n",
      "                          (u'provided', 'O'),\n",
      "                          (u'(', 'PUNC'),\n",
      "                          (u'mono', 'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'stereo', 'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'quad', 'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'etc', 'O'),\n",
      "                          (u'. ) .', 'PUNC')],\n",
      "        'predicted_answer': u'78',\n",
      "        'question_index': 0,\n",
      "        'ranked_answers': [   [(u'78', 'NUMBER'), 1.6326530612244898],\n",
      "                              [(u'78', 'NUMBER'), 1.6326530612244898],\n",
      "                              [   (u'33 1\\u20443', 'NUMBER'),\n",
      "                                  1.6145124716553287],\n",
      "                              [   (u'33 1\\u20443', 'NUMBER'),\n",
      "                                  1.6145124716553287],\n",
      "                              [(u'45', 'NUMBER'), 1.605442176870748],\n",
      "                              [(u'45', 'NUMBER'), 1.605442176870748],\n",
      "                              [   (u'16 2\\u20443', 'NUMBER'),\n",
      "                                  1.551020408163265],\n",
      "                              [(u'7', 'NUMBER'), 1.3877551020408165],\n",
      "                              [(u'10', 'NUMBER'), 1.3333333333333333],\n",
      "                              [(u'12', 'NUMBER'), 1.2789115646258504],\n",
      "                              [(u'12-inch', 'NUMBER'), 1.2789115646258504],\n",
      "                              [(u'33', 'NUMBER'), 1.1700680272108843],\n",
      "                              [(u'SP', 'OTHERCAP'), 1.1020408163265307],\n",
      "                              [(u'EP', 'OTHERCAP'), 1.0],\n",
      "                              [(u'LP', 'OTHERCAP'), 0.8163265306122448]],\n",
      "        'sentence_index': 2,\n",
      "        'set_index': 0,\n",
      "        'vector_ranked_answers': [   [   (u'12', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.3197278911564626],\n",
      "                                     [   (u'10', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.3333333333333333],\n",
      "                                     [   (u'7', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.34693877551020413],\n",
      "                                     [   (u'16 2\\u20443', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.38775510204081626],\n",
      "                                     [   (u'33 1\\u20443', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.4036281179138322],\n",
      "                                     [   (u'45', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.401360544217687],\n",
      "                                     [   (u'78', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.40816326530612246],\n",
      "                                     [   (u'33 1\\u20443', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.4036281179138322],\n",
      "                                     [   (u'SP', 'OTHERCAP'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.3673469387755102],\n",
      "                                     [   (u'78', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.40816326530612246],\n",
      "                                     [   (u'EP', 'OTHERCAP'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.3333333333333333],\n",
      "                                     [   (u'12-inch', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.3197278911564626],\n",
      "                                     [   (u'33', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.2925170068027211],\n",
      "                                     [   (u'45', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.401360544217687],\n",
      "                                     [   (u'LP', 'OTHERCAP'),\n",
      "                                         1,\n",
      "                                         1,\n",
      "                                         0.4081632653061224]]}]\n",
      "\n",
      "Rank Correct:  36\n",
      "Rank Wrong:  368\n",
      "Rank Total:  404\n",
      "Rank Overall Average %:  0.0891089108911\n",
      "Rank Correct Average of Previous %:  0.473684210526\n",
      "\n",
      "Processing rank:  rapid\n",
      "Processed: 0\n",
      "\n",
      "Part C Output: \n",
      "[   {   'candidates': [   (u'Phonograph records', 'O'),\n",
      "                          (u'are', 'O'),\n",
      "                          (u'generally', 'O'),\n",
      "                          (u'described', 'O'),\n",
      "                          (u'by', 'O'),\n",
      "                          (u'their', 'O'),\n",
      "                          (u'diameter', 'O'),\n",
      "                          (u'in', 'O'),\n",
      "                          (u'inches', 'O'),\n",
      "                          (u'(', 'PUNC'),\n",
      "                          (u'12', 'NUMBER'),\n",
      "                          (u\"'' ,\", 'PUNC'),\n",
      "                          (u'10', 'NUMBER'),\n",
      "                          (u\"'' ,\", 'PUNC'),\n",
      "                          (u'7', 'NUMBER'),\n",
      "                          (u\"'' ) ,\", 'PUNC'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'rotational speed', 'O'),\n",
      "                          (u'in', 'O'),\n",
      "                          (u'rpm', 'O'),\n",
      "                          (u'at', 'O'),\n",
      "                          (u'which', 'O'),\n",
      "                          (u'they', 'O'),\n",
      "                          (u'are', 'O'),\n",
      "                          (u'played', 'O'),\n",
      "                          (u'(', 'PUNC'),\n",
      "                          (u'16 2\\u20443', 'NUMBER'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'33 1\\u20443', 'NUMBER'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'45', 'NUMBER'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'78', 'NUMBER'),\n",
      "                          (u') ,', 'PUNC'),\n",
      "                          (u'and', 'O'),\n",
      "                          (u'their', 'O'),\n",
      "                          (u'time capacity', 'O'),\n",
      "                          (u'resulting', 'O'),\n",
      "                          (u'from', 'O'),\n",
      "                          (u'a', 'O'),\n",
      "                          (u'combination', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'those', 'O'),\n",
      "                          (u'parameters', 'O'),\n",
      "                          (u'(', 'PUNC'),\n",
      "                          (u'LP', 'OTHERCAP'),\n",
      "                          (u'\\u2013', 'O'),\n",
      "                          (u'long', 'O'),\n",
      "                          (u'playing', 'O'),\n",
      "                          (u'33 1\\u20443', 'NUMBER'),\n",
      "                          (u'rpm', 'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'SP', 'OTHERCAP'),\n",
      "                          (u'\\u2013', 'O'),\n",
      "                          (u'78', 'NUMBER'),\n",
      "                          (u'rpm', 'O'),\n",
      "                          (u'single', 'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'EP', 'OTHERCAP'),\n",
      "                          (u'\\u2013', 'O'),\n",
      "                          (u'12-inch', 'NUMBER'),\n",
      "                          (u'single', 'O'),\n",
      "                          (u'or', 'O'),\n",
      "                          (u'extended', 'O'),\n",
      "                          (u'play', 'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'33', 'NUMBER'),\n",
      "                          (u'or', 'O'),\n",
      "                          (u'45', 'NUMBER'),\n",
      "                          (u'rpm', 'O'),\n",
      "                          (u')', 'PUNC'),\n",
      "                          (u';', 'O'),\n",
      "                          (u'their', 'O'),\n",
      "                          (u'reproductive quality', 'O'),\n",
      "                          (u'or', 'O'),\n",
      "                          (u'level', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'fidelity', 'O'),\n",
      "                          (u'(', 'PUNC'),\n",
      "                          (u'high-fidelity', 'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'orthophonic', 'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'full-range', 'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'etc', 'O'),\n",
      "                          (u'. ) ,', 'PUNC'),\n",
      "                          (u'and', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'number', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'audio channels', 'O'),\n",
      "                          (u'provided', 'O'),\n",
      "                          (u'(', 'PUNC'),\n",
      "                          (u'mono', 'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'stereo', 'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'quad', 'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'etc', 'O'),\n",
      "                          (u'. ) .', 'PUNC')],\n",
      "        'predicted_answer': u'16 2\\u20443',\n",
      "        'question_index': 0,\n",
      "        'ranked_answers': [   [(u'78', 'NUMBER'), 1.6326530612244898],\n",
      "                              [(u'78', 'NUMBER'), 1.6326530612244898],\n",
      "                              [   (u'33 1\\u20443', 'NUMBER'),\n",
      "                                  1.6145124716553287],\n",
      "                              [   (u'33 1\\u20443', 'NUMBER'),\n",
      "                                  1.6145124716553287],\n",
      "                              [(u'45', 'NUMBER'), 1.605442176870748],\n",
      "                              [(u'45', 'NUMBER'), 1.605442176870748],\n",
      "                              [   (u'16 2\\u20443', 'NUMBER'),\n",
      "                                  1.551020408163265],\n",
      "                              [(u'7', 'NUMBER'), 1.3877551020408165],\n",
      "                              [(u'10', 'NUMBER'), 1.3333333333333333],\n",
      "                              [(u'12', 'NUMBER'), 1.2789115646258504],\n",
      "                              [(u'12-inch', 'NUMBER'), 1.2789115646258504],\n",
      "                              [(u'33', 'NUMBER'), 1.1700680272108843],\n",
      "                              [(u'SP', 'OTHERCAP'), 1.1020408163265307],\n",
      "                              [(u'EP', 'OTHERCAP'), 1.0],\n",
      "                              [(u'LP', 'OTHERCAP'), 0.8163265306122448]],\n",
      "        'sentence_index': 2,\n",
      "        'set_index': 0,\n",
      "        'vector_ranked_answers': [   [   (u'12', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.3197278911564626],\n",
      "                                     [   (u'10', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.3333333333333333],\n",
      "                                     [   (u'7', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.34693877551020413],\n",
      "                                     [   (u'16 2\\u20443', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.38775510204081626],\n",
      "                                     [   (u'33 1\\u20443', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.4036281179138322],\n",
      "                                     [   (u'45', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.401360544217687],\n",
      "                                     [   (u'78', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.40816326530612246],\n",
      "                                     [   (u'33 1\\u20443', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.4036281179138322],\n",
      "                                     [   (u'SP', 'OTHERCAP'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.3673469387755102],\n",
      "                                     [   (u'78', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.40816326530612246],\n",
      "                                     [   (u'EP', 'OTHERCAP'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.3333333333333333],\n",
      "                                     [   (u'12-inch', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.3197278911564626],\n",
      "                                     [   (u'33', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.2925170068027211],\n",
      "                                     [   (u'45', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.401360544217687],\n",
      "                                     [   (u'LP', 'OTHERCAP'),\n",
      "                                         1,\n",
      "                                         1,\n",
      "                                         0.4081632653061224]]}]\n",
      "\n",
      "Rank Correct:  58\n",
      "Rank Wrong:  346\n",
      "Rank Total:  404\n",
      "Rank Overall Average %:  0.143564356436\n",
      "Rank Correct Average of Previous %:  0.763157894737\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_rank(\"rapid\", DATA, True, {\"cached\" : False,\n",
    "                                    \"train_enhancement\": True,\n",
    "                                    \"gen_model\": True,\n",
    "                                    \"use_enhancement\": False,\n",
    "                                    \"enhancement_dataset\": \"rapid\"})\n",
    "\n",
    "process_rank(\"rapid\", DATA, True, {\"cached\" : True,\n",
    "                                    \"train_enhancement\": False,\n",
    "                                    \"gen_model\": False,\n",
    "                                    \"use_enhancement\": True,\n",
    "                                    \"enhancement_dataset\": \"rapid\"})\n",
    "\n",
    "# process_rank(\"rapid\", DATA, True, {\"cached\" : True,\n",
    "#                                     \"train_enhancement\": False,\n",
    "#                                     \"gen_model\": False,\n",
    "#                                     \"use_enhancement\": True,\n",
    "#                                     \"enhancement_dataset\": \"dev\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1503,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len(DATA[\"train\"][\"c_output_answer_set\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1504,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rank:  dev\n",
      "Processed: 0\n",
      "Processed: 1000\n",
      "Processed: 2000\n",
      "Processed: 3000\n",
      "Processed: 4000\n",
      "Processed: 5000\n",
      "Processed: 6000\n",
      "Processed: 7000\n",
      "Processed: 8000\n",
      "Shape X/Y:  (35450, 681487) (35450,)\n",
      "Example X:    (0, 50736)\t1.0\n",
      "  (0, 50769)\t1.0\n",
      "  (0, 50805)\t1.0\n",
      "  (0, 116047)\t1.0\n",
      "  (0, 116055)\t1.0\n",
      "  (0, 116068)\t1.0\n",
      "  (0, 168619)\t1.0\n",
      "  (0, 168643)\t1.0\n",
      "  (0, 168666)\t1.0\n",
      "  (0, 180415)\t1.0\n",
      "  (0, 180794)\t1.0\n",
      "  (0, 181142)\t1.0\n",
      "  (0, 182915)\t1.0\n",
      "  (0, 182926)\t1.0\n",
      "  (0, 182933)\t1.0\n",
      "  (0, 320561)\t1.0\n",
      "  (0, 320564)\t1.0\n",
      "  (0, 320570)\t1.0\n",
      "  (0, 320617)\t1.0\n",
      "  (0, 320661)\t1.0\n",
      "  (0, 320668)\t1.0\n",
      "  (0, 320700)\t1.0\n",
      "  (0, 320704)\t1.0\n",
      "  (0, 320705)\t1.0\n",
      "  (0, 320718)\t1.0\n",
      "  :\t:\n",
      "  (0, 652383)\t1.0\n",
      "  (0, 652428)\t1.0\n",
      "  (0, 652782)\t1.0\n",
      "  (0, 652832)\t1.0\n",
      "  (0, 652833)\t1.0\n",
      "  (0, 652933)\t1.0\n",
      "  (0, 653642)\t1.0\n",
      "  (0, 653731)\t1.0\n",
      "  (0, 658688)\t1.0\n",
      "  (0, 658689)\t1.0\n",
      "  (0, 658692)\t1.0\n",
      "  (0, 658700)\t1.0\n",
      "  (0, 658711)\t1.0\n",
      "  (0, 658712)\t1.0\n",
      "  (0, 658722)\t1.0\n",
      "  (0, 658726)\t1.0\n",
      "  (0, 658727)\t1.0\n",
      "  (0, 658729)\t1.0\n",
      "  (0, 658749)\t1.0\n",
      "  (0, 658753)\t1.0\n",
      "  (0, 680953)\t1.0\n",
      "  (0, 681477)\t1.0\n",
      "  (0, 681481)\t0.151515151515\n",
      "  (0, 681484)\t1.0\n",
      "  (0, 681486)\t2.0\n",
      "Example Y:  0\n",
      "Model:  LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "\n",
      "Data Slice: \n",
      "\n",
      "Shape X/Y:  (35450, 681487) (35450,)\n",
      "Example X:    (0, 50736)\t1.0\n",
      "  (0, 50769)\t1.0\n",
      "  (0, 50805)\t1.0\n",
      "  (0, 116047)\t1.0\n",
      "  (0, 116055)\t1.0\n",
      "  (0, 116068)\t1.0\n",
      "  (0, 168619)\t1.0\n",
      "  (0, 168643)\t1.0\n",
      "  (0, 168666)\t1.0\n",
      "  (0, 180415)\t1.0\n",
      "  (0, 180794)\t1.0\n",
      "  (0, 181142)\t1.0\n",
      "  (0, 182915)\t1.0\n",
      "  (0, 182926)\t1.0\n",
      "  (0, 182933)\t1.0\n",
      "  (0, 320561)\t1.0\n",
      "  (0, 320564)\t1.0\n",
      "  (0, 320570)\t1.0\n",
      "  (0, 320617)\t1.0\n",
      "  (0, 320661)\t1.0\n",
      "  (0, 320668)\t1.0\n",
      "  (0, 320700)\t1.0\n",
      "  (0, 320704)\t1.0\n",
      "  (0, 320705)\t1.0\n",
      "  (0, 320718)\t1.0\n",
      "  :\t:\n",
      "  (0, 652383)\t1.0\n",
      "  (0, 652428)\t1.0\n",
      "  (0, 652782)\t1.0\n",
      "  (0, 652832)\t1.0\n",
      "  (0, 652833)\t1.0\n",
      "  (0, 652933)\t1.0\n",
      "  (0, 653642)\t1.0\n",
      "  (0, 653731)\t1.0\n",
      "  (0, 658688)\t1.0\n",
      "  (0, 658689)\t1.0\n",
      "  (0, 658692)\t1.0\n",
      "  (0, 658700)\t1.0\n",
      "  (0, 658711)\t1.0\n",
      "  (0, 658712)\t1.0\n",
      "  (0, 658722)\t1.0\n",
      "  (0, 658726)\t1.0\n",
      "  (0, 658727)\t1.0\n",
      "  (0, 658729)\t1.0\n",
      "  (0, 658749)\t1.0\n",
      "  (0, 658753)\t1.0\n",
      "  (0, 680953)\t1.0\n",
      "  (0, 681477)\t1.0\n",
      "  (0, 681481)\t0.151515151515\n",
      "  (0, 681484)\t1.0\n",
      "  (0, 681486)\t2.0\n",
      "Example Y:  0\n",
      "\n",
      "Training model...\n",
      "Cross validating...\n",
      "\n",
      "Model results: \n",
      "\n",
      "\n",
      "Part C Output: \n",
      "[   {   'candidates': [   (u'Night-vision devices', 'O'),\n",
      "                          (u'using', 'O'),\n",
      "                          (u'active', 'O'),\n",
      "                          (u'near-infrared illumination', 'O'),\n",
      "                          (u'allow', 'O'),\n",
      "                          (u'people', 'O'),\n",
      "                          (u'or', 'O'),\n",
      "                          (u'animals', 'O'),\n",
      "                          (u'to', 'O'),\n",
      "                          (u'be', 'O'),\n",
      "                          (u'observed', 'O'),\n",
      "                          (u'without', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'observer', 'O'),\n",
      "                          (u'being', 'O'),\n",
      "                          (u'detected', 'O'),\n",
      "                          (u'.', 'PUNC')],\n",
      "        'predicted_answer': u'Night-vision devices',\n",
      "        'question_index': 0,\n",
      "        'ranked_answers': [   [   (u'Night-vision devices', 'O'),\n",
      "                                  0.30303030303030304],\n",
      "                              [   (u'near-infrared illumination', 'O'),\n",
      "                                  0.27272727272727276]],\n",
      "        'sentence_index': 1,\n",
      "        'set_index': 0,\n",
      "        'vector_ranked_answers': [   [   (u'Night-vision devices', 'O'),\n",
      "                                         0,\n",
      "                                         2,\n",
      "                                         0.15151515151515152],\n",
      "                                     [   (   u'near-infrared illumination',\n",
      "                                             'O'),\n",
      "                                         0,\n",
      "                                         2,\n",
      "                                         0.13636363636363638]]}]\n",
      "\n",
      "Rank Correct:  1268\n",
      "Rank Wrong:  7195\n",
      "Rank Total:  8463\n",
      "Rank Overall Average %:  0.149828665958\n",
      "Rank Correct Average of Previous %:  0.475084301236\n",
      "\n",
      "Processing rank:  dev\n",
      "Processed: 0\n",
      "Processed: 1000\n",
      "Processed: 2000\n",
      "Processed: 3000\n",
      "Processed: 4000\n",
      "Processed: 5000\n",
      "Processed: 6000\n",
      "Processed: 7000\n",
      "Processed: 8000\n",
      "\n",
      "Part C Output: \n",
      "[   {   'candidates': [   (u'Night-vision devices', 'O'),\n",
      "                          (u'using', 'O'),\n",
      "                          (u'active', 'O'),\n",
      "                          (u'near-infrared illumination', 'O'),\n",
      "                          (u'allow', 'O'),\n",
      "                          (u'people', 'O'),\n",
      "                          (u'or', 'O'),\n",
      "                          (u'animals', 'O'),\n",
      "                          (u'to', 'O'),\n",
      "                          (u'be', 'O'),\n",
      "                          (u'observed', 'O'),\n",
      "                          (u'without', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'observer', 'O'),\n",
      "                          (u'being', 'O'),\n",
      "                          (u'detected', 'O'),\n",
      "                          (u'.', 'PUNC')],\n",
      "        'predicted_answer': u'Night-vision devices',\n",
      "        'question_index': 0,\n",
      "        'ranked_answers': [   [   (u'Night-vision devices', 'O'),\n",
      "                                  0.30303030303030304],\n",
      "                              [   (u'near-infrared illumination', 'O'),\n",
      "                                  0.27272727272727276]],\n",
      "        'sentence_index': 1,\n",
      "        'set_index': 0,\n",
      "        'vector_ranked_answers': [   [   (u'Night-vision devices', 'O'),\n",
      "                                         0,\n",
      "                                         2,\n",
      "                                         0.15151515151515152],\n",
      "                                     [   (   u'near-infrared illumination',\n",
      "                                             'O'),\n",
      "                                         0,\n",
      "                                         2,\n",
      "                                         0.13636363636363638]]}]\n",
      "\n",
      "Rank Correct:  2104\n",
      "Rank Wrong:  6359\n",
      "Rank Total:  8463\n",
      "Rank Overall Average %:  0.24861160345\n",
      "Rank Correct Average of Previous %:  0.78831022855\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_rank(\"dev\", DATA, True, {\"cached\" : False,\n",
    "                                    \"train_enhancement\": True,\n",
    "                                    \"gen_model\": True,\n",
    "                                    \"use_enhancement\": False,\n",
    "                                    \"enhancement_dataset\": \"dev\"})\n",
    "\n",
    "process_rank(\"dev\", DATA, True, {   \"cached\" : True,\n",
    "                                    \"train_enhancement\": False,\n",
    "                                    \"gen_model\": False,\n",
    "                                    \"use_enhancement\": True,\n",
    "                                    \"enhancement_dataset\": \"dev\"})        \n",
    "\n",
    "# process_rank(\"dev\", DATA, True, {   \"cached\" : True,\n",
    "#                                     \"train_enhancement\": False,\n",
    "#                                     \"gen_model\": False,\n",
    "#                                     \"use_enhancement\": True,\n",
    "#                                     \"enhancement_dataset\": \"train\"})                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1505,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rank:  train\n",
      "Processed: 0\n",
      "Processed: 1000\n",
      "Processed: 2000\n",
      "Processed: 3000\n",
      "Processed: 4000\n",
      "Processed: 5000\n",
      "Processed: 6000\n",
      "Processed: 7000\n",
      "Processed: 8000\n",
      "Processed: 9000\n",
      "Processed: 10000\n",
      "Processed: 11000\n",
      "Processed: 12000\n",
      "Processed: 13000\n",
      "Processed: 14000\n",
      "Processed: 15000\n",
      "Processed: 16000\n",
      "Processed: 17000\n",
      "Processed: 18000\n",
      "Processed: 19000\n",
      "Processed: 20000\n",
      "Processed: 21000\n",
      "Processed: 22000\n",
      "Processed: 23000\n",
      "Processed: 24000\n",
      "Processed: 25000\n",
      "Processed: 26000\n",
      "Processed: 27000\n",
      "Processed: 28000\n",
      "Processed: 29000\n",
      "Processed: 30000\n",
      "Processed: 31000\n",
      "Processed: 32000\n",
      "Processed: 33000\n",
      "Processed: 34000\n",
      "Processed: 35000\n",
      "Processed: 36000\n",
      "Processed: 37000\n",
      "Processed: 38000\n",
      "Processed: 39000\n",
      "Processed: 40000\n",
      "Processed: 41000\n",
      "Processed: 42000\n",
      "Processed: 43000\n",
      "Processed: 44000\n",
      "Processed: 45000\n",
      "Processed: 46000\n",
      "Processed: 47000\n",
      "Processed: 48000\n",
      "Processed: 49000\n",
      "Processed: 50000\n",
      "Processed: 51000\n",
      "Processed: 52000\n",
      "Processed: 53000\n",
      "Processed: 54000\n",
      "Processed: 55000\n",
      "Processed: 56000\n",
      "Processed: 57000\n",
      "Processed: 58000\n",
      "Processed: 59000\n",
      "Processed: 60000\n",
      "Processed: 61000\n",
      "Processed: 62000\n",
      "Processed: 63000\n",
      "Processed: 64000\n",
      "Processed: 65000\n",
      "Processed: 66000\n",
      "Processed: 67000\n",
      "Processed: 68000\n",
      "Processed: 69000\n",
      "Processed: 70000\n",
      "Shape X/Y:  (302727, 4816122) (302727,)\n",
      "Example X:    (0, 233851)\t1.0\n",
      "  (0, 295256)\t1.0\n",
      "  (0, 799301)\t1.0\n",
      "  (0, 1257687)\t1.0\n",
      "  (0, 1336303)\t1.0\n",
      "  (0, 2006268)\t1.0\n",
      "  (0, 2006269)\t1.0\n",
      "  (0, 2006272)\t1.0\n",
      "  (0, 2006274)\t1.0\n",
      "  (0, 2006275)\t1.0\n",
      "  (0, 2006276)\t1.0\n",
      "  (0, 2006281)\t1.0\n",
      "  (0, 2006286)\t1.0\n",
      "  (0, 2006289)\t1.0\n",
      "  (0, 2006311)\t1.0\n",
      "  (0, 2006315)\t1.0\n",
      "  (0, 2006320)\t1.0\n",
      "  (0, 2006325)\t1.0\n",
      "  (0, 2006330)\t1.0\n",
      "  (0, 2006373)\t1.0\n",
      "  (0, 2006400)\t1.0\n",
      "  (0, 2006413)\t1.0\n",
      "  (0, 2006423)\t1.0\n",
      "  (0, 2006462)\t1.0\n",
      "  (0, 2006468)\t1.0\n",
      "  :\t:\n",
      "  (0, 4506926)\t1.0\n",
      "  (0, 4507133)\t1.0\n",
      "  (0, 4507227)\t1.0\n",
      "  (0, 4507290)\t1.0\n",
      "  (0, 4507401)\t1.0\n",
      "  (0, 4507444)\t1.0\n",
      "  (0, 4507637)\t1.0\n",
      "  (0, 4507685)\t1.0\n",
      "  (0, 4507688)\t1.0\n",
      "  (0, 4507723)\t1.0\n",
      "  (0, 4507772)\t1.0\n",
      "  (0, 4507861)\t1.0\n",
      "  (0, 4507901)\t1.0\n",
      "  (0, 4507978)\t1.0\n",
      "  (0, 4507986)\t1.0\n",
      "  (0, 4508199)\t1.0\n",
      "  (0, 4508281)\t1.0\n",
      "  (0, 4508303)\t1.0\n",
      "  (0, 4508351)\t1.0\n",
      "  (0, 4508624)\t1.0\n",
      "  (0, 4816110)\t1.0\n",
      "  (0, 4816115)\t2.0\n",
      "  (0, 4816116)\t0.319727891156\n",
      "  (0, 4816118)\t1.0\n",
      "  (0, 4816121)\t2.0\n",
      "Example Y:  0\n",
      "Model:  LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "\n",
      "Data Slice: \n",
      "\n",
      "Shape X/Y:  (302727, 4816122) (302727,)\n",
      "Example X:    (0, 233851)\t1.0\n",
      "  (0, 295256)\t1.0\n",
      "  (0, 799301)\t1.0\n",
      "  (0, 1257687)\t1.0\n",
      "  (0, 1336303)\t1.0\n",
      "  (0, 2006268)\t1.0\n",
      "  (0, 2006269)\t1.0\n",
      "  (0, 2006272)\t1.0\n",
      "  (0, 2006274)\t1.0\n",
      "  (0, 2006275)\t1.0\n",
      "  (0, 2006276)\t1.0\n",
      "  (0, 2006281)\t1.0\n",
      "  (0, 2006286)\t1.0\n",
      "  (0, 2006289)\t1.0\n",
      "  (0, 2006311)\t1.0\n",
      "  (0, 2006315)\t1.0\n",
      "  (0, 2006320)\t1.0\n",
      "  (0, 2006325)\t1.0\n",
      "  (0, 2006330)\t1.0\n",
      "  (0, 2006373)\t1.0\n",
      "  (0, 2006400)\t1.0\n",
      "  (0, 2006413)\t1.0\n",
      "  (0, 2006423)\t1.0\n",
      "  (0, 2006462)\t1.0\n",
      "  (0, 2006468)\t1.0\n",
      "  :\t:\n",
      "  (0, 4506926)\t1.0\n",
      "  (0, 4507133)\t1.0\n",
      "  (0, 4507227)\t1.0\n",
      "  (0, 4507290)\t1.0\n",
      "  (0, 4507401)\t1.0\n",
      "  (0, 4507444)\t1.0\n",
      "  (0, 4507637)\t1.0\n",
      "  (0, 4507685)\t1.0\n",
      "  (0, 4507688)\t1.0\n",
      "  (0, 4507723)\t1.0\n",
      "  (0, 4507772)\t1.0\n",
      "  (0, 4507861)\t1.0\n",
      "  (0, 4507901)\t1.0\n",
      "  (0, 4507978)\t1.0\n",
      "  (0, 4507986)\t1.0\n",
      "  (0, 4508199)\t1.0\n",
      "  (0, 4508281)\t1.0\n",
      "  (0, 4508303)\t1.0\n",
      "  (0, 4508351)\t1.0\n",
      "  (0, 4508624)\t1.0\n",
      "  (0, 4816110)\t1.0\n",
      "  (0, 4816115)\t2.0\n",
      "  (0, 4816116)\t0.319727891156\n",
      "  (0, 4816118)\t1.0\n",
      "  (0, 4816121)\t2.0\n",
      "Example Y:  0\n",
      "\n",
      "Training model...\n",
      "Cross validating...\n",
      "\n",
      "Model results: \n",
      "\n",
      "\n",
      "Part C Output: \n",
      "[   {   'candidates': [   (u'Phonograph records', 'O'),\n",
      "                          (u'are', 'STOPWORD'),\n",
      "                          (u'generally described', u'O'),\n",
      "                          (u'by their', 'STOPWORD'),\n",
      "                          (u'diameter', u'O'),\n",
      "                          (u'in', 'STOPWORD'),\n",
      "                          (u'inches', 'O'),\n",
      "                          (u'(', 'PUNC'),\n",
      "                          (u'12', 'NUMBER'),\n",
      "                          (u\"'' ,\", 'PUNC'),\n",
      "                          (u'10', 'NUMBER'),\n",
      "                          (u\"'' ,\", 'PUNC'),\n",
      "                          (u'7', 'NUMBER'),\n",
      "                          (u\"'' ) ,\", 'PUNC'),\n",
      "                          (u'the', 'STOPWORD'),\n",
      "                          (u'rotational speed', u'O'),\n",
      "                          (u'in', 'STOPWORD'),\n",
      "                          (u'rpm', u'O'),\n",
      "                          (u'at which they are', 'STOPWORD'),\n",
      "                          (u'played', u'O'),\n",
      "                          (u'(', 'PUNC'),\n",
      "                          (u'16 2\\u20443', 'NUMBER'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'33 1\\u20443', 'NUMBER'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'45', 'NUMBER'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'78', 'NUMBER'),\n",
      "                          (u') ,', 'PUNC'),\n",
      "                          (u'and their', 'STOPWORD'),\n",
      "                          (u'time capacity resulting', u'O'),\n",
      "                          (u'from a', 'STOPWORD'),\n",
      "                          (u'combination', u'O'),\n",
      "                          (u'of those', 'STOPWORD'),\n",
      "                          (u'parameters', u'O'),\n",
      "                          (u'(', 'PUNC'),\n",
      "                          (u'LP', 'OTHERCAP'),\n",
      "                          (u'\\u2013 long playing', u'O'),\n",
      "                          (u'33 1\\u20443', 'NUMBER'),\n",
      "                          (u'rpm', u'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'SP', 'OTHERCAP'),\n",
      "                          (u'\\u2013', u'O'),\n",
      "                          (u'78', 'NUMBER'),\n",
      "                          (u'rpm single', u'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'EP', 'OTHERCAP'),\n",
      "                          (u'\\u2013', u'O'),\n",
      "                          (u'12-inch', 'NUMBER'),\n",
      "                          (u'single', u'O'),\n",
      "                          (u'or', 'STOPWORD'),\n",
      "                          (u'extended play', u'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'33', 'NUMBER'),\n",
      "                          (u'or', 'STOPWORD'),\n",
      "                          (u'45', 'NUMBER'),\n",
      "                          (u'rpm', u'O'),\n",
      "                          (u')', 'PUNC'),\n",
      "                          (u';', u'O'),\n",
      "                          (u'their', 'STOPWORD'),\n",
      "                          (u'reproductive quality', u'O'),\n",
      "                          (u'or', 'STOPWORD'),\n",
      "                          (u'level', u'O'),\n",
      "                          (u'of', 'STOPWORD'),\n",
      "                          (u'fidelity', u'O'),\n",
      "                          (u'(', 'PUNC'),\n",
      "                          (u'high-fidelity', u'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'orthophonic', u'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'full-range', u'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'etc', u'O'),\n",
      "                          (u'. ) ,', 'PUNC'),\n",
      "                          (u'and the', 'STOPWORD'),\n",
      "                          (u'number', 'O'),\n",
      "                          (u'of', 'STOPWORD'),\n",
      "                          (u'audio channels provided', u'O'),\n",
      "                          (u'(', 'PUNC'),\n",
      "                          (u'mono', u'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'stereo', u'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'quad', u'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'etc', u'O'),\n",
      "                          (u'. ) .', 'PUNC')],\n",
      "        'predicted_answer': u'78',\n",
      "        'question_index': 0,\n",
      "        'ranked_answers': [   [(u'78', 'NUMBER'), 1.6326530612244898],\n",
      "                              [(u'78', 'NUMBER'), 1.6326530612244898],\n",
      "                              [   (u'33 1\\u20443', 'NUMBER'),\n",
      "                                  1.6145124716553287],\n",
      "                              [   (u'33 1\\u20443', 'NUMBER'),\n",
      "                                  1.6145124716553287],\n",
      "                              [(u'45', 'NUMBER'), 1.605442176870748],\n",
      "                              [(u'45', 'NUMBER'), 1.605442176870748],\n",
      "                              [   (u'16 2\\u20443', 'NUMBER'),\n",
      "                                  1.551020408163265],\n",
      "                              [(u'7', 'NUMBER'), 1.3877551020408165],\n",
      "                              [(u'10', 'NUMBER'), 1.3333333333333333],\n",
      "                              [(u'12', 'NUMBER'), 1.2789115646258504],\n",
      "                              [(u'12-inch', 'NUMBER'), 1.2789115646258504],\n",
      "                              [(u'33', 'NUMBER'), 1.1700680272108843],\n",
      "                              [(u'SP', 'OTHERCAP'), 1.1020408163265307],\n",
      "                              [(u'EP', 'OTHERCAP'), 1.0],\n",
      "                              [(u'LP', 'OTHERCAP'), 0.8163265306122448]],\n",
      "        'sentence_index': 2,\n",
      "        'set_index': 0,\n",
      "        'vector_ranked_answers': [   [   (u'12', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.3197278911564626],\n",
      "                                     [   (u'10', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.3333333333333333],\n",
      "                                     [   (u'7', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.34693877551020413],\n",
      "                                     [   (u'16 2\\u20443', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.38775510204081626],\n",
      "                                     [   (u'33 1\\u20443', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.4036281179138322],\n",
      "                                     [   (u'45', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.401360544217687],\n",
      "                                     [   (u'78', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.40816326530612246],\n",
      "                                     [   (u'33 1\\u20443', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.4036281179138322],\n",
      "                                     [   (u'SP', 'OTHERCAP'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.3673469387755102],\n",
      "                                     [   (u'78', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.40816326530612246],\n",
      "                                     [   (u'EP', 'OTHERCAP'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.3333333333333333],\n",
      "                                     [   (u'12-inch', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.3197278911564626],\n",
      "                                     [   (u'33', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.2925170068027211],\n",
      "                                     [   (u'45', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.401360544217687],\n",
      "                                     [   (u'LP', 'OTHERCAP'),\n",
      "                                         1,\n",
      "                                         1,\n",
      "                                         0.4081632653061224]]}]\n",
      "\n",
      "Rank Correct:  11080\n",
      "Rank Wrong:  59079\n",
      "Rank Total:  70159\n",
      "Rank Overall Average %:  0.157926994398\n",
      "Rank Correct Average of Previous %:  0.519968088601\n",
      "\n",
      "Processing rank:  train\n",
      "Processed: 0\n",
      "Processed: 1000\n",
      "Processed: 2000\n",
      "Processed: 3000\n",
      "Processed: 4000\n",
      "Processed: 5000\n",
      "Processed: 6000\n",
      "Processed: 7000\n",
      "Processed: 8000\n",
      "Processed: 9000\n",
      "Processed: 10000\n",
      "Processed: 11000\n",
      "Processed: 12000\n",
      "Processed: 13000\n",
      "Processed: 14000\n",
      "Processed: 15000\n",
      "Processed: 16000\n",
      "Processed: 17000\n",
      "Processed: 18000\n",
      "Processed: 19000\n",
      "Processed: 20000\n",
      "Processed: 21000\n",
      "Processed: 22000\n",
      "Processed: 23000\n",
      "Processed: 24000\n",
      "Processed: 25000\n",
      "Processed: 26000\n",
      "Processed: 27000\n",
      "Processed: 28000\n",
      "Processed: 29000\n",
      "Processed: 30000\n",
      "Processed: 31000\n",
      "Processed: 32000\n",
      "Processed: 33000\n",
      "Processed: 34000\n",
      "Processed: 35000\n",
      "Processed: 36000\n",
      "Processed: 37000\n",
      "Processed: 38000\n",
      "Processed: 39000\n",
      "Processed: 40000\n",
      "Processed: 41000\n",
      "Processed: 42000\n",
      "Processed: 43000\n",
      "Processed: 44000\n",
      "Processed: 45000\n",
      "Processed: 46000\n",
      "Processed: 47000\n",
      "Processed: 48000\n",
      "Processed: 49000\n",
      "Processed: 50000\n",
      "Processed: 51000\n",
      "Processed: 52000\n",
      "Processed: 53000\n",
      "Processed: 54000\n",
      "Processed: 55000\n",
      "Processed: 56000\n",
      "Processed: 57000\n",
      "Processed: 58000\n",
      "Processed: 59000\n",
      "Processed: 60000\n",
      "Processed: 61000\n",
      "Processed: 62000\n",
      "Processed: 63000\n",
      "Processed: 64000\n",
      "Processed: 65000\n",
      "Processed: 66000\n",
      "Processed: 67000\n",
      "Processed: 68000\n",
      "Processed: 69000\n",
      "Processed: 70000\n",
      "\n",
      "Part C Output: \n",
      "[   {   'candidates': [   (u'Phonograph records', 'O'),\n",
      "                          (u'are', 'STOPWORD'),\n",
      "                          (u'generally described', u'O'),\n",
      "                          (u'by their', 'STOPWORD'),\n",
      "                          (u'diameter', u'O'),\n",
      "                          (u'in', 'STOPWORD'),\n",
      "                          (u'inches', 'O'),\n",
      "                          (u'(', 'PUNC'),\n",
      "                          (u'12', 'NUMBER'),\n",
      "                          (u\"'' ,\", 'PUNC'),\n",
      "                          (u'10', 'NUMBER'),\n",
      "                          (u\"'' ,\", 'PUNC'),\n",
      "                          (u'7', 'NUMBER'),\n",
      "                          (u\"'' ) ,\", 'PUNC'),\n",
      "                          (u'the', 'STOPWORD'),\n",
      "                          (u'rotational speed', u'O'),\n",
      "                          (u'in', 'STOPWORD'),\n",
      "                          (u'rpm', u'O'),\n",
      "                          (u'at which they are', 'STOPWORD'),\n",
      "                          (u'played', u'O'),\n",
      "                          (u'(', 'PUNC'),\n",
      "                          (u'16 2\\u20443', 'NUMBER'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'33 1\\u20443', 'NUMBER'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'45', 'NUMBER'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'78', 'NUMBER'),\n",
      "                          (u') ,', 'PUNC'),\n",
      "                          (u'and their', 'STOPWORD'),\n",
      "                          (u'time capacity resulting', u'O'),\n",
      "                          (u'from a', 'STOPWORD'),\n",
      "                          (u'combination', u'O'),\n",
      "                          (u'of those', 'STOPWORD'),\n",
      "                          (u'parameters', u'O'),\n",
      "                          (u'(', 'PUNC'),\n",
      "                          (u'LP', 'OTHERCAP'),\n",
      "                          (u'\\u2013 long playing', u'O'),\n",
      "                          (u'33 1\\u20443', 'NUMBER'),\n",
      "                          (u'rpm', u'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'SP', 'OTHERCAP'),\n",
      "                          (u'\\u2013', u'O'),\n",
      "                          (u'78', 'NUMBER'),\n",
      "                          (u'rpm single', u'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'EP', 'OTHERCAP'),\n",
      "                          (u'\\u2013', u'O'),\n",
      "                          (u'12-inch', 'NUMBER'),\n",
      "                          (u'single', u'O'),\n",
      "                          (u'or', 'STOPWORD'),\n",
      "                          (u'extended play', u'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'33', 'NUMBER'),\n",
      "                          (u'or', 'STOPWORD'),\n",
      "                          (u'45', 'NUMBER'),\n",
      "                          (u'rpm', u'O'),\n",
      "                          (u')', 'PUNC'),\n",
      "                          (u';', u'O'),\n",
      "                          (u'their', 'STOPWORD'),\n",
      "                          (u'reproductive quality', u'O'),\n",
      "                          (u'or', 'STOPWORD'),\n",
      "                          (u'level', u'O'),\n",
      "                          (u'of', 'STOPWORD'),\n",
      "                          (u'fidelity', u'O'),\n",
      "                          (u'(', 'PUNC'),\n",
      "                          (u'high-fidelity', u'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'orthophonic', u'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'full-range', u'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'etc', u'O'),\n",
      "                          (u'. ) ,', 'PUNC'),\n",
      "                          (u'and the', 'STOPWORD'),\n",
      "                          (u'number', 'O'),\n",
      "                          (u'of', 'STOPWORD'),\n",
      "                          (u'audio channels provided', u'O'),\n",
      "                          (u'(', 'PUNC'),\n",
      "                          (u'mono', u'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'stereo', u'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'quad', u'O'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'etc', u'O'),\n",
      "                          (u'. ) .', 'PUNC')],\n",
      "        'predicted_answer': u'78',\n",
      "        'question_index': 0,\n",
      "        'ranked_answers': [   [(u'78', 'NUMBER'), 1.6326530612244898],\n",
      "                              [(u'78', 'NUMBER'), 1.6326530612244898],\n",
      "                              [   (u'33 1\\u20443', 'NUMBER'),\n",
      "                                  1.6145124716553287],\n",
      "                              [   (u'33 1\\u20443', 'NUMBER'),\n",
      "                                  1.6145124716553287],\n",
      "                              [(u'45', 'NUMBER'), 1.605442176870748],\n",
      "                              [(u'45', 'NUMBER'), 1.605442176870748],\n",
      "                              [   (u'16 2\\u20443', 'NUMBER'),\n",
      "                                  1.551020408163265],\n",
      "                              [(u'7', 'NUMBER'), 1.3877551020408165],\n",
      "                              [(u'10', 'NUMBER'), 1.3333333333333333],\n",
      "                              [(u'12', 'NUMBER'), 1.2789115646258504],\n",
      "                              [(u'12-inch', 'NUMBER'), 1.2789115646258504],\n",
      "                              [(u'33', 'NUMBER'), 1.1700680272108843],\n",
      "                              [(u'SP', 'OTHERCAP'), 1.1020408163265307],\n",
      "                              [(u'EP', 'OTHERCAP'), 1.0],\n",
      "                              [(u'LP', 'OTHERCAP'), 0.8163265306122448]],\n",
      "        'sentence_index': 2,\n",
      "        'set_index': 0,\n",
      "        'vector_ranked_answers': [   [   (u'12', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.3197278911564626],\n",
      "                                     [   (u'10', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.3333333333333333],\n",
      "                                     [   (u'7', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.34693877551020413],\n",
      "                                     [   (u'16 2\\u20443', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.38775510204081626],\n",
      "                                     [   (u'33 1\\u20443', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.4036281179138322],\n",
      "                                     [   (u'45', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.401360544217687],\n",
      "                                     [   (u'78', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.40816326530612246],\n",
      "                                     [   (u'33 1\\u20443', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.4036281179138322],\n",
      "                                     [   (u'SP', 'OTHERCAP'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.3673469387755102],\n",
      "                                     [   (u'78', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.40816326530612246],\n",
      "                                     [   (u'EP', 'OTHERCAP'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.3333333333333333],\n",
      "                                     [   (u'12-inch', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.3197278911564626],\n",
      "                                     [   (u'33', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.2925170068027211],\n",
      "                                     [   (u'45', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.401360544217687],\n",
      "                                     [   (u'LP', 'OTHERCAP'),\n",
      "                                         1,\n",
      "                                         1,\n",
      "                                         0.4081632653061224]]}]\n",
      "\n",
      "Rank Correct:  17462\n",
      "Rank Wrong:  52697\n",
      "Rank Total:  70159\n",
      "Rank Overall Average %:  0.248891802905\n",
      "Rank Correct Average of Previous %:  0.819465953353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_rank(\"train\", DATA, True, {\"cached\" : False,\n",
    "                                    \"train_enhancement\": True,\n",
    "                                    \"gen_model\": True,\n",
    "                                    \"use_enhancement\": False,\n",
    "                                    \"enhancement_dataset\": \"train\"})\n",
    "\n",
    "process_rank(\"train\", DATA, True, {   \"cached\" : True,\n",
    "                                    \"train_enhancement\": False,\n",
    "                                    \"gen_model\": False,\n",
    "                                    \"use_enhancement\": True,\n",
    "                                    \"enhancement_dataset\": \"train\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1506,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rank:  dev\n",
      "Processed: 0\n",
      "Processed: 1000\n",
      "Processed: 2000\n",
      "Processed: 3000\n",
      "Processed: 4000\n",
      "Processed: 5000\n",
      "Processed: 6000\n",
      "Processed: 7000\n",
      "Processed: 8000\n",
      "\n",
      "Part C Output: \n",
      "[   {   'candidates': [   (u'Night-vision devices', 'O'),\n",
      "                          (u'using', 'O'),\n",
      "                          (u'active', 'O'),\n",
      "                          (u'near-infrared illumination', 'O'),\n",
      "                          (u'allow', 'O'),\n",
      "                          (u'people', 'O'),\n",
      "                          (u'or', 'O'),\n",
      "                          (u'animals', 'O'),\n",
      "                          (u'to', 'O'),\n",
      "                          (u'be', 'O'),\n",
      "                          (u'observed', 'O'),\n",
      "                          (u'without', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'observer', 'O'),\n",
      "                          (u'being', 'O'),\n",
      "                          (u'detected', 'O'),\n",
      "                          (u'.', 'PUNC')],\n",
      "        'predicted_answer': u'Night-vision devices',\n",
      "        'question_index': 0,\n",
      "        'ranked_answers': [   [   (u'Night-vision devices', 'O'),\n",
      "                                  0.30303030303030304],\n",
      "                              [   (u'near-infrared illumination', 'O'),\n",
      "                                  0.27272727272727276]],\n",
      "        'sentence_index': 1,\n",
      "        'set_index': 0,\n",
      "        'vector_ranked_answers': [   [   (u'Night-vision devices', 'O'),\n",
      "                                         0,\n",
      "                                         2,\n",
      "                                         0.15151515151515152],\n",
      "                                     [   (   u'near-infrared illumination',\n",
      "                                             'O'),\n",
      "                                         0,\n",
      "                                         2,\n",
      "                                         0.13636363636363638]]}]\n",
      "\n",
      "Rank Correct:  1485\n",
      "Rank Wrong:  6978\n",
      "Rank Total:  8463\n",
      "Rank Overall Average %:  0.175469691599\n",
      "Rank Correct Average of Previous %:  0.55638816036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_rank(\"dev\", DATA, True, {   \"cached\" : True,\n",
    "                                    \"train_enhancement\": False,\n",
    "                                    \"gen_model\": False,\n",
    "                                    \"use_enhancement\": True,\n",
    "                                    \"enhancement_dataset\": \"train\"})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rank:  test\n",
      "\n",
      "Part C Output: \n",
      "[   {   'candidates': [   (u'The', 'O'),\n",
      "                          (u'Crimean War', 'OTHERCAP'),\n",
      "                          (u'marked', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'ascendancy', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'France', u'LOCATION'),\n",
      "                          (u'to', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'position', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'pre-eminent power', 'O'),\n",
      "                          (u'on', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'Continent', 'OTHERCAP'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u':411', 'NUMBER'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'continued decline', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'Ottoman Empire', 'OTHERCAP'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'and', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'beginning', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'a', 'O'),\n",
      "                          (u'decline', 'O'),\n",
      "                          (u'for', 'O'),\n",
      "                          (u'Tsarist', 'OTHERCAP'),\n",
      "                          (u'Russia', u'LOCATION'),\n",
      "                          (u'.', 'PUNC')],\n",
      "        'predicted_answer': u':411',\n",
      "        'question_index': 0,\n",
      "        'ranked_answers': [   [(u':411', 'NUMBER'), 0.6117647058823529],\n",
      "                              [   (u'Ottoman Empire', 'OTHERCAP'),\n",
      "                                  0.5647058823529412],\n",
      "                              [(u'Tsarist', 'OTHERCAP'), 0.5294117647058822],\n",
      "                              [   (u'Russia', u'LOCATION'),\n",
      "                                  0.49411764705882355],\n",
      "                              [   (u'Continent', 'OTHERCAP'),\n",
      "                                  0.4235294117647059],\n",
      "                              [   (u'France', u'LOCATION'),\n",
      "                                  0.24705882352941178],\n",
      "                              [   (u'Crimean War', 'OTHERCAP'),\n",
      "                                  0.09411764705882353]],\n",
      "        'sentence_index': 353,\n",
      "        'set_index': 0,\n",
      "        'vector_ranked_answers': [   [   (u'France', u'LOCATION'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.08235294117647059],\n",
      "                                     [   (u'Continent', 'OTHERCAP'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.1411764705882353],\n",
      "                                     [   (u':411', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.15294117647058822],\n",
      "                                     [   (u'Ottoman Empire', 'OTHERCAP'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.18823529411764706],\n",
      "                                     [   (u'Tsarist', 'OTHERCAP'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.1764705882352941],\n",
      "                                     [   (u'Russia', u'LOCATION'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.16470588235294117],\n",
      "                                     [   (u'Crimean War', 'OTHERCAP'),\n",
      "                                         1,\n",
      "                                         1,\n",
      "                                         0.047058823529411764]]}]\n",
      "\n",
      "\n",
      "Processing rank:  test\n",
      "\n",
      "Part C Output: \n",
      "[   {   'candidates': [   (u'The', 'O'),\n",
      "                          (u'Crimean War', 'OTHERCAP'),\n",
      "                          (u'marked', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'ascendancy', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'France', u'LOCATION'),\n",
      "                          (u'to', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'position', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'pre-eminent power', 'O'),\n",
      "                          (u'on', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'Continent', 'OTHERCAP'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u':411', 'NUMBER'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'continued decline', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'Ottoman Empire', 'OTHERCAP'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'and', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'beginning', 'O'),\n",
      "                          (u'of', 'O'),\n",
      "                          (u'a', 'O'),\n",
      "                          (u'decline', 'O'),\n",
      "                          (u'for', 'O'),\n",
      "                          (u'Tsarist', 'OTHERCAP'),\n",
      "                          (u'Russia', u'LOCATION'),\n",
      "                          (u'.', 'PUNC')],\n",
      "        'predicted_answer': u':411',\n",
      "        'question_index': 0,\n",
      "        'ranked_answers': [   [(u':411', 'NUMBER'), 0.6117647058823529],\n",
      "                              [   (u'Ottoman Empire', 'OTHERCAP'),\n",
      "                                  0.5647058823529412],\n",
      "                              [(u'Tsarist', 'OTHERCAP'), 0.5294117647058822],\n",
      "                              [   (u'Russia', u'LOCATION'),\n",
      "                                  0.49411764705882355],\n",
      "                              [   (u'Continent', 'OTHERCAP'),\n",
      "                                  0.4235294117647059],\n",
      "                              [   (u'France', u'LOCATION'),\n",
      "                                  0.24705882352941178],\n",
      "                              [   (u'Crimean War', 'OTHERCAP'),\n",
      "                                  0.09411764705882353]],\n",
      "        'sentence_index': 353,\n",
      "        'set_index': 0,\n",
      "        'vector_ranked_answers': [   [   (u'France', u'LOCATION'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.08235294117647059],\n",
      "                                     [   (u'Continent', 'OTHERCAP'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.1411764705882353],\n",
      "                                     [   (u':411', 'NUMBER'),\n",
      "                                         2,\n",
      "                                         2,\n",
      "                                         0.15294117647058822],\n",
      "                                     [   (u'Ottoman Empire', 'OTHERCAP'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.18823529411764706],\n",
      "                                     [   (u'Tsarist', 'OTHERCAP'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.1764705882352941],\n",
      "                                     [   (u'Russia', u'LOCATION'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.16470588235294117],\n",
      "                                     [   (u'Crimean War', 'OTHERCAP'),\n",
      "                                         1,\n",
      "                                         1,\n",
      "                                         0.047058823529411764]]}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_rank(\"test\", DATA, False, {\"cached\" : False,\n",
    "                                    \"train_enhancement\": False,\n",
    "                                    \"gen_model\": False,\n",
    "                                    \"use_enhancement\": False,\n",
    "                                    \"enhancement_dataset\": \"dev\"})\n",
    "\n",
    "process_rank(\"test\", DATA, False, {   \"cached\" : True,\n",
    "                                    \"train_enhancement\": False,\n",
    "                                    \"gen_model\": False,\n",
    "                                    \"use_enhancement\": True,\n",
    "                                    \"enhancement_dataset\": \"dev\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1507,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rank:  test\n",
      "Processed: 0\n",
      "Processed: 1000\n",
      "Processed: 2000\n",
      "Processed: 3000\n",
      "Processed: 4000\n",
      "Processed: 5000\n",
      "Processed: 6000\n",
      "Processed: 7000\n",
      "Processed: 8000\n",
      "\n",
      "Part C Output: \n",
      "[   {   'candidates': [   (u'This', 'O'),\n",
      "                          (u'was', 'O'),\n",
      "                          (u'welcomed', 'O'),\n",
      "                          (u'by', 'O'),\n",
      "                          (u'France', u'LOCATION'),\n",
      "                          (u'and', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'UK', u'LOCATION'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'where', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'citizens', 'O'),\n",
      "                          (u'began', 'O'),\n",
      "                          (u'to', 'O'),\n",
      "                          (u'turn', 'O'),\n",
      "                          (u'against', 'O'),\n",
      "                          (u'their', 'O'),\n",
      "                          (u'governments', 'O'),\n",
      "                          (u'as', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'war', 'O'),\n",
      "                          (u'dragged', 'O'),\n",
      "                          (u'on', 'O'),\n",
      "                          (u'.', 'PUNC')],\n",
      "        'predicted_answer': u'UK',\n",
      "        'question_index': 0,\n",
      "        'ranked_answers': [   [(u'UK', u'LOCATION'), 0.7333333333333334],\n",
      "                              [(u'France', u'LOCATION'), 0.6000000000000001]],\n",
      "        'sentence_index': 25,\n",
      "        'set_index': 0,\n",
      "        'vector_ranked_answers': [   [(u'France', u'LOCATION'), 2, 1, 0.2],\n",
      "                                     [   (u'UK', u'LOCATION'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.24444444444444446]]}]\n",
      "\n",
      "\n",
      "Processing rank:  test\n",
      "Processed: 0\n",
      "Processed: 1000\n",
      "Processed: 2000\n",
      "Processed: 3000\n",
      "Processed: 4000\n",
      "Processed: 5000\n",
      "Processed: 6000\n",
      "Processed: 7000\n",
      "Processed: 8000\n",
      "\n",
      "Part C Output: \n",
      "[   {   'candidates': [   (u'This', 'O'),\n",
      "                          (u'was', 'O'),\n",
      "                          (u'welcomed', 'O'),\n",
      "                          (u'by', 'O'),\n",
      "                          (u'France', u'LOCATION'),\n",
      "                          (u'and', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'UK', u'LOCATION'),\n",
      "                          (u',', 'PUNC'),\n",
      "                          (u'where', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'citizens', 'O'),\n",
      "                          (u'began', 'O'),\n",
      "                          (u'to', 'O'),\n",
      "                          (u'turn', 'O'),\n",
      "                          (u'against', 'O'),\n",
      "                          (u'their', 'O'),\n",
      "                          (u'governments', 'O'),\n",
      "                          (u'as', 'O'),\n",
      "                          (u'the', 'O'),\n",
      "                          (u'war', 'O'),\n",
      "                          (u'dragged', 'O'),\n",
      "                          (u'on', 'O'),\n",
      "                          (u'.', 'PUNC')],\n",
      "        'predicted_answer': u'UK',\n",
      "        'question_index': 0,\n",
      "        'ranked_answers': [   [(u'UK', u'LOCATION'), 0.7333333333333334],\n",
      "                              [(u'France', u'LOCATION'), 0.6000000000000001]],\n",
      "        'sentence_index': 25,\n",
      "        'set_index': 0,\n",
      "        'vector_ranked_answers': [   [(u'France', u'LOCATION'), 2, 1, 0.2],\n",
      "                                     [   (u'UK', u'LOCATION'),\n",
      "                                         2,\n",
      "                                         1,\n",
      "                                         0.24444444444444446]]}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_rank(\"test\", DATA, False, {\"cached\" : False,\n",
    "                                    \"train_enhancement\": False,\n",
    "                                    \"gen_model\": False,\n",
    "                                    \"use_enhancement\": False,\n",
    "                                    \"enhancement_dataset\": \"train\"})\n",
    "\n",
    "process_rank(\"test\", DATA, False, {   \"cached\" : True,\n",
    "                                    \"train_enhancement\": False,\n",
    "                                    \"gen_model\": False,\n",
    "                                    \"use_enhancement\": True,\n",
    "                                    \"enhancement_dataset\": \"train\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1508,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_submit(name, data):\n",
    "    \n",
    "    headers = ['id', 'answer']\n",
    "    \n",
    "    c_output_answer_set = data[name][\"c_output_answer_set\"]       \n",
    "\n",
    "    with open(name + '.submit.csv', 'w') as f:\n",
    "\n",
    "        f_csv = csv.DictWriter(f, headers)\n",
    "        f_csv.writeheader()\n",
    "\n",
    "        for index, result_c in enumerate(c_output_answer_set):\n",
    "            \n",
    "            predicted_answer = result_c[\"predicted_answer\"]\n",
    "            \n",
    "            if predicted_answer is not None:\n",
    "                f_csv.writerows([{'id':index+1,'answer':predicted_answer.encode(\"utf-8\")}])\n",
    "            else:\n",
    "                f_csv.writerows([{'id':index+1,'answer':\"NONE\"}])\n",
    "            \n",
    "#             if isinstance( answer_list[index]['answer'], int):\n",
    "                \n",
    "#                 f_csv.writerows([{'id':index+1,'answer':answer_list[index]['answer'][0][0]}])\n",
    "                \n",
    "#             else:\n",
    "                \n",
    "#                 f_csv.writerows([{'id':index+1,'answer':answer_list[index]['answer'][0][0].encode(\"utf-8\")}])        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1509,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "process_submit(\"rapid\", DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1510,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_submit(\"test\", DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_wrong_debug(name, data):\n",
    "    \n",
    "    question_set = data[name][\"question_set\"]\n",
    "    document_set = data[name][\"document_set\"]\n",
    "    rank_wrong = data[name][\"rank_wrong\"]\n",
    "    rank_correct = data[name][\"rank_correct\"]\n",
    "    \n",
    "    for i, result_wrong in enumerate(rank_correct):\n",
    "        \n",
    "        question = question_set[result_wrong[\"set_index\"]][result_wrong[\"question_index\"]]\n",
    "        candidate_sentence = document_set[result_wrong[\"set_index\"]][result_wrong[\"sentence_index\"]]\n",
    "        correct_sentence = document_set[result_wrong[\"set_index\"]][question[\"answer_sentence\"]]\n",
    "        \n",
    "        candidates = result_wrong[\"candidates\"]\n",
    "        ranked_answers = result_wrong[\"ranked_answers\"]\n",
    "        vector_ranked_answers = result_wrong[\"vector_ranked_answers\"]\n",
    "        predicted_answer = result_wrong[\"predicted_answer\"]\n",
    "        \n",
    "#         if i == 299:\n",
    "#         if question[\"answer_sentence\"] == result_wrong[\"sentence_index\"] and i % 100 == 0:\n",
    "        if question[\"answer\"].replace(\" \", \"\") in predicted_answer.replace(\" \", \"\"): # and i % 10 == 0:\n",
    "#             if len(set(question[\"answer\"].replace(\" \", \"\")).intersection(punct_tokens)) > 0:\n",
    "\n",
    "                print \"=\" * 20\n",
    "                print \"=\" * 20\n",
    "\n",
    "                print \"Question: \"\n",
    "                print\n",
    "                pp.pprint(question[\"question\"])\n",
    "\n",
    "                print\n",
    "                print \"Correct Sentence: (Part A)\"\n",
    "                print\n",
    "                pp.pprint(correct_sentence)\n",
    "                print\n",
    "                print \"Chosen Sentence: (Part A)\"\n",
    "                print\n",
    "                pp.pprint(candidate_sentence)\n",
    "                print\n",
    "\n",
    "                print \"Candidate Answers: (Part B)\"\n",
    "                print\n",
    "                pp.pprint(candidates)\n",
    "                print\n",
    "                print \"Ranked Answers: (Part C)\"\n",
    "                print\n",
    "                pp.pprint(ranked_answers)\n",
    "                print\n",
    "                print\n",
    "                print \"Vector Ranked Answers: (Part C)\"\n",
    "                print\n",
    "                pp.pprint(vector_ranked_answers)\n",
    "                print            \n",
    "                print \"Predicted Answer: (Part C)\"\n",
    "                print\n",
    "                pp.pprint(predicted_answer)\n",
    "                print\n",
    "                print \"Correct Answer: (Part C)\"\n",
    "                print\n",
    "                pp.pprint(question[\"answer\"])     \n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# log_wrong_debug(\"rapid\", DATA)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
