{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in the python script containing the same code as the load the data notebook\n",
    "%run loadData.py\n",
    "# now we can access train, dev, and test\n",
    "# along with trainSents, devSents testSents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Phonograph records are generally described by their diameter in inches (12\", 10\", 7\"), the rotational speed in rpm at which they are played (16 2\\u20443, 33 1\\u20443, 45, 78), and their time capacity resulting from a combination of those parameters (LP \\u2013 long playing 33 1\\u20443 rpm, SP \\u2013 78 rpm single, EP \\u2013 12-inch single or extended play, 33 or 45 rpm); their reproductive quality or level of fidelity (high-fidelity, orthophonic, full-range, etc.), and the number of audio channels provided (mono, stereo, quad, etc.).'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSents[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'answer': u'long playing',\n",
       " u'answer_sentence': 2,\n",
       " u'question': u'What does LP stand for when it comes to time capacity?'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = trainSents[0]\n",
    "questions = train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Retrieval Pool Boosting\n",
    "\n",
    "## Issue\n",
    "\n",
    "- Candidate sentence not appearing in sentence retrieval pool\n",
    "\n",
    "## Goal\n",
    "\n",
    "- Increase the chance that answer appears in retrieval selection pool (either single sentence or vector of sentences).\n",
    "\n",
    "## Possible Strategies\n",
    "\n",
    "- Increase Size of Pool\n",
    "- Rank Sentences in retrieved Pool\n",
    "- Increase Size of Trained Models (nltk.corpus)\n",
    "- Use in combination with Trained Semantic Models (pretrained word2vec/doc2vec)\n",
    "- Tune preprocessing and hyperparameters to increase pool quality\n",
    "- Determine quality effects of models on a per corpus, multi-corpus or per doc basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tuning functions\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Follow lemmatize function from guide notebook: WSTA_N1B_preprocessing.ipynb\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(word):\n",
    "    lemma = lemmatizer.lemmatize(word,'v')\n",
    "    if lemma == word:\n",
    "        lemma = lemmatizer.lemmatize(word,'n')\n",
    "    return lemma\n",
    "\n",
    "word_tokenizer = nltk.tokenize.WordPunctTokenizer() #word_tokenize #tokenize.regexp.WordPunctTokenizer()\n",
    "\n",
    "def pre_process(line):\n",
    "    tokenized_sentence = word_tokenizer.tokenize(line.lower())\n",
    "    lemmatized_sentence = [lemmatize(token) for token in tokenized_sentence]\n",
    "    return lemmatized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Core functions\n",
    "\n",
    "def vectorize_documents(text_documents):\n",
    "\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', tokenizer=pre_process)\n",
    "    vector_documents = vectorizer.fit_transform(text_documents)\n",
    "    \n",
    "    return [vector_documents, vectorizer]\n",
    "\n",
    "def vectorize_query(vectorizer, text_query):\n",
    "    return vectorizer.transform([text_query])\n",
    "\n",
    "def process_neighbours(vector_documents):\n",
    "    \n",
    "    neighbours = NearestNeighbors(1, algorithm=\"brute\", metric=\"cosine\")\n",
    "    neighbours.fit(vector_documents)\n",
    "    \n",
    "    return neighbours\n",
    "\n",
    "def closest_documents(neighbours, vector_query, n):\n",
    "\n",
    "    result = neighbours.kneighbors(vector_query, n, return_distance=True)\n",
    "\n",
    "    result_indices = result[1][0]\n",
    "    result_distances = result[0][0]\n",
    "    \n",
    "    return sorted(zip(result_indices, result_distances), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def raw_text_to_sentences(raw_text, tokenizer):\n",
    "    return tokenizer.tokenize(raw_text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processed_sentence(sentence):\n",
    "    words = sentence.split()\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increase Size of Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_sent_corpus = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "punkt_tokenizer = nltk.data.load(\"tokenizers/punkt/english.pickle\")\n",
    "corpora = [nltk.corpus.reuters]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for corpus in corpora:\n",
    "    \n",
    "    for i, fileid in enumerate(corpus.fileids()):\n",
    "        \n",
    "        doc = nltk.corpus.reuters.raw(fileid)\n",
    "        sentences = raw_text_to_sentences(doc, punkt_tokenizer)\n",
    "        \n",
    "        for j, sentence in enumerate(sentences):\n",
    "            \n",
    "            proc_sent = processed_sentence(sentences[0])\n",
    "            \n",
    "            if i == 0 and j == 0:\n",
    "                \n",
    "                print \"Raw:\\n\"\n",
    "                print repr(sentence), \"\\n\"\n",
    "                print \"Processed:\\n\"\n",
    "                print repr(proc_sent)\n",
    "                \n",
    "            full_sent_corpus.append(proc_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A gramophone record (phonograph record in American English) or vinyl record, commonly known as a \"record\", is an analogue sound storage medium in the form of a flat polyvinyl chloride (previously shellac) disc with an inscribed, modulated spiral groove.\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(trainSents):\n",
    "    for j, raw_sent in enumerate(doc):\n",
    "        \n",
    "        if i == 0 and j == 0:\n",
    "            print raw_sent\n",
    "            \n",
    "        full_sent_corpus.append(raw_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_vector_documents, full_vectorizer = vectorize_documents(full_sent_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increase Size of Pool, vectorize candidate sentence retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Demonstration function\n",
    "def demo_process_set_vector(questions, documents):\n",
    "    \n",
    "#     vector_documents = full_vectorizer.transform(documents)\n",
    "    vector_documents, vectorizer = vectorize_documents(documents)\n",
    "    \n",
    "#     analyze = full_vectorizer.build_analyzer()\n",
    "    analyze = vectorizer.build_analyzer()\n",
    "    \n",
    "    neighbours = process_neighbours(vector_documents)\n",
    "\n",
    "    print \"=\" * 20\n",
    "    print \"Vector documents shape: {0}\".format(vector_documents.shape)\n",
    "    print \"Actual documents length: {0}\".format(len(documents))\n",
    "    print \"=\" * 20, \"\\n\"\n",
    "    \n",
    "    for question in questions[10:10+3]:\n",
    "        \n",
    "        text_query = question[\"question\"]\n",
    "\n",
    "        print \"Text query:\\n\\n\\t{0}\\n\".format(text_query)\n",
    "\n",
    "#         vector_query = vectorize_query(full_vectorizer, text_query)\n",
    "        vector_query = vectorize_query(vectorizer, text_query)\n",
    "\n",
    "        print \"Vector query shape:\\n\\n\\t{0}\".format(vector_query.shape)\n",
    "      \n",
    "        results = closest_documents(neighbours, vector_query, 1)\n",
    "        \n",
    "        print \"Query (text):\\n\\n\\t{0}\\n\".format(text_query)            \n",
    "        print \"Query (vector text):\\n\"\n",
    "        pp.pprint(analyze(text_query))       \n",
    "        \n",
    "        print \"Answer Sentence (text):\\n\\n\\t{0}\\n\".format(text_query)            \n",
    "        print \"Answer Sentence (vector text):\\n\"\n",
    "        pp.pprint(analyze(text_query))               \n",
    "        \n",
    "        \n",
    "        for result_index, result_distance in results:\n",
    "        \n",
    "            print\n",
    "            print \"Result:\\n\\n\\tDistance ({0}), Index ({1})\\n\".format(result_distance, result_index)\n",
    "            print\n",
    "            print \"Document (text):\\n\\n\\t{0}\".format(documents[result_index].encode(\"utf-8\"))\n",
    "            print\n",
    "            print \"Document (vector text): \\n\\n\"\n",
    "            pp.pprint(analyze(documents[result_index]))\n",
    "\n",
    "            print \"\\n\", \"=\" * 20, \"\\n\"\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Vector documents shape: (463, 2047)\n",
      "Actual documents length: 463\n",
      "==================== \n",
      "\n",
      "Text query:\n",
      "\n",
      "\tWhat was the original intent of the phonautograph?\n",
      "\n",
      "Vector query shape:\n",
      "\n",
      "\t(1, 2047)\n",
      "Query (text):\n",
      "\n",
      "\tWhat was the original intent of the phonautograph?\n",
      "\n",
      "Query (vector text):\n",
      "\n",
      "[u'original', u'intent', u'phonautograph', u'?']\n",
      "Answer Sentence (text):\n",
      "\n",
      "\tWhat was the original intent of the phonautograph?\n",
      "\n",
      "Answer Sentence (vector text):\n",
      "\n",
      "[u'original', u'intent', u'phonautograph', u'?']\n",
      "\n",
      "Result:\n",
      "\n",
      "\tDistance (0.71736934448), Index (9)\n",
      "\n",
      "\n",
      "Document (text):\n",
      "\n",
      "\tThe phonautograph, patented by Léon Scott in 1857, used a vibrating diaphragm and stylus to graphically record sound waves as tracings on sheets of paper, purely for visual analysis and without any intent of playing them back.\n",
      "\n",
      "Document (vector text): \n",
      "\n",
      "\n",
      "[   u'phonautograph',\n",
      "    u',',\n",
      "    u'patent',\n",
      "    u'l\\xe9on',\n",
      "    u'scott',\n",
      "    u'1857',\n",
      "    u',',\n",
      "    u'use',\n",
      "    u'vibrate',\n",
      "    u'diaphragm',\n",
      "    u'stylus',\n",
      "    u'graphically',\n",
      "    u'record',\n",
      "    u'sound',\n",
      "    u'wave',\n",
      "    u'trace',\n",
      "    u'sheet',\n",
      "    u'paper',\n",
      "    u',',\n",
      "    u'purely',\n",
      "    u'visual',\n",
      "    u'analysis',\n",
      "    u'intent',\n",
      "    u'play',\n",
      "    u'.']\n",
      "\n",
      "==================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "demo_process_set_vector(questions, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluateSentenceRetrivalVector(questionsList, documentsList, numToEval, sentenceVectorSize):\n",
    "    \n",
    "    numCorrect = 0\n",
    "    numWrong = 0\n",
    "    \n",
    "    for i in range (0, numToEval):\n",
    "        \n",
    "        documents = documentsList[i]\n",
    "        questions = questionsList[i]\n",
    "        \n",
    "#         vector_documents = full_vectorizer.transform(documents)\n",
    "        vector_documents, vectorizer = vectorize_documents(documents)\n",
    "\n",
    "#         analyze = full_vectorizer.build_analyzer()\n",
    "        analyze = vectorizer.build_analyzer()\n",
    "        \n",
    "        neighbours = process_neighbours(vector_documents)        \n",
    "        \n",
    "        for j in range (0, len(questions)):\n",
    "            \n",
    "            text_query = questions[j][\"question\"]\n",
    "            \n",
    "#             vector_query = vectorize_query(full_vectorizer, text_query)\n",
    "            vector_query = vectorize_query(vectorizer, text_query)\n",
    "            \n",
    "            results  = closest_documents(neighbours, vector_query, sentenceVectorSize)\n",
    "            \n",
    "            hit = False\n",
    "            \n",
    "            for result_index, result_distance in results:\n",
    "                if result_index == int(questions[j][\"answer_sentence\"]):\n",
    "                    numCorrect += 1\n",
    "                    hit = True\n",
    "                    break\n",
    "            \n",
    "            if not hit:\n",
    "                numWrong += 1\n",
    "                \n",
    "    return (numCorrect, numWrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence Vector Size : 1\n",
      "\tNumber Correct : 928\n",
      "\tNumber incorrect: 733\n",
      "\tTotal : 1661\n",
      "\tAverage correct : 0.558699578567\n",
      "\n",
      "Sentence Vector Size : 2\n",
      "\tNumber Correct : 1129\n",
      "\tNumber incorrect: 532\n",
      "\tTotal : 1661\n",
      "\tAverage correct : 0.679711017459\n",
      "\n",
      "Sentence Vector Size : 3\n",
      "\tNumber Correct : 1216\n",
      "\tNumber incorrect: 445\n",
      "\tTotal : 1661\n",
      "\tAverage correct : 0.73208910295\n",
      "\n",
      "Sentence Vector Size : 4\n",
      "\tNumber Correct : 1264\n",
      "\tNumber incorrect: 397\n",
      "\tTotal : 1661\n",
      "\tAverage correct : 0.760987357014\n",
      "\n",
      "Sentence Vector Size : 5\n",
      "\tNumber Correct : 1318\n",
      "\tNumber incorrect: 343\n",
      "\tTotal : 1661\n",
      "\tAverage correct : 0.793497892836\n",
      "\n",
      "Sentence Vector Size : 10\n",
      "\tNumber Correct : 1428\n",
      "\tNumber incorrect: 233\n",
      "\tTotal : 1661\n",
      "\tAverage correct : 0.859723058399\n",
      "\n",
      "Sentence Vector Size : 20\n",
      "\tNumber Correct : 1501\n",
      "\tNumber incorrect: 160\n",
      "\tTotal : 1661\n",
      "\tAverage correct : 0.903672486454\n",
      "\n",
      "Sentence Vector Size : 30\n",
      "\tNumber Correct : 1531\n",
      "\tNumber incorrect: 130\n",
      "\tTotal : 1661\n",
      "\tAverage correct : 0.921733895244\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for x in [1,2,3,4,5,10,20,30]:\n",
    "    \n",
    "    (correct, wrong) = evaluateSentenceRetrivalVector(train, trainSents, 10, x)\n",
    "    \n",
    "    print\n",
    "    print(\"Sentence Vector Size : \" + str(x))\n",
    "    print(\"\\tNumber Correct : \" + str(correct))\n",
    "    print(\"\\tNumber incorrect: \" + str(wrong))\n",
    "    print(\"\\tTotal : \" + str(correct + wrong))\n",
    "    print (\"\\tAverage correct : \" + str((correct + 0.0) / (correct + wrong)))\n",
    "    \n",
    "    results.append((x, (correct + 0.0) / (correct + wrong)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Vector Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fad5a9d7a90>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEcCAYAAADgJkIVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fad9c676a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = pd.DataFrame(results).plot.bar(x=0, y=1, title=\"Sentence Pool Size vs. Proportion of Answer Sentences in Pool\", legend=False)\n",
    "\n",
    "ax.set_xlabel(\"Sentence Pool Size\")\n",
    "ax.set_ylabel(\"Proportion of Answer Sentences in Pool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of sentences per document: 208.819444444\n"
     ]
    }
   ],
   "source": [
    "print \"Average number of sentences per document:\", sum(map(len, trainSents)) * 1.0 / len(trainSents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Models\n",
    "\n",
    "## Pretrained word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# From: WSTA_N10_word_vectors\n",
    "\n",
    "import gensim\n",
    "from nltk.data import find\n",
    "\n",
    "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))\n",
    "word2vec_model = gensim.models.Word2Vec.load_word2vec_format(word2vec_sample, binary=False) # Use this if newer gensim: gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.651095837676\n",
      "0.887075321449\n",
      "[ 0.01637     0.072989   -0.066381    0.0633773  -0.0256813  -0.0699854\n",
      " -0.0210256  -0.0164451   0.031989    0.0140421   0.0367949  -0.0961173\n",
      " -0.0162949  -0.138769   -0.0955165  -0.0447546  -0.0459561  -0.0408498\n",
      " -0.13816901 -0.00071806  0.0405495  -0.019674    0.0361942   0.0949158\n",
      " -0.0447546  -0.0651795  -0.0294359   0.0762931   0.139971   -0.0100623\n",
      " -0.0252308   0.054066   -0.045055   -0.00867308  0.0262821  -0.0567693\n",
      "  0.0684835  -0.0162949   0.00702106  0.0444542  -0.0238791   0.0456557\n",
      "  0.0726887   0.0804982  -0.0211758  -0.108132   -0.00253434  0.0859048\n",
      "  0.18863     0.0582711  -0.0195238   0.0657802   0.0768938  -0.0318388\n",
      "  0.0138169   0.0367949   0.0333407   0.0204249   0.151985    0.00435531\n",
      " -0.009837   -0.0294359  -0.0049185  -0.0396484   0.0309377  -0.0657802\n",
      "  0.0008307  -0.0414506  -0.0130659  -0.00403617  0.0387473   0.0252308\n",
      " -0.0049185  -0.0420513  -0.039348   -0.00998718 -0.0156191  -0.0810989\n",
      " -0.0597729  -0.0241795  -0.0327399  -0.0190733   0.0642784  -0.0925129\n",
      "  0.00732143  0.096718   -0.0534652  -0.16219801  0.033641   -0.0798975\n",
      "  0.0889085   0.0531649  -0.0462564   0.011489   -0.0134414   0.0259817\n",
      "  0.0459561   0.0492601   0.0117894  -0.0342418  -0.0176465  -0.0129908\n",
      "  0.0432528  -0.0177216   0.0138169  -0.0130659   0.0603736  -0.0741905\n",
      "  0.00953663  0.00578205 -0.0961173  -0.048359    0.0597729   0.0955165\n",
      " -0.0183224  -0.0255311  -0.0182473  -0.135766   -0.0693846  -0.0153938\n",
      " -0.0579707   0.0279341  -0.0189231   0.0226777  -0.120747    0.0414506\n",
      "  0.0901099  -0.00720879 -0.0173462   0.0208755  -0.0714872  -0.0142674\n",
      " -0.0423517   0.0462564  -0.0115641   0.0189231   0.00478709 -0.0382967\n",
      "  0.0256813   0.0865055   0.0522638   0.0104377  -0.0144176   0.0931136\n",
      "  0.0168205   0.0297363  -0.0358938   0.0699854  -0.0636777  -0.0222271\n",
      "  0.0955165  -0.0576704  -0.14718001  0.136967    0.0768938  -0.0612747\n",
      "  0.0202747   0.0135165   0.00799726  0.0036044   0.030337   -0.0300366\n",
      "  0.0660806  -0.0249304  -0.0474579  -0.0699854   0.0552674   0.00919872\n",
      " -0.0205751  -0.0355934   0.0498608   0.0744909   0.0477583   0.0561685\n",
      " -0.0949158  -0.014793    0.0355934   0.0835019   0.015544   -0.004712\n",
      " -0.0702857  -0.124952   -0.0283846   0.0456557  -0.0582711   0.0210256\n",
      "  0.00480586 -0.00829762  0.0306374   0.0853041  -0.0654799  -0.0537656\n",
      " -0.100923   -0.0261319   0.00886081  0.0570696  -0.0141923  -0.02463\n",
      " -0.051663    0.028685   -0.00109352 -0.105128   -0.0202747  -0.0363443\n",
      " -0.0417509  -0.0441539   0.0234286  -0.019674   -0.00347299 -0.00420513\n",
      " -0.0726887   0.0222271  -0.0313883  -0.119546   -0.0101374   0.078696\n",
      "  0.102725   -0.0889085   0.00036373  0.00604487  0.0330403   0.00525641\n",
      " -0.0190733  -0.00441163 -0.0576704  -0.111136    0.0211758   0.0435531\n",
      "  0.0453553   0.00253434  0.138769   -0.0997216  -0.0193736  -0.13096\n",
      " -0.0109634  -0.164601    0.0471575  -0.05737     0.102125    0.0489597\n",
      "  0.0847033  -0.0678828   0.00156754 -0.0726887   0.0156941   0.00465568\n",
      " -0.00566942  0.048359    0.0690843  -0.0871063  -0.120147   -0.0279341\n",
      "  0.00991209 -0.0408498  -0.0105879  -0.0280843  -0.0184725  -0.0678828\n",
      " -0.0262821   0.00717125 -0.0291355   0.00867308  0.00882326  0.0358938\n",
      "  0.0513627   0.0618755  -0.0829011  -0.00998718  0.00074153 -0.00687088\n",
      " -0.0501612   0.0456557  -0.0465568   0.0387473  -0.0110385  -0.0367949\n",
      " -0.0597729  -0.0168956  -0.0255311   0.0235788   0.0621758   0.0495605\n",
      "  0.0901099   0.0348425   0.0702857  -0.0853041  -0.0191484   0.036044\n",
      "  0.039348    0.129758   -0.0216264  -0.00600733 -0.0498608  -0.0438535\n",
      "  0.0525641   0.0277839   0.0321392   0.0762931  -0.00717125  0.0114139 ]\n",
      "[(u'Sultan', 0.281292200088501), (u'kingdom', 0.2541031837463379), (u'kings', 0.23390893638134003), (u'Uncle', 0.23022136092185974), (u'King', 0.2208530157804489), (u'followeth', 0.21388334035873413), (u'Kingdom', 0.21375447511672974), (u'Jr.', 0.2125283181667328), (u'Nasser', 0.211060032248497), (u'prophet', 0.20930814743041992)]\n",
      "[(u'Sultan', 1.196327805519104), (u'Jr.', 1.1830052137374878), (u'AEC', 1.1750377416610718), (u'Yogi', 1.1739656925201416), (u'Uncle', 1.1731584072113037), (u'Nasser', 1.1691230535507202), (u'Brother', 1.1687828302383423), (u'kingdom', 1.1621840000152588), (u'followeth', 1.1606109142303467), (u'Moloch', 1.1587198972702026)]\n",
      "farm\n",
      "0.651095837676\n"
     ]
    }
   ],
   "source": [
    "# By word\n",
    "print word2vec_model.similarity(\"king\", \"queen\")\n",
    "\n",
    "# By set of words\n",
    "print word2vec_model.n_similarity([\"king\", \"royal\"], [\"queen\", \"royal\"])\n",
    "\n",
    "# Word vector from word\n",
    "print word2vec_model[\"turtle\"]\n",
    "    \n",
    "# Similarity measures\n",
    "print word2vec_model.most_similar(positive=[\"king\"], negative=[\"queen\"], topn=10)\n",
    "print word2vec_model.most_similar_cosmul(positive=[\"king\"], negative=[\"queen\"], topn=10)\n",
    "\n",
    "print word2vec_model.doesnt_match([\"farm\", \"turtle\", \"kangaroo\"])\n",
    "print word2vec_model.similarity(\"king\", \"queen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersected doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import gensim\n",
    "reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameter tuning example\n",
    "\n",
    "sampling_threshold = 1e-5\n",
    "hs = 0\n",
    "dm = 0\n",
    "negative_size = 5\n",
    "dbow_words = 1\n",
    "\n",
    "vector_size = 300\n",
    "window_size = 15\n",
    "min_count = 10\n",
    "\n",
    "train_epoch = 30\n",
    "\n",
    "alpha = 0.025\n",
    "min_alpha = 0.0001\n",
    "\n",
    "alpha_delta = (alpha - min_alpha) / train_epoch\n",
    "\n",
    "worker_count = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "\n",
    "for doc in trainSents:\n",
    "    for sent in doc:\n",
    "        sentences.append(sent.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LabeledLineSentence(object):\n",
    "    def __iter__(self):        \n",
    "        for i, sent in enumerate(sentences):\n",
    "              yield gensim.models.doc2vec.LabeledSentence(sent, [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_corp = LabeledLineSentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shuffle(sentences)\n",
    "doc2vec_model = gensim.models.Doc2Vec(\n",
    "    size=vector_size, \n",
    "    window=window_size, \n",
    "    min_count=min_count, \n",
    "    sample=sampling_threshold, \n",
    "    workers=worker_count,\n",
    "    hs=hs, dm=dm,\n",
    "    negative=negative_size,\n",
    "    dbow_words=dbow_words,\n",
    "    alpha=alpha, \n",
    "    min_alpha=min_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc2vec_model.build_vocab(sent_corp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc2vec_model.intersect_word2vec_format(word2vec_sample, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round:  0\n",
      "Round:  1\n",
      "Round:  2\n",
      "Round:  3\n",
      "Round:  4\n",
      "Round:  5\n",
      "Round:  6\n",
      "Round:  7\n",
      "Round:  8\n",
      "Round:  9\n",
      "Round:  10\n",
      "Round:  11\n",
      "Round:  12\n",
      "Round:  13\n",
      "Round:  14\n",
      "Round:  15\n",
      "Round:  16\n",
      "Round:  17\n",
      "Round:  18\n",
      "Round:  19\n",
      "Round:  20\n",
      "Round:  21\n",
      "Round:  22\n",
      "Round:  23\n",
      "Round:  24\n",
      "Round:  25\n",
      "Round:  26\n",
      "Round:  27\n",
      "Round:  28\n",
      "Round:  29\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(train_epoch):\n",
    "\n",
    "    shuffle(sentences)\n",
    "    \n",
    "    print \"Round: \", epoch\n",
    "\n",
    "    doc2vec_model.alpha = alpha\n",
    "    doc2vec_model.min_alpha = alpha\n",
    "\n",
    "    doc2vec_model.train(sent_corp)\n",
    "\n",
    "    alpha -= alpha_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save vec\n",
    "doc2vec_model.save(\"./doc2vec_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.31497025e-01   4.28963780e-01   1.89759552e-01  -7.62067363e-03\n",
      "   2.36616462e-01  -5.26692905e-02   1.90043628e-01  -3.95169616e-01\n",
      "   3.86164904e-01  -8.74810666e-02  -6.36034310e-02  -3.79510403e-01\n",
      "  -9.33280364e-02   3.44261453e-02  -1.69033721e-01  -2.06876159e-01\n",
      "   1.68516830e-01   1.85036257e-01   1.94571361e-01   7.64003256e-03\n",
      "   1.67728320e-01   2.91753829e-01  -2.83090323e-01   1.77406911e-02\n",
      "   2.58673459e-01  -1.62149072e-02  -1.00098200e-01  -7.95970857e-02\n",
      "   3.50048244e-01  -3.74841362e-01  -4.44957241e-03   8.59596208e-02\n",
      "  -7.26464093e-02   4.30337004e-02  -1.07183091e-01  -3.78531665e-01\n",
      "   2.62540698e-01  -5.18812798e-02   4.85228328e-03   5.47052249e-02\n",
      "  -8.39148313e-02   1.10118851e-01   2.24901006e-01  -2.22072646e-01\n",
      "  -2.20796570e-01  -2.63728440e-01  -9.82312933e-02   1.03392914e-01\n",
      "   1.51837245e-01  -2.79694200e-01  -4.59061339e-02  -7.51143396e-02\n",
      "  -1.55862719e-01   4.17556502e-02  -2.17629701e-01  -1.29511699e-01\n",
      "   1.22726662e-02  -2.05150083e-01  -3.26811336e-02  -2.30575442e-01\n",
      "  -3.63693982e-02  -7.23167742e-03  -2.80978292e-01  -1.23426192e-01\n",
      "  -1.74907029e-01  -2.51841933e-01  -4.58795317e-02   1.44904092e-01\n",
      "  -4.17949170e-01  -9.13363136e-03   1.37323186e-01   1.70604549e-02\n",
      "   1.73891574e-01  -1.63531899e-01  -4.94242787e-01  -2.42098659e-01\n",
      "  -8.14012513e-02  -1.21482596e-01   1.31897489e-02   6.89239874e-02\n",
      "   1.72217235e-01   9.13563520e-02  -2.87792776e-02   6.78890273e-02\n",
      "  -1.85300723e-01  -2.45722398e-01  -2.65412211e-01  -2.22679019e-01\n",
      "   4.60964777e-02   1.81774482e-01   6.49305899e-03  -1.71297103e-01\n",
      "  -7.02795014e-02   2.71598876e-01   1.61294620e-02  -6.04146421e-02\n",
      "  -7.09558427e-02   8.99402201e-02  -4.24144343e-02   2.42648497e-01\n",
      "   9.00481716e-02  -2.22378477e-01  -7.24889413e-02   8.07476938e-02\n",
      "   1.30212247e-01  -2.53663570e-01   6.43802881e-02   1.57142058e-01\n",
      "   2.42726617e-02  -2.44563431e-01  -9.06364024e-02  -5.03729358e-02\n",
      "  -1.64172947e-02   7.43858442e-02  -7.81579167e-02   2.71423191e-01\n",
      "  -5.38052879e-02   8.81442726e-02  -3.12188249e-02  -2.99477223e-02\n",
      "  -3.12264096e-02   6.41789883e-02   7.02358410e-02   2.77534673e-05\n",
      "  -1.26783431e-01  -2.95120955e-01  -1.55789889e-02   6.51103929e-02\n",
      "   1.40322983e-01   4.45699155e-01  -1.12739600e-01   2.45861158e-01\n",
      "   7.73125887e-02   2.83154342e-02  -8.78852010e-02   2.04570554e-02\n",
      "   5.49241044e-02   4.15659696e-02   3.28227639e-01   1.11896597e-01\n",
      "   3.19279790e-01  -1.71127513e-01   6.01204894e-02   4.42295671e-01\n",
      "   1.44027732e-02   1.85351204e-02  -1.19624518e-01  -2.11956695e-01\n",
      "  -2.34261572e-01  -2.33597428e-01   5.89436293e-02  -2.84977388e-02\n",
      "   8.76551047e-02   4.04452980e-01   9.62183028e-02  -8.91231075e-02\n",
      "  -8.53166208e-02  -1.25784978e-01  -4.95167434e-01   9.21628922e-02\n",
      "  -5.70160896e-02   1.01121217e-01   1.05300814e-01   8.62423051e-03\n",
      "   8.07050616e-03  -2.31185302e-01   2.38978356e-01  -1.44090056e-01\n",
      "  -6.67712763e-02  -9.07792896e-02  -1.27523825e-01   1.57766089e-01\n",
      "   3.65830064e-02  -3.98475498e-01   5.38795330e-02   1.09239131e-01\n",
      "   1.92898437e-01  -4.13711280e-01  -1.35160297e-01   1.07787957e-03\n",
      "  -4.55608994e-01  -2.13732883e-01  -1.61113113e-01  -1.40610440e-02\n",
      "  -9.12607014e-02  -2.35204533e-01   1.64356709e-01   2.08678871e-01\n",
      "   2.80819803e-01   9.39912125e-02   1.44577295e-01  -3.80409998e-03\n",
      "  -8.44939128e-02   2.14474589e-01  -3.12351100e-02   1.56557441e-01\n",
      "  -4.22907807e-02  -1.34867290e-02   7.06299096e-02  -3.12885046e-01\n",
      "   2.94823498e-01   1.01775371e-01  -3.59637707e-01   9.07006711e-02\n",
      "   8.31950642e-03  -2.55382687e-01  -1.14288546e-01   1.06601968e-01\n",
      "   4.60649244e-02   1.57171395e-02  -7.96376765e-02   3.78970802e-01\n",
      "   9.52442288e-02   3.19253743e-01  -5.45870885e-02  -3.55397463e-02\n",
      "   1.65653810e-01   1.33426916e-02   6.26330823e-02  -1.85146779e-01\n",
      "  -1.73501283e-01   3.53331231e-02   2.17558637e-01   1.73738852e-01\n",
      "  -5.43530881e-02  -4.24337126e-02   2.39276469e-01   1.50699764e-01\n",
      "   6.66964054e-02  -1.14910938e-01   4.17928472e-02   1.00047477e-01\n",
      "  -1.16508603e-01   3.64608109e-01   1.21131346e-01   2.87150949e-01\n",
      "   2.13464558e-01  -1.72312632e-02   1.56785280e-01   2.05084041e-01\n",
      "  -8.18181410e-02  -2.65958607e-01  -5.87664098e-02  -7.62358680e-02\n",
      "  -1.48352608e-01   4.89886478e-02   1.29530147e-01   1.40570449e-02\n",
      "   1.20881662e-01  -8.15788358e-02   5.27970977e-02   2.93792505e-02\n",
      "   7.35232383e-02   1.65223166e-01   1.29031301e-01   4.13970128e-02\n",
      "  -2.76716709e-01  -1.85931310e-01  -2.03533292e-01  -3.64895552e-01\n",
      "  -1.55888230e-01   9.51624438e-02   2.26891100e-01   3.04801345e-01\n",
      "   1.40905306e-01  -2.22271279e-01  -2.05917694e-02  -2.11804911e-01\n",
      "  -2.31670141e-01  -6.88192099e-02  -1.86466742e-02   2.30749488e-01\n",
      "  -1.66776143e-02  -1.82207361e-01   4.61142838e-01  -6.42097369e-02\n",
      "  -5.72453700e-02  -2.03576222e-01   4.57669459e-02   3.62941325e-02\n",
      "  -1.08830750e-01   3.25299472e-01  -5.39094992e-02   1.51824161e-01\n",
      "  -6.38190210e-02  -2.56936461e-01   1.38283059e-01   3.55795205e-01\n",
      "   7.99690336e-02   3.41072381e-01  -1.01470649e-01  -2.28960648e-01\n",
      "  -4.30529803e-01   1.35338590e-01   1.99509382e-01  -2.06415609e-01\n",
      "   1.11130670e-01  -3.49696241e-02   1.54366866e-01  -6.71295971e-02]\n",
      "farm\n",
      "[(u'huns', 0.24207834899425507), (u'abandoning', 0.2200893610715866), (u'murdered', 0.21127328276634216), (u'undisputed', 0.20080813765525818), (u'commanded', 0.19702816009521484), (u'(c.', 0.19458350539207458), (u'magnus', 0.1942438930273056), (u'region', 0.1911391317844391), (u'demise', 0.1903011053800583), (u'impression', 0.18742996454238892)]\n",
      "[(u'huns', 1.13799250125885), (u'abandoning', 1.1367428302764893), (u'murdered', 1.129019021987915), (u'undisputed', 1.1230363845825195), (u'impression', 1.1155271530151367), (u'expense', 1.1153360605239868), (u'commanded', 1.1150836944580078), (u'magnus', 1.1146767139434814), (u'demise', 1.114365816116333), (u'(c.', 1.113966464996338)]\n",
      "0.704212032626\n",
      "0.704212032626\n",
      "[ 0.02585918  0.06100375 -0.08774483 -0.00739496 -0.04122698 -0.00534143\n",
      " -0.02446961  0.0260016  -0.0590136  -0.01809221  0.01835017  0.02913041\n",
      " -0.0013288  -0.05486665 -0.01571374  0.03299318  0.00144069 -0.01350606\n",
      "  0.03502028 -0.03823548 -0.00611469  0.003898   -0.08172769  0.01793902\n",
      "  0.00698398  0.00442145 -0.06668975 -0.0989003   0.00695013 -0.0425433\n",
      "  0.03215763  0.04904949 -0.07150216 -0.00418546 -0.02017685  0.00848947\n",
      "  0.02203021  0.01884393  0.02424736 -0.03064172  0.02862456 -0.01221713\n",
      " -0.00516514 -0.00312461  0.00954296  0.02840408 -0.04228759 -0.08578406\n",
      "  0.01818297 -0.03133411 -0.02258679  0.0330611  -0.02714408 -0.02477907\n",
      "  0.00182228  0.0031098  -0.0353213   0.02576219 -0.03131041 -0.02525805\n",
      "  0.05511935 -0.03150685  0.01966664  0.02801436  0.01641754  0.0446643\n",
      "  0.03057235  0.0025353   0.01536783  0.09593218 -0.02286172  0.04981206\n",
      " -0.01931944 -0.00426898 -0.03709302  0.03783145 -0.00179225 -0.01459095\n",
      "  0.04029362  0.04512022  0.0453447   0.06294847  0.02831417  0.03163547\n",
      "  0.00424056  0.02035617  0.05015454  0.04416201  0.04132309 -0.03322023\n",
      " -0.025426    0.01762258  0.06517811 -0.03675087  0.05730379  0.0768512\n",
      "  0.02076814 -0.06238872  0.01031009 -0.03516351  0.01807478 -0.02127575\n",
      "  0.05621732 -0.04352859  0.02296859  0.00799727 -0.01104503 -0.00715159\n",
      "  0.04838916  0.05034655  0.03809059 -0.03979453  0.04030778 -0.03831818\n",
      " -0.01118967 -0.07619529  0.01161084  0.02050308 -0.02891784  0.01476145\n",
      "  0.0363179  -0.00586747 -0.04028201  0.06475788  0.06264052 -0.01494892\n",
      " -0.00439838 -0.04287384 -0.02319544  0.02921851 -0.06027365 -0.04389355\n",
      "  0.00352403  0.01214812 -0.00225636 -0.013862    0.07391041  0.00119935\n",
      " -0.03928717  0.04649908  0.02653568  0.04317921  0.02410018 -0.06975507\n",
      "  0.00163938  0.01648647 -0.03141909 -0.00756751 -0.05094377  0.04036339\n",
      " -0.06810289  0.05244622 -0.01131601  0.02015995 -0.02505327 -0.00412973\n",
      " -0.07151207  0.01464757 -0.01382759 -0.02795403 -0.04609708 -0.02863787\n",
      "  0.00900631 -0.00926893 -0.0063477  -0.00256509  0.0215628   0.00747772\n",
      " -0.02389704  0.02613682 -0.05125268  0.04060712  0.04344188 -0.02729662\n",
      "  0.02009539  0.02302593 -0.02254699 -0.01160049 -0.04584116 -0.05448725\n",
      " -0.05466649 -0.04616675 -0.05583374 -0.02190026 -0.00014707  0.00790153\n",
      " -0.01255134 -0.03343987  0.07828943 -0.02421498  0.03749695 -0.01195321\n",
      "  0.04921286  0.0029674   0.00383798 -0.09001935  0.04454748  0.05415576\n",
      " -0.00698262 -0.02587227 -0.0129608  -0.03042215 -0.00990416  0.00370884\n",
      " -0.00251372 -0.04537825 -0.04421558  0.03167501  0.0375649  -0.03388137\n",
      " -0.00295782  0.01864166  0.04615222 -0.00646993  0.00337122  0.00460658\n",
      " -0.03484327 -0.02011312  0.03632656  0.00637918  0.04616145 -0.10840878\n",
      "  0.02317474 -0.06914655  0.00051942  0.01137162 -0.01487953  0.11236675\n",
      " -0.00955331 -0.03908218 -0.00190035 -0.00837381 -0.01406969  0.08287849\n",
      " -0.0182694  -0.07576462  0.031459   -0.06403176 -0.08908021 -0.08902694\n",
      "  0.05942859 -0.01330912 -0.01062279 -0.01960234  0.00124137  0.01548475\n",
      " -0.05261302  0.05135372 -0.06159668  0.05236287 -0.04433273 -0.03296834\n",
      "  0.0661569  -0.0036175  -0.05383654  0.03321612 -0.05708627 -0.02489134\n",
      " -0.0294832  -0.03260549  0.00881639  0.05493058  0.00624675  0.05699357\n",
      " -0.12792505  0.03957666 -0.0087729  -0.02864727 -0.06834609  0.0428624\n",
      "  0.01727114  0.03555903 -0.02508826  0.04157188 -0.00794741 -0.05013743\n",
      "  0.00623029 -0.09863122 -0.04906521 -0.01756747 -0.09095658 -0.05561997\n",
      "  0.01052165  0.02261661 -0.02588015  0.00304213 -0.02493305 -0.00321341\n",
      " -0.08936793 -0.01018991  0.03045582  0.01329705 -0.03583356 -0.03103523\n",
      "  0.00113265 -0.01058341 -0.01658039 -0.01104227  0.06470878 -0.02626832]\n"
     ]
    }
   ],
   "source": [
    "# Access vector by sen index\n",
    "print doc2vec_model.docvecs[0]\n",
    "\n",
    "# Similarity measures\n",
    "print doc2vec_model.doesnt_match([\"farm\", \"turtle\", \"kangaroo\"])\n",
    "print doc2vec_model.most_similar(positive=[\"king\"], negative=[\"queen\"], topn=10)\n",
    "print doc2vec_model.most_similar_cosmul(positive=[\"king\"], negative=[\"queen\"], topn=10)\n",
    "print doc2vec_model.n_similarity([\"king\"], [\"queen\"])\n",
    "print doc2vec_model.similarity(\"king\", \"queen\")\n",
    "\n",
    "# Infer vector of new sentence\n",
    "infer_vec = doc2vec_model.infer_vector([\"king\", \"queen\"])\n",
    "\n",
    "print infer_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
