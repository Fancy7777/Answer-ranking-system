{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in the python script containing the same code as the load the data notebook\n",
    "%run loadData.py\n",
    "# now we can access train, dev, and test\n",
    "# along with trainSents, devSents testSents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Phonograph records are generally described by their diameter in inches (12\", 10\", 7\"), the rotational speed in rpm at which they are played (16 2\\u20443, 33 1\\u20443, 45, 78), and their time capacity resulting from a combination of those parameters (LP \\u2013 long playing 33 1\\u20443 rpm, SP \\u2013 78 rpm single, EP \\u2013 12-inch single or extended play, 33 or 45 rpm); their reproductive quality or level of fidelity (high-fidelity, orthophonic, full-range, etc.), and the number of audio channels provided (mono, stereo, quad, etc.).'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSents[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'answer': u'long playing',\n",
       " u'answer_sentence': 2,\n",
       " u'question': u'What does LP stand for when it comes to time capacity?'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = trainSents[0]\n",
    "questions = train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Retrieval Pool Boosting\n",
    "\n",
    "## Issue\n",
    "\n",
    "- Candidate sentence not appearing in sentence retrieval pool\n",
    "\n",
    "## Goal\n",
    "\n",
    "- Increase the chance that answer appears in retrieval selection pool (either single sentence or vector of sentences).\n",
    "\n",
    "## Possible Strategies\n",
    "\n",
    "- Increase Size of Pool\n",
    "- Rank Sentences in retrieved Pool\n",
    "- Increase Size of Trained Models (nltk.corpus)\n",
    "- Use in combination with Trained Semantic Models (pretrained word2vec/doc2vec)\n",
    "- Tune preprocessing and hyperparameters to increase pool quality\n",
    "- Determine quality effects of models on a per corpus, multi-corpus or per doc basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tuning functions\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Follow lemmatize function from guide notebook: WSTA_N1B_preprocessing.ipynb\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(word):\n",
    "    lemma = lemmatizer.lemmatize(word,'v')\n",
    "    if lemma == word:\n",
    "        lemma = lemmatizer.lemmatize(word,'n')\n",
    "    return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Core functions\n",
    "\n",
    "def vectorize_documents(text_documents):\n",
    "\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    vector_documents = vectorizer.fit_transform(text_documents)\n",
    "    \n",
    "    return [vector_documents, vectorizer]\n",
    "\n",
    "def vectorize_query(vectorizer, text_query):\n",
    "    return vectorizer.transform([text_query])\n",
    "\n",
    "def process_neighbours(vector_documents):\n",
    "    \n",
    "    neighbours = NearestNeighbors(1, algorithm=\"brute\", metric=\"cosine\")\n",
    "    neighbours.fit(vector_documents)\n",
    "    \n",
    "    return neighbours\n",
    "\n",
    "def closest_documents(neighbours, vector_query, n):\n",
    "\n",
    "    result = neighbours.kneighbors(vector_query, n, return_distance=True)\n",
    "\n",
    "    result_indices = result[1][0]\n",
    "    result_distances = result[0][0]\n",
    "    \n",
    "    return sorted(zip(result_indices, result_distances), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def raw_text_to_sentences(raw_text, tokenizer):\n",
    "    return tokenizer.tokenize(raw_text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processed_sentence(sentence):\n",
    "    words = sentence.split()\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increase Size of Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_sent_corpus = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "punkt_tokenizer = nltk.data.load(\"tokenizers/punkt/english.pickle\")\n",
    "corpora = [nltk.corpus.reuters]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for corpus in corpora:\n",
    "    \n",
    "    for i, fileid in enumerate(corpus.fileids()):\n",
    "        \n",
    "        doc = nltk.corpus.reuters.raw(fileid)\n",
    "        sentences = raw_text_to_sentences(doc, punkt_tokenizer)\n",
    "        \n",
    "        for j, sentence in enumerate(sentences):\n",
    "            \n",
    "            proc_sent = processed_sentence(sentences[0])\n",
    "            \n",
    "            if i == 0 and j == 0:\n",
    "                \n",
    "                print \"Raw:\\n\"\n",
    "                print repr(sentence), \"\\n\"\n",
    "                print \"Processed:\\n\"\n",
    "                print repr(proc_sent)\n",
    "                \n",
    "            full_sent_corpus.append(proc_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A gramophone record (phonograph record in American English) or vinyl record, commonly known as a \"record\", is an analogue sound storage medium in the form of a flat polyvinyl chloride (previously shellac) disc with an inscribed, modulated spiral groove.\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(trainSents):\n",
    "    for j, raw_sent in enumerate(doc):\n",
    "        \n",
    "        if i == 0 and j == 0:\n",
    "            print raw_sent\n",
    "            \n",
    "        full_sent_corpus.append(raw_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_vector_documents, full_vectorizer = vectorize_documents(full_sent_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increase Size of Pool, vectorize candidate sentence retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Demonstration function\n",
    "def demo_process_set_vector(questions, documents):\n",
    "    \n",
    "#     vector_documents = full_vectorizer.transform(documents)\n",
    "    vector_documents, vectorizer = vectorize_documents(documents)\n",
    "    \n",
    "    analyze = full_vectorizer.build_analyzer()\n",
    "    neighbours = process_neighbours(vector_documents)\n",
    "\n",
    "    print \"=\" * 20\n",
    "    print \"Vector documents shape: {0}\".format(vector_documents.shape)\n",
    "    print \"Actual documents length: {0}\".format(len(documents))\n",
    "    print \"=\" * 20, \"\\n\"\n",
    "    \n",
    "    for question in questions[10:10+3]:\n",
    "        \n",
    "        text_query = question[\"question\"]\n",
    "\n",
    "        print \"Text query:\\n\\n\\t{0}\\n\".format(text_query)\n",
    "\n",
    "#         vector_query = vectorize_query(full_vectorizer, text_query)\n",
    "        vector_query = vectorize_query(vectorizer, text_query)\n",
    "\n",
    "        print \"Vector query shape:\\n\\n\\t{0}\".format(vector_query.shape)\n",
    "      \n",
    "        results = closest_documents(neighbours, vector_query, 1)\n",
    "        \n",
    "        print \"Query (text):\\n\\n\\t{0}\\n\".format(text_query)            \n",
    "        print \"Query (vector text):\\n\"\n",
    "        pp.pprint(analyze(text_query))       \n",
    "        \n",
    "        print \"Answer Sentence (text):\\n\\n\\t{0}\\n\".format(text_query)            \n",
    "        print \"Answer Sentence (vector text):\\n\"\n",
    "        pp.pprint(analyze(text_query))               \n",
    "        \n",
    "        \n",
    "        for result_index, result_distance in results:\n",
    "        \n",
    "            print\n",
    "            print \"Result:\\n\\n\\tDistance ({0}), Index ({1})\\n\".format(result_distance, result_index)\n",
    "            print\n",
    "            print \"Document (text):\\n\\n\\t{0}\".format(documents[result_index].encode(\"utf-8\"))\n",
    "            print\n",
    "            print \"Document (vector text): \\n\\n\"\n",
    "            pp.pprint(analyze(documents[result_index]))\n",
    "\n",
    "            print \"\\n\", \"=\" * 20, \"\\n\"\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Vector documents shape: (463, 2425)\n",
      "Actual documents length: 463\n",
      "==================== \n",
      "\n",
      "Text query:\n",
      "\n",
      "\tWhat was the original intent of the phonautograph?\n",
      "\n",
      "Vector query shape:\n",
      "\n",
      "\t(1, 2425)\n",
      "Query (text):\n",
      "\n",
      "\tWhat was the original intent of the phonautograph?\n",
      "\n",
      "Query (vector text):\n",
      "\n",
      "[u'original', u'intent', u'phonautograph']\n",
      "Answer Sentence (text):\n",
      "\n",
      "\tWhat was the original intent of the phonautograph?\n",
      "\n",
      "Answer Sentence (vector text):\n",
      "\n",
      "[u'original', u'intent', u'phonautograph']\n",
      "\n",
      "Result:\n",
      "\n",
      "\tDistance (0.72338690096), Index (9)\n",
      "\n",
      "\n",
      "Document (text):\n",
      "\n",
      "\tThe phonautograph, patented by LÃ©on Scott in 1857, used a vibrating diaphragm and stylus to graphically record sound waves as tracings on sheets of paper, purely for visual analysis and without any intent of playing them back.\n",
      "\n",
      "Document (vector text): \n",
      "\n",
      "\n",
      "[   u'phonautograph',\n",
      "    u'patented',\n",
      "    u'l\\xe9on',\n",
      "    u'scott',\n",
      "    u'1857',\n",
      "    u'used',\n",
      "    u'vibrating',\n",
      "    u'diaphragm',\n",
      "    u'stylus',\n",
      "    u'graphically',\n",
      "    u'record',\n",
      "    u'sound',\n",
      "    u'waves',\n",
      "    u'tracings',\n",
      "    u'sheets',\n",
      "    u'paper',\n",
      "    u'purely',\n",
      "    u'visual',\n",
      "    u'analysis',\n",
      "    u'intent',\n",
      "    u'playing']\n",
      "\n",
      "==================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "demo_process_set_vector(questions, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluateSentenceRetrivalVector(questionsList, documentsList, numToEval, sentenceVectorSize):\n",
    "    \n",
    "    numCorrect = 0\n",
    "    numWrong = 0\n",
    "    \n",
    "    for i in range (0, numToEval):\n",
    "        \n",
    "        documents = documentsList[i]\n",
    "        questions = questionsList[i]\n",
    "        \n",
    "#         vector_documents = full_vectorizer.transform(documents)\n",
    "        vector_documents, vectorizer = vectorize_documents(documents)\n",
    "\n",
    "        analyze = full_vectorizer.build_analyzer()\n",
    "        neighbours = process_neighbours(vector_documents)        \n",
    "        \n",
    "        for j in range (0, len(questions)):\n",
    "            \n",
    "            text_query = questions[j][\"question\"]\n",
    "            \n",
    "#             vector_query = vectorize_query(full_vectorizer, text_query)\n",
    "            vector_query = vectorize_query(vectorizer, text_query)\n",
    "            \n",
    "            results  = closest_documents(neighbours, vector_query, sentenceVectorSize)\n",
    "            \n",
    "            hit = False\n",
    "            \n",
    "            for result_index, result_distance in results:\n",
    "                if result_index == int(questions[j][\"answer_sentence\"]):\n",
    "                    numCorrect += 1\n",
    "                    hit = True\n",
    "                    break\n",
    "            \n",
    "            if not hit:\n",
    "                numWrong += 1\n",
    "                \n",
    "    return (numCorrect, numWrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence Vector Size : 1\n",
      "\tNumber Correct : 905\n",
      "\tNumber incorrect: 756\n",
      "\tTotal : 1661\n",
      "\tAverage correct : 0.544852498495\n",
      "\n",
      "Sentence Vector Size : 2\n",
      "\tNumber Correct : 1111\n",
      "\tNumber incorrect: 550\n",
      "\tTotal : 1661\n",
      "\tAverage correct : 0.668874172185\n",
      "\n",
      "Sentence Vector Size : 3\n",
      "\tNumber Correct : 1202\n",
      "\tNumber incorrect: 459\n",
      "\tTotal : 1661\n",
      "\tAverage correct : 0.723660445515\n",
      "\n",
      "Sentence Vector Size : 4\n",
      "\tNumber Correct : 1251\n",
      "\tNumber incorrect: 410\n",
      "\tTotal : 1661\n",
      "\tAverage correct : 0.753160746538\n",
      "\n",
      "Sentence Vector Size : 5\n",
      "\tNumber Correct : 1284\n",
      "\tNumber incorrect: 377\n",
      "\tTotal : 1661\n",
      "\tAverage correct : 0.773028296207\n",
      "\n",
      "Sentence Vector Size : 10\n",
      "\tNumber Correct : 1393\n",
      "\tNumber incorrect: 268\n",
      "\tTotal : 1661\n",
      "\tAverage correct : 0.83865141481\n",
      "\n",
      "Sentence Vector Size : 20\n",
      "\tNumber Correct : 1464\n",
      "\tNumber incorrect: 197\n",
      "\tTotal : 1661\n",
      "\tAverage correct : 0.881396748946\n",
      "\n",
      "Sentence Vector Size : 30\n",
      "\tNumber Correct : 1499\n",
      "\tNumber incorrect: 162\n",
      "\tTotal : 1661\n",
      "\tAverage correct : 0.902468392535\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for x in [1,2,3,4,5,10,20,30]:\n",
    "    \n",
    "    (correct, wrong) = evaluateSentenceRetrivalVector(train, trainSents, 10, x)\n",
    "    \n",
    "    print\n",
    "    print(\"Sentence Vector Size : \" + str(x))\n",
    "    print(\"\\tNumber Correct : \" + str(correct))\n",
    "    print(\"\\tNumber incorrect: \" + str(wrong))\n",
    "    print(\"\\tTotal : \" + str(correct + wrong))\n",
    "    print (\"\\tAverage correct : \" + str((correct + 0.0) / (correct + wrong)))\n",
    "    \n",
    "    results.append((x, (correct + 0.0) / (correct + wrong)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Vector Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f73e10a1950>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEcCAYAAADgJkIVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAfNpereo1G+4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f73e177ced0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = pd.DataFrame(results).plot.bar(x=0, y=1, title=\"Sentence Pool Size vs. Proportion of Answer Sentences in Pool\", legend=False)\n",
    "\n",
    "ax.set_xlabel(\"Sentence Pool Size\")\n",
    "ax.set_ylabel(\"Proportion of Answer Sentences in Pool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of sentences per document: 208.819444444\n"
     ]
    }
   ],
   "source": [
    "print \"Average number of sentences per document:\", sum(map(len, trainSents)) * 1.0 / len(trainSents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Models\n",
    "\n",
    "## Pretrained word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# From: WSTA_N10_word_vectors\n",
    "\n",
    "import gensim\n",
    "from nltk.data import find\n",
    "\n",
    "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))\n",
    "word2vec_model = gensim.models.Word2Vec.load_word2vec_format(word2vec_sample, binary=False) # Use this if newer gensim: gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.651095837676\n",
      "0.887075321449\n",
      "[ 0.01637     0.072989   -0.066381    0.0633773  -0.0256813  -0.0699854\n",
      " -0.0210256  -0.0164451   0.031989    0.0140421   0.0367949  -0.0961173\n",
      " -0.0162949  -0.138769   -0.0955165  -0.0447546  -0.0459561  -0.0408498\n",
      " -0.13816901 -0.00071806  0.0405495  -0.019674    0.0361942   0.0949158\n",
      " -0.0447546  -0.0651795  -0.0294359   0.0762931   0.139971   -0.0100623\n",
      " -0.0252308   0.054066   -0.045055   -0.00867308  0.0262821  -0.0567693\n",
      "  0.0684835  -0.0162949   0.00702106  0.0444542  -0.0238791   0.0456557\n",
      "  0.0726887   0.0804982  -0.0211758  -0.108132   -0.00253434  0.0859048\n",
      "  0.18863     0.0582711  -0.0195238   0.0657802   0.0768938  -0.0318388\n",
      "  0.0138169   0.0367949   0.0333407   0.0204249   0.151985    0.00435531\n",
      " -0.009837   -0.0294359  -0.0049185  -0.0396484   0.0309377  -0.0657802\n",
      "  0.0008307  -0.0414506  -0.0130659  -0.00403617  0.0387473   0.0252308\n",
      " -0.0049185  -0.0420513  -0.039348   -0.00998718 -0.0156191  -0.0810989\n",
      " -0.0597729  -0.0241795  -0.0327399  -0.0190733   0.0642784  -0.0925129\n",
      "  0.00732143  0.096718   -0.0534652  -0.16219801  0.033641   -0.0798975\n",
      "  0.0889085   0.0531649  -0.0462564   0.011489   -0.0134414   0.0259817\n",
      "  0.0459561   0.0492601   0.0117894  -0.0342418  -0.0176465  -0.0129908\n",
      "  0.0432528  -0.0177216   0.0138169  -0.0130659   0.0603736  -0.0741905\n",
      "  0.00953663  0.00578205 -0.0961173  -0.048359    0.0597729   0.0955165\n",
      " -0.0183224  -0.0255311  -0.0182473  -0.135766   -0.0693846  -0.0153938\n",
      " -0.0579707   0.0279341  -0.0189231   0.0226777  -0.120747    0.0414506\n",
      "  0.0901099  -0.00720879 -0.0173462   0.0208755  -0.0714872  -0.0142674\n",
      " -0.0423517   0.0462564  -0.0115641   0.0189231   0.00478709 -0.0382967\n",
      "  0.0256813   0.0865055   0.0522638   0.0104377  -0.0144176   0.0931136\n",
      "  0.0168205   0.0297363  -0.0358938   0.0699854  -0.0636777  -0.0222271\n",
      "  0.0955165  -0.0576704  -0.14718001  0.136967    0.0768938  -0.0612747\n",
      "  0.0202747   0.0135165   0.00799726  0.0036044   0.030337   -0.0300366\n",
      "  0.0660806  -0.0249304  -0.0474579  -0.0699854   0.0552674   0.00919872\n",
      " -0.0205751  -0.0355934   0.0498608   0.0744909   0.0477583   0.0561685\n",
      " -0.0949158  -0.014793    0.0355934   0.0835019   0.015544   -0.004712\n",
      " -0.0702857  -0.124952   -0.0283846   0.0456557  -0.0582711   0.0210256\n",
      "  0.00480586 -0.00829762  0.0306374   0.0853041  -0.0654799  -0.0537656\n",
      " -0.100923   -0.0261319   0.00886081  0.0570696  -0.0141923  -0.02463\n",
      " -0.051663    0.028685   -0.00109352 -0.105128   -0.0202747  -0.0363443\n",
      " -0.0417509  -0.0441539   0.0234286  -0.019674   -0.00347299 -0.00420513\n",
      " -0.0726887   0.0222271  -0.0313883  -0.119546   -0.0101374   0.078696\n",
      "  0.102725   -0.0889085   0.00036373  0.00604487  0.0330403   0.00525641\n",
      " -0.0190733  -0.00441163 -0.0576704  -0.111136    0.0211758   0.0435531\n",
      "  0.0453553   0.00253434  0.138769   -0.0997216  -0.0193736  -0.13096\n",
      " -0.0109634  -0.164601    0.0471575  -0.05737     0.102125    0.0489597\n",
      "  0.0847033  -0.0678828   0.00156754 -0.0726887   0.0156941   0.00465568\n",
      " -0.00566942  0.048359    0.0690843  -0.0871063  -0.120147   -0.0279341\n",
      "  0.00991209 -0.0408498  -0.0105879  -0.0280843  -0.0184725  -0.0678828\n",
      " -0.0262821   0.00717125 -0.0291355   0.00867308  0.00882326  0.0358938\n",
      "  0.0513627   0.0618755  -0.0829011  -0.00998718  0.00074153 -0.00687088\n",
      " -0.0501612   0.0456557  -0.0465568   0.0387473  -0.0110385  -0.0367949\n",
      " -0.0597729  -0.0168956  -0.0255311   0.0235788   0.0621758   0.0495605\n",
      "  0.0901099   0.0348425   0.0702857  -0.0853041  -0.0191484   0.036044\n",
      "  0.039348    0.129758   -0.0216264  -0.00600733 -0.0498608  -0.0438535\n",
      "  0.0525641   0.0277839   0.0321392   0.0762931  -0.00717125  0.0114139 ]\n",
      "[(u'Sultan', 0.281292200088501), (u'kingdom', 0.2541031837463379), (u'kings', 0.23390893638134003), (u'Uncle', 0.23022136092185974), (u'King', 0.2208530157804489), (u'followeth', 0.21388334035873413), (u'Kingdom', 0.21375447511672974), (u'Jr.', 0.2125283181667328), (u'Nasser', 0.211060032248497), (u'prophet', 0.20930814743041992)]\n",
      "[(u'Sultan', 1.196327805519104), (u'Jr.', 1.1830052137374878), (u'AEC', 1.1750377416610718), (u'Yogi', 1.1739656925201416), (u'Uncle', 1.1731584072113037), (u'Nasser', 1.1691230535507202), (u'Brother', 1.1687828302383423), (u'kingdom', 1.1621840000152588), (u'followeth', 1.1606109142303467), (u'Moloch', 1.1587198972702026)]\n",
      "farm\n",
      "0.651095837676\n"
     ]
    }
   ],
   "source": [
    "# By word\n",
    "print word2vec_model.similarity(\"king\", \"queen\")\n",
    "\n",
    "# By set of words\n",
    "print word2vec_model.n_similarity([\"king\", \"royal\"], [\"queen\", \"royal\"])\n",
    "\n",
    "# Word vector from word\n",
    "print word2vec_model[\"turtle\"]\n",
    "    \n",
    "# Similarity measures\n",
    "print word2vec_model.most_similar(positive=[\"king\"], negative=[\"queen\"], topn=10)\n",
    "print word2vec_model.most_similar_cosmul(positive=[\"king\"], negative=[\"queen\"], topn=10)\n",
    "\n",
    "print word2vec_model.doesnt_match([\"farm\", \"turtle\", \"kangaroo\"])\n",
    "print word2vec_model.similarity(\"king\", \"queen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersected doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import gensim\n",
    "reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameter tuning example\n",
    "\n",
    "sampling_threshold = 1e-5\n",
    "hs = 0\n",
    "dm = 0\n",
    "negative_size = 5\n",
    "dbow_words = 1\n",
    "\n",
    "vector_size = 300\n",
    "window_size = 15\n",
    "min_count = 10\n",
    "\n",
    "train_epoch = 30\n",
    "\n",
    "alpha = 0.025\n",
    "min_alpha = 0.0001\n",
    "\n",
    "alpha_delta = (alpha - min_alpha) / train_epoch\n",
    "\n",
    "worker_count = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "\n",
    "for doc in trainSents:\n",
    "    for sent in doc:\n",
    "        sentences.append(sent.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LabeledLineSentence(object):\n",
    "    def __iter__(self):        \n",
    "        for i, sent in enumerate(sentences):\n",
    "              yield gensim.models.doc2vec.LabeledSentence(sent, [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_corp = LabeledLineSentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shuffle(sentences)\n",
    "doc2vec_model = gensim.models.Doc2Vec(\n",
    "    size=vector_size, \n",
    "    window=window_size, \n",
    "    min_count=min_count, \n",
    "    sample=sampling_threshold, \n",
    "    workers=worker_count,\n",
    "    hs=hs, dm=dm,\n",
    "    negative=negative_size,\n",
    "    dbow_words=dbow_words,\n",
    "    alpha=alpha, \n",
    "    min_alpha=min_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc2vec_model.build_vocab(sent_corp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc2vec_model.intersect_word2vec_format(word2vec_sample, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round:  0\n",
      "Round:  1\n",
      "Round:  2\n",
      "Round:  3\n",
      "Round:  4\n",
      "Round:  5\n",
      "Round:  6\n",
      "Round:  7\n",
      "Round:  8\n",
      "Round:  9\n",
      "Round:  10\n",
      "Round:  11\n",
      "Round:  12\n",
      "Round:  13\n",
      "Round:  14\n",
      "Round:  15\n",
      "Round:  16\n",
      "Round:  17\n",
      "Round:  18\n",
      "Round:  19\n",
      "Round:  20\n",
      "Round:  21\n",
      "Round:  22\n",
      "Round:  23\n",
      "Round:  24\n",
      "Round:  25\n",
      "Round:  26\n",
      "Round:  27\n",
      "Round:  28\n",
      "Round:  29\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(train_epoch):\n",
    "\n",
    "    shuffle(sentences)\n",
    "    \n",
    "    print \"Round: \", epoch\n",
    "\n",
    "    doc2vec_model.alpha = alpha\n",
    "    doc2vec_model.min_alpha = alpha\n",
    "\n",
    "    doc2vec_model.train(sent_corp)\n",
    "\n",
    "    alpha -= alpha_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save vec\n",
    "doc2vec_model.save(\"./doc2vec_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.31497025e-01   4.28963780e-01   1.89759552e-01  -7.62067363e-03\n",
      "   2.36616462e-01  -5.26692905e-02   1.90043628e-01  -3.95169616e-01\n",
      "   3.86164904e-01  -8.74810666e-02  -6.36034310e-02  -3.79510403e-01\n",
      "  -9.33280364e-02   3.44261453e-02  -1.69033721e-01  -2.06876159e-01\n",
      "   1.68516830e-01   1.85036257e-01   1.94571361e-01   7.64003256e-03\n",
      "   1.67728320e-01   2.91753829e-01  -2.83090323e-01   1.77406911e-02\n",
      "   2.58673459e-01  -1.62149072e-02  -1.00098200e-01  -7.95970857e-02\n",
      "   3.50048244e-01  -3.74841362e-01  -4.44957241e-03   8.59596208e-02\n",
      "  -7.26464093e-02   4.30337004e-02  -1.07183091e-01  -3.78531665e-01\n",
      "   2.62540698e-01  -5.18812798e-02   4.85228328e-03   5.47052249e-02\n",
      "  -8.39148313e-02   1.10118851e-01   2.24901006e-01  -2.22072646e-01\n",
      "  -2.20796570e-01  -2.63728440e-01  -9.82312933e-02   1.03392914e-01\n",
      "   1.51837245e-01  -2.79694200e-01  -4.59061339e-02  -7.51143396e-02\n",
      "  -1.55862719e-01   4.17556502e-02  -2.17629701e-01  -1.29511699e-01\n",
      "   1.22726662e-02  -2.05150083e-01  -3.26811336e-02  -2.30575442e-01\n",
      "  -3.63693982e-02  -7.23167742e-03  -2.80978292e-01  -1.23426192e-01\n",
      "  -1.74907029e-01  -2.51841933e-01  -4.58795317e-02   1.44904092e-01\n",
      "  -4.17949170e-01  -9.13363136e-03   1.37323186e-01   1.70604549e-02\n",
      "   1.73891574e-01  -1.63531899e-01  -4.94242787e-01  -2.42098659e-01\n",
      "  -8.14012513e-02  -1.21482596e-01   1.31897489e-02   6.89239874e-02\n",
      "   1.72217235e-01   9.13563520e-02  -2.87792776e-02   6.78890273e-02\n",
      "  -1.85300723e-01  -2.45722398e-01  -2.65412211e-01  -2.22679019e-01\n",
      "   4.60964777e-02   1.81774482e-01   6.49305899e-03  -1.71297103e-01\n",
      "  -7.02795014e-02   2.71598876e-01   1.61294620e-02  -6.04146421e-02\n",
      "  -7.09558427e-02   8.99402201e-02  -4.24144343e-02   2.42648497e-01\n",
      "   9.00481716e-02  -2.22378477e-01  -7.24889413e-02   8.07476938e-02\n",
      "   1.30212247e-01  -2.53663570e-01   6.43802881e-02   1.57142058e-01\n",
      "   2.42726617e-02  -2.44563431e-01  -9.06364024e-02  -5.03729358e-02\n",
      "  -1.64172947e-02   7.43858442e-02  -7.81579167e-02   2.71423191e-01\n",
      "  -5.38052879e-02   8.81442726e-02  -3.12188249e-02  -2.99477223e-02\n",
      "  -3.12264096e-02   6.41789883e-02   7.02358410e-02   2.77534673e-05\n",
      "  -1.26783431e-01  -2.95120955e-01  -1.55789889e-02   6.51103929e-02\n",
      "   1.40322983e-01   4.45699155e-01  -1.12739600e-01   2.45861158e-01\n",
      "   7.73125887e-02   2.83154342e-02  -8.78852010e-02   2.04570554e-02\n",
      "   5.49241044e-02   4.15659696e-02   3.28227639e-01   1.11896597e-01\n",
      "   3.19279790e-01  -1.71127513e-01   6.01204894e-02   4.42295671e-01\n",
      "   1.44027732e-02   1.85351204e-02  -1.19624518e-01  -2.11956695e-01\n",
      "  -2.34261572e-01  -2.33597428e-01   5.89436293e-02  -2.84977388e-02\n",
      "   8.76551047e-02   4.04452980e-01   9.62183028e-02  -8.91231075e-02\n",
      "  -8.53166208e-02  -1.25784978e-01  -4.95167434e-01   9.21628922e-02\n",
      "  -5.70160896e-02   1.01121217e-01   1.05300814e-01   8.62423051e-03\n",
      "   8.07050616e-03  -2.31185302e-01   2.38978356e-01  -1.44090056e-01\n",
      "  -6.67712763e-02  -9.07792896e-02  -1.27523825e-01   1.57766089e-01\n",
      "   3.65830064e-02  -3.98475498e-01   5.38795330e-02   1.09239131e-01\n",
      "   1.92898437e-01  -4.13711280e-01  -1.35160297e-01   1.07787957e-03\n",
      "  -4.55608994e-01  -2.13732883e-01  -1.61113113e-01  -1.40610440e-02\n",
      "  -9.12607014e-02  -2.35204533e-01   1.64356709e-01   2.08678871e-01\n",
      "   2.80819803e-01   9.39912125e-02   1.44577295e-01  -3.80409998e-03\n",
      "  -8.44939128e-02   2.14474589e-01  -3.12351100e-02   1.56557441e-01\n",
      "  -4.22907807e-02  -1.34867290e-02   7.06299096e-02  -3.12885046e-01\n",
      "   2.94823498e-01   1.01775371e-01  -3.59637707e-01   9.07006711e-02\n",
      "   8.31950642e-03  -2.55382687e-01  -1.14288546e-01   1.06601968e-01\n",
      "   4.60649244e-02   1.57171395e-02  -7.96376765e-02   3.78970802e-01\n",
      "   9.52442288e-02   3.19253743e-01  -5.45870885e-02  -3.55397463e-02\n",
      "   1.65653810e-01   1.33426916e-02   6.26330823e-02  -1.85146779e-01\n",
      "  -1.73501283e-01   3.53331231e-02   2.17558637e-01   1.73738852e-01\n",
      "  -5.43530881e-02  -4.24337126e-02   2.39276469e-01   1.50699764e-01\n",
      "   6.66964054e-02  -1.14910938e-01   4.17928472e-02   1.00047477e-01\n",
      "  -1.16508603e-01   3.64608109e-01   1.21131346e-01   2.87150949e-01\n",
      "   2.13464558e-01  -1.72312632e-02   1.56785280e-01   2.05084041e-01\n",
      "  -8.18181410e-02  -2.65958607e-01  -5.87664098e-02  -7.62358680e-02\n",
      "  -1.48352608e-01   4.89886478e-02   1.29530147e-01   1.40570449e-02\n",
      "   1.20881662e-01  -8.15788358e-02   5.27970977e-02   2.93792505e-02\n",
      "   7.35232383e-02   1.65223166e-01   1.29031301e-01   4.13970128e-02\n",
      "  -2.76716709e-01  -1.85931310e-01  -2.03533292e-01  -3.64895552e-01\n",
      "  -1.55888230e-01   9.51624438e-02   2.26891100e-01   3.04801345e-01\n",
      "   1.40905306e-01  -2.22271279e-01  -2.05917694e-02  -2.11804911e-01\n",
      "  -2.31670141e-01  -6.88192099e-02  -1.86466742e-02   2.30749488e-01\n",
      "  -1.66776143e-02  -1.82207361e-01   4.61142838e-01  -6.42097369e-02\n",
      "  -5.72453700e-02  -2.03576222e-01   4.57669459e-02   3.62941325e-02\n",
      "  -1.08830750e-01   3.25299472e-01  -5.39094992e-02   1.51824161e-01\n",
      "  -6.38190210e-02  -2.56936461e-01   1.38283059e-01   3.55795205e-01\n",
      "   7.99690336e-02   3.41072381e-01  -1.01470649e-01  -2.28960648e-01\n",
      "  -4.30529803e-01   1.35338590e-01   1.99509382e-01  -2.06415609e-01\n",
      "   1.11130670e-01  -3.49696241e-02   1.54366866e-01  -6.71295971e-02]\n",
      "farm\n",
      "[(u'huns', 0.24207834899425507), (u'abandoning', 0.2200893610715866), (u'murdered', 0.21127328276634216), (u'undisputed', 0.20080813765525818), (u'commanded', 0.19702816009521484), (u'(c.', 0.19458350539207458), (u'magnus', 0.1942438930273056), (u'region', 0.1911391317844391), (u'demise', 0.1903011053800583), (u'impression', 0.18742996454238892)]\n",
      "[(u'huns', 1.13799250125885), (u'abandoning', 1.1367428302764893), (u'murdered', 1.129019021987915), (u'undisputed', 1.1230363845825195), (u'impression', 1.1155271530151367), (u'expense', 1.1153360605239868), (u'commanded', 1.1150836944580078), (u'magnus', 1.1146767139434814), (u'demise', 1.114365816116333), (u'(c.', 1.113966464996338)]\n",
      "0.704212032626\n",
      "0.704212032626\n",
      "[ 0.02585918  0.06100375 -0.08774483 -0.00739496 -0.04122698 -0.00534143\n",
      " -0.02446961  0.0260016  -0.0590136  -0.01809221  0.01835017  0.02913041\n",
      " -0.0013288  -0.05486665 -0.01571374  0.03299318  0.00144069 -0.01350606\n",
      "  0.03502028 -0.03823548 -0.00611469  0.003898   -0.08172769  0.01793902\n",
      "  0.00698398  0.00442145 -0.06668975 -0.0989003   0.00695013 -0.0425433\n",
      "  0.03215763  0.04904949 -0.07150216 -0.00418546 -0.02017685  0.00848947\n",
      "  0.02203021  0.01884393  0.02424736 -0.03064172  0.02862456 -0.01221713\n",
      " -0.00516514 -0.00312461  0.00954296  0.02840408 -0.04228759 -0.08578406\n",
      "  0.01818297 -0.03133411 -0.02258679  0.0330611  -0.02714408 -0.02477907\n",
      "  0.00182228  0.0031098  -0.0353213   0.02576219 -0.03131041 -0.02525805\n",
      "  0.05511935 -0.03150685  0.01966664  0.02801436  0.01641754  0.0446643\n",
      "  0.03057235  0.0025353   0.01536783  0.09593218 -0.02286172  0.04981206\n",
      " -0.01931944 -0.00426898 -0.03709302  0.03783145 -0.00179225 -0.01459095\n",
      "  0.04029362  0.04512022  0.0453447   0.06294847  0.02831417  0.03163547\n",
      "  0.00424056  0.02035617  0.05015454  0.04416201  0.04132309 -0.03322023\n",
      " -0.025426    0.01762258  0.06517811 -0.03675087  0.05730379  0.0768512\n",
      "  0.02076814 -0.06238872  0.01031009 -0.03516351  0.01807478 -0.02127575\n",
      "  0.05621732 -0.04352859  0.02296859  0.00799727 -0.01104503 -0.00715159\n",
      "  0.04838916  0.05034655  0.03809059 -0.03979453  0.04030778 -0.03831818\n",
      " -0.01118967 -0.07619529  0.01161084  0.02050308 -0.02891784  0.01476145\n",
      "  0.0363179  -0.00586747 -0.04028201  0.06475788  0.06264052 -0.01494892\n",
      " -0.00439838 -0.04287384 -0.02319544  0.02921851 -0.06027365 -0.04389355\n",
      "  0.00352403  0.01214812 -0.00225636 -0.013862    0.07391041  0.00119935\n",
      " -0.03928717  0.04649908  0.02653568  0.04317921  0.02410018 -0.06975507\n",
      "  0.00163938  0.01648647 -0.03141909 -0.00756751 -0.05094377  0.04036339\n",
      " -0.06810289  0.05244622 -0.01131601  0.02015995 -0.02505327 -0.00412973\n",
      " -0.07151207  0.01464757 -0.01382759 -0.02795403 -0.04609708 -0.02863787\n",
      "  0.00900631 -0.00926893 -0.0063477  -0.00256509  0.0215628   0.00747772\n",
      " -0.02389704  0.02613682 -0.05125268  0.04060712  0.04344188 -0.02729662\n",
      "  0.02009539  0.02302593 -0.02254699 -0.01160049 -0.04584116 -0.05448725\n",
      " -0.05466649 -0.04616675 -0.05583374 -0.02190026 -0.00014707  0.00790153\n",
      " -0.01255134 -0.03343987  0.07828943 -0.02421498  0.03749695 -0.01195321\n",
      "  0.04921286  0.0029674   0.00383798 -0.09001935  0.04454748  0.05415576\n",
      " -0.00698262 -0.02587227 -0.0129608  -0.03042215 -0.00990416  0.00370884\n",
      " -0.00251372 -0.04537825 -0.04421558  0.03167501  0.0375649  -0.03388137\n",
      " -0.00295782  0.01864166  0.04615222 -0.00646993  0.00337122  0.00460658\n",
      " -0.03484327 -0.02011312  0.03632656  0.00637918  0.04616145 -0.10840878\n",
      "  0.02317474 -0.06914655  0.00051942  0.01137162 -0.01487953  0.11236675\n",
      " -0.00955331 -0.03908218 -0.00190035 -0.00837381 -0.01406969  0.08287849\n",
      " -0.0182694  -0.07576462  0.031459   -0.06403176 -0.08908021 -0.08902694\n",
      "  0.05942859 -0.01330912 -0.01062279 -0.01960234  0.00124137  0.01548475\n",
      " -0.05261302  0.05135372 -0.06159668  0.05236287 -0.04433273 -0.03296834\n",
      "  0.0661569  -0.0036175  -0.05383654  0.03321612 -0.05708627 -0.02489134\n",
      " -0.0294832  -0.03260549  0.00881639  0.05493058  0.00624675  0.05699357\n",
      " -0.12792505  0.03957666 -0.0087729  -0.02864727 -0.06834609  0.0428624\n",
      "  0.01727114  0.03555903 -0.02508826  0.04157188 -0.00794741 -0.05013743\n",
      "  0.00623029 -0.09863122 -0.04906521 -0.01756747 -0.09095658 -0.05561997\n",
      "  0.01052165  0.02261661 -0.02588015  0.00304213 -0.02493305 -0.00321341\n",
      " -0.08936793 -0.01018991  0.03045582  0.01329705 -0.03583356 -0.03103523\n",
      "  0.00113265 -0.01058341 -0.01658039 -0.01104227  0.06470878 -0.02626832]\n"
     ]
    }
   ],
   "source": [
    "# Access vector by sen index\n",
    "print doc2vec_model.docvecs[0]\n",
    "\n",
    "# Similarity measures\n",
    "print doc2vec_model.doesnt_match([\"farm\", \"turtle\", \"kangaroo\"])\n",
    "print doc2vec_model.most_similar(positive=[\"king\"], negative=[\"queen\"], topn=10)\n",
    "print doc2vec_model.most_similar_cosmul(positive=[\"king\"], negative=[\"queen\"], topn=10)\n",
    "print doc2vec_model.n_similarity([\"king\"], [\"queen\"])\n",
    "print doc2vec_model.similarity(\"king\", \"queen\")\n",
    "\n",
    "# Infer vector of new sentence\n",
    "infer_vec = doc2vec_model.infer_vector([\"king\", \"queen\"])\n",
    "\n",
    "print infer_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
